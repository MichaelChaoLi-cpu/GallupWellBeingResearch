{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e0a7f5-4f81-45a5-9068-4772bd46d6a2",
   "metadata": {},
   "source": [
    "# XGB Experiment based on 64 Variables 1911k Rows 14 Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24578a9a-6f89-4907-816d-d814c5ade4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/OneDrive - Kyushu University/ESG09_Article/Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42df5056-cd73-470d-8334-ce8671cdcb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/OneDrive - Kyushu University/ESG09_Article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6009ac-145e-47be-9096-35eeedab9b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f33844a-36be-4ee8-83c0-fe624c94334b",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb60c9b4-8d85-43a5-931c-58c8ba463e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde636e-76d5-4782-9d02-854c30a448cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d359fa6-1cb7-47e9-ae65-0ff6cba75d25",
   "metadata": {},
   "source": [
    "## Load and Make Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed8730d-5cc8-4179-aa98-231dc486a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_Filename = os.path.join(\"Data\", \"GallupWB_Ml64var1911k14wave_v1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33e195a-3b83-47d2-ac56-773050de6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "Df = pd.read_parquet(Df_Filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3fa09c-ebe8-424c-8024-d2c901bc9297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1911212, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c0e57-c12a-489e-84cf-f39bf650b2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc602706-5109-4d5b-8b50-5acf8df6854c",
   "metadata": {},
   "source": [
    "### Train and Test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab08588-64e2-4eea-bfd5-2fb199315901",
   "metadata": {},
   "outputs": [],
   "source": [
    "Df = Df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a5dfbc-3333-487c-b158-6da2d45815a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Df['COUNTRY_ISO3'] = Df['COUNTRY_ISO3'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820f531b-321d-4d13-89f0-fc4db03118a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wave</th>\n",
       "      <th>INCOME_2</th>\n",
       "      <th>Cantril_ladder</th>\n",
       "      <th>Health_disable</th>\n",
       "      <th>Relative_have</th>\n",
       "      <th>Living_standard_change</th>\n",
       "      <th>Enough_food</th>\n",
       "      <th>Enough_shelter</th>\n",
       "      <th>Well_rested</th>\n",
       "      <th>Respected</th>\n",
       "      <th>...</th>\n",
       "      <th>Corruption_government</th>\n",
       "      <th>Performance_leadership</th>\n",
       "      <th>Gender_female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Employment</th>\n",
       "      <th>Children_under15</th>\n",
       "      <th>Feeling_income</th>\n",
       "      <th>Income_level</th>\n",
       "      <th>COUNTRY_ISO3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>35602.470662</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NZL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>20170.734058</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>8664.458086</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>BWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>30706.925977</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KWT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>4826.805232</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wave      INCOME_2  Cantril_ladder  Health_disable  Relative_have  \\\n",
       "0    10  35602.470662             7.0             2.0            1.0   \n",
       "1    11  20170.734058             5.0             2.0            1.0   \n",
       "2     6   8664.458086             4.0             2.0            1.0   \n",
       "3    12  30706.925977             2.0             2.0            1.0   \n",
       "4     7   4826.805232             8.0             1.0            1.0   \n",
       "\n",
       "   Living_standard_change  Enough_food  Enough_shelter  Well_rested  \\\n",
       "0                    -0.0          0.0             0.0          1.0   \n",
       "1                    -1.0          0.0             0.0          1.0   \n",
       "2                     1.0          0.0             1.0          1.0   \n",
       "3                     1.0          0.0             0.0          0.0   \n",
       "4                     1.0          0.0             0.0          1.0   \n",
       "\n",
       "   Respected  ...  Corruption_government  Performance_leadership  \\\n",
       "0        1.0  ...                    1.0                     0.0   \n",
       "1        1.0  ...                    1.0                     0.0   \n",
       "2        1.0  ...                    0.0                     1.0   \n",
       "3        1.0  ...                    0.0                     0.0   \n",
       "4        1.0  ...                    1.0                     0.0   \n",
       "\n",
       "   Gender_female   Age  Marital_status  Employment  Children_under15  \\\n",
       "0            0.0  64.0             1.0         5.0               0.0   \n",
       "1            1.0  18.0             1.0         6.0               0.0   \n",
       "2            0.0  15.0             1.0         6.0               1.0   \n",
       "3            0.0  33.0             2.0         1.0               1.0   \n",
       "4            0.0  29.0             8.0         1.0               1.0   \n",
       "\n",
       "   Feeling_income  Income_level  COUNTRY_ISO3  \n",
       "0             2.0           3.0           NZL  \n",
       "1             2.0           1.0           LBN  \n",
       "2             3.0           3.0           BWA  \n",
       "3             2.0           1.0           KWT  \n",
       "4             3.0           4.0           HND  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2199da16-1770-4fb8-a1d1-9762d1bc15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Df['Cantril_ladder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738dfbdb-c2ef-4de7-bb5d-64f669496ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Df.drop(columns=['Cantril_ladder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c348f3-2864-4af9-8fa3-05da3bce7d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1911212, 63)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b201386a-df93-407a-98a0-7137b8c8fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64354b-904a-4008-89df-4c1326e2e399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "592be31a-44af-4a63-b13d-ab918ed2e92e",
   "metadata": {},
   "source": [
    "### Basic XGBoost Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6537ceb-0de9-4092-900c-face914d69e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(objective='reg:squarederror', device = 'cuda', tree_method='hist', \n",
    "                         n_estimators=500, learning_rate=0.01, max_depth=5, \n",
    "                         random_state=42, enable_categorical=True  )\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42697959-c7fe-48e9-9ba0-d4d0d6dccb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:55:55] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "496cb641-32a0-4492-bdaa-82ea816e0271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.5966296143017"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aceb4dc0-ffad-4488-b5ea-0808237ba6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b75ab5a-0042-4220-a374-8cc39fd27428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.76520229433162"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_train_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac36f1d-28bb-4a1d-a421-cdd62735f11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1141001-6f60-4bd8-a690-59124ff47e67",
   "metadata": {},
   "source": [
    "### Fine-tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eb54a8a-e788-48c2-a1d9-c7af49df1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = list(range(100, 1_100, 100))\n",
    "learning_rate_list = [0.001, 0.01, 0.1]\n",
    "max_depth_list = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "subsample_list = [0.6, 0.7, 0.8, 0.9, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cb3e882-b288-40f4-b57c-96bf7febff78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0.001, 3, 0.6, 4.415129833618048, 4.422782984695772]\n",
      "[100, 0.001, 3, 0.7, 4.412602303237378, 4.420117210903651]\n",
      "[100, 0.001, 3, 0.8, 4.410935930442783, 4.41855089772758]\n",
      "[100, 0.001, 3, 0.9, 4.4092220231562, 4.417050344741524]\n",
      "[100, 0.001, 3, 1, 4.4095473873662865, 4.417731229417187]\n",
      "[100, 0.001, 4, 0.6, 4.903044187677407, 4.912279482273075]\n",
      "[100, 0.001, 4, 0.7, 4.90045962560981, 4.909927152140847]\n",
      "[100, 0.001, 4, 0.8, 4.897552002123485, 4.907206175979095]\n",
      "[100, 0.001, 4, 0.9, 4.896992113351861, 4.906531296831296]\n",
      "[100, 0.001, 4, 1, 4.897321347174199, 4.907313591677176]\n",
      "[100, 0.001, 5, 0.6, 5.253012524011447, 5.257933675260096]\n",
      "[100, 0.001, 5, 0.7, 5.250737347942824, 5.25565407777755]\n",
      "[100, 0.001, 5, 0.8, 5.248080082113926, 5.253282434074924]\n",
      "[100, 0.001, 5, 0.9, 5.247298210580098, 5.252559814047042]\n",
      "[100, 0.001, 5, 1, 5.247236993414739, 5.253057381817328]\n",
      "[100, 0.001, 6, 0.6, 5.504764814079033, 5.5036402645967435]\n",
      "[100, 0.001, 6, 0.7, 5.502601052408529, 5.501884572701066]\n",
      "[100, 0.001, 6, 0.8, 5.499601474751293, 5.499214545520614]\n",
      "[100, 0.001, 6, 0.9, 5.498660149087343, 5.498510533213297]\n",
      "[100, 0.001, 6, 1, 5.498015809928269, 5.498119059329953]\n",
      "[100, 0.001, 7, 0.6, 5.697542134904432, 5.689947256359629]\n",
      "[100, 0.001, 7, 0.7, 5.695396731169922, 5.687975161170533]\n",
      "[100, 0.001, 7, 0.8, 5.692616895177361, 5.685392991075256]\n",
      "[100, 0.001, 7, 0.9, 5.691516123955765, 5.684082633649501]\n",
      "[100, 0.001, 7, 1, 5.691342125965171, 5.684367166501936]\n",
      "[100, 0.001, 8, 0.6, 5.857163412831401, 5.840101624668992]\n",
      "[100, 0.001, 8, 0.7, 5.8551453938786135, 5.838043411715077]\n",
      "[100, 0.001, 8, 0.8, 5.853015411750551, 5.836058204108019]\n",
      "[100, 0.001, 8, 0.9, 5.851443633754894, 5.8341605709309245]\n",
      "[100, 0.001, 8, 1, 5.849030103229902, 5.831906513739593]\n",
      "[100, 0.001, 9, 0.6, 6.000606583947487, 5.966647243908419]\n",
      "[100, 0.001, 9, 0.7, 5.99879233596432, 5.96435375089448]\n",
      "[100, 0.001, 9, 0.8, 5.996768478194747, 5.962323894638011]\n",
      "[100, 0.001, 9, 0.9, 5.994530946406873, 5.9602769380660785]\n",
      "[100, 0.001, 9, 1, 5.9903873864364465, 5.959032028257516]\n",
      "[100, 0.001, 10, 0.6, 6.141179191499124, 6.0722516397438415]\n",
      "[100, 0.001, 10, 0.7, 6.140800584782868, 6.072841768041126]\n",
      "[100, 0.001, 10, 0.8, 6.139299793735164, 6.071105088686934]\n",
      "[100, 0.001, 10, 0.9, 6.1380251284857135, 6.070614199768243]\n",
      "[100, 0.001, 10, 1, 6.133313092739979, 6.070062472420346]\n",
      "[100, 0.001, 11, 0.6, 6.296982992016186, 6.163078783326704]\n",
      "[100, 0.001, 11, 0.7, 6.29822303308849, 6.164167814400601]\n",
      "[100, 0.001, 11, 0.8, 6.29812681987314, 6.163096924284561]\n",
      "[100, 0.001, 11, 0.9, 6.297674902900874, 6.163741386139609]\n",
      "[100, 0.001, 11, 1, 6.2897957306076275, 6.160800863501937]\n",
      "[100, 0.001, 12, 0.6, 6.487920804385682, 6.238500928003732]\n",
      "[100, 0.001, 12, 0.7, 6.493266594155056, 6.240599807011382]\n",
      "[100, 0.001, 12, 0.8, 6.496654109998712, 6.241869459159021]\n",
      "[100, 0.001, 12, 0.9, 6.498797707679326, 6.2425380384569795]\n",
      "[100, 0.001, 12, 1, 6.487359483271327, 6.239532773211842]\n",
      "[100, 0.001, 13, 0.6, 6.738069107982392, 6.297801008357151]\n",
      "[100, 0.001, 13, 0.7, 6.753401262425762, 6.3023378037796896]\n",
      "[100, 0.001, 13, 0.8, 6.764857192309903, 6.306761635509506]\n",
      "[100, 0.001, 13, 0.9, 6.77291910540998, 6.308397470345184]\n",
      "[100, 0.001, 13, 1, 6.759155115395876, 6.306318820237744]\n",
      "[100, 0.001, 14, 0.6, 7.06717905143972, 6.3386857872247955]\n",
      "[100, 0.001, 14, 0.7, 7.102194919434657, 6.3463303059286496]\n",
      "[100, 0.001, 14, 0.8, 7.130377059151605, 6.355052131909444]\n",
      "[100, 0.001, 14, 0.9, 7.15263359721896, 6.359781478953208]\n",
      "[100, 0.001, 14, 1, 7.137175173745824, 6.34609126844865]\n",
      "[100, 0.001, 15, 0.6, 7.481242033180968, 6.355545735455282]\n",
      "[100, 0.001, 15, 0.7, 7.5519171162330085, 6.366121946773806]\n",
      "[100, 0.001, 15, 0.8, 7.611126212215935, 6.383075529432858]\n",
      "[100, 0.001, 15, 0.9, 7.660325556544856, 6.389479676550547]\n",
      "[100, 0.001, 15, 1, 7.652296206777665, 6.367100695059824]\n",
      "[100, 0.001, 16, 0.6, 7.96834459396848, 6.343552577084899]\n",
      "[100, 0.001, 16, 0.7, 8.094589269562002, 6.361881093177335]\n",
      "[100, 0.001, 16, 0.8, 8.203899003667992, 6.382786516953997]\n",
      "[100, 0.001, 16, 0.9, 8.296557345543542, 6.395144588304602]\n",
      "[100, 0.001, 16, 1, 8.310303712057543, 6.359510919897926]\n",
      "[100, 0.01, 3, 0.6, 24.130555185751856, 24.18875002822277]\n",
      "[100, 0.01, 3, 0.7, 24.135795078131373, 24.197741344545943]\n",
      "[100, 0.01, 3, 0.8, 24.1182846106309, 24.17581080681944]\n",
      "[100, 0.01, 3, 0.9, 24.12213305985883, 24.181439315793206]\n",
      "[100, 0.01, 3, 1, 24.126401408409205, 24.183272740118046]\n",
      "[100, 0.01, 4, 0.6, 25.842174386567052, 25.89481483485757]\n",
      "[100, 0.01, 4, 0.7, 25.840937624357263, 25.890370765691763]\n",
      "[100, 0.01, 4, 0.8, 25.836785494967017, 25.887325110473903]\n",
      "[100, 0.01, 4, 0.9, 25.84687217812638, 25.901432144791126]\n",
      "[100, 0.01, 4, 1, 25.85194579152452, 25.904127335771697]\n",
      "[100, 0.01, 5, 0.6, 26.958048712103267, 26.99830770191608]\n",
      "[100, 0.01, 5, 0.7, 26.948827293940735, 26.982266583070903]\n",
      "[100, 0.01, 5, 0.8, 26.957391595825207, 26.991276430668975]\n",
      "[100, 0.01, 5, 0.9, 26.950805555915704, 26.987341690373313]\n",
      "[100, 0.01, 5, 1, 26.96365450171746, 26.995849199239675]\n",
      "[100, 0.01, 6, 0.6, 27.80993654075973, 27.811314553419443]\n",
      "[100, 0.01, 6, 0.7, 27.802317813081444, 27.803966081373222]\n",
      "[100, 0.01, 6, 0.8, 27.7951858986873, 27.794050429732188]\n",
      "[100, 0.01, 6, 0.9, 27.794264535265622, 27.795044449396876]\n",
      "[100, 0.01, 6, 1, 27.79513147322804, 27.795059864522653]\n",
      "[100, 0.01, 7, 0.6, 28.508075567277313, 28.459056701017914]\n",
      "[100, 0.01, 7, 0.7, 28.500795666975918, 28.45307152622358]\n",
      "[100, 0.01, 7, 0.8, 28.498959215146012, 28.453122398605924]\n",
      "[100, 0.01, 7, 0.9, 28.49108866923318, 28.442912923339346]\n",
      "[100, 0.01, 7, 1, 28.486547294476207, 28.43837931979477]\n",
      "[100, 0.01, 8, 0.6, 29.152845050841957, 28.994045611154462]\n",
      "[100, 0.01, 8, 0.7, 29.13983473780225, 28.985772137092304]\n",
      "[100, 0.01, 8, 0.8, 29.13733160573193, 28.978235063956646]\n",
      "[100, 0.01, 8, 0.9, 29.124618450841822, 28.962445419834282]\n",
      "[100, 0.01, 8, 1, 29.11548563800436, 28.95722171801288]\n",
      "[100, 0.01, 9, 0.6, 29.817277970546808, 29.469250593939933]\n",
      "[100, 0.01, 9, 0.7, 29.811997810138323, 29.459393550786228]\n",
      "[100, 0.01, 9, 0.8, 29.801015165928625, 29.444732983255008]\n",
      "[100, 0.01, 9, 0.9, 29.78702689952574, 29.436878479714757]\n",
      "[100, 0.01, 9, 1, 29.769269048147716, 29.42221595803445]\n",
      "[100, 0.01, 10, 0.6, 30.588804543773108, 29.90160939601627]\n",
      "[100, 0.01, 10, 0.7, 30.579750551496076, 29.89039973779255]\n",
      "[100, 0.01, 10, 0.8, 30.575034809033184, 29.882492625329682]\n",
      "[100, 0.01, 10, 0.9, 30.55309244438056, 29.858978637450416]\n",
      "[100, 0.01, 10, 1, 30.52221178967831, 29.825592864116345]\n",
      "[100, 0.01, 11, 0.6, 31.587259647823263, 30.290726419033675]\n",
      "[100, 0.01, 11, 0.7, 31.584005788388914, 30.27390337892253]\n",
      "[100, 0.01, 11, 0.8, 31.575454704975712, 30.258027401795594]\n",
      "[100, 0.01, 11, 0.9, 31.557091998548227, 30.2404972900568]\n",
      "[100, 0.01, 11, 1, 31.495497361534262, 30.172416086086606]\n",
      "[100, 0.01, 12, 0.6, 32.97416198339883, 30.625129970052413]\n",
      "[100, 0.01, 12, 0.7, 32.99168644449598, 30.61497146646116]\n",
      "[100, 0.01, 12, 0.8, 32.99523222571993, 30.59411038123373]\n",
      "[100, 0.01, 12, 0.9, 32.98548651026043, 30.56845440817283]\n",
      "[100, 0.01, 12, 1, 32.87571578142063, 30.462940119580228]\n",
      "[100, 0.01, 13, 0.6, 34.930501795221524, 30.921117001518805]\n",
      "[100, 0.01, 13, 0.7, 35.0056809025693, 30.908120408443196]\n",
      "[100, 0.01, 13, 0.8, 35.056614733879954, 30.888642880479022]\n",
      "[100, 0.01, 13, 0.9, 35.08042452693198, 30.85885653619086]\n",
      "[100, 0.01, 13, 1, 34.91742718990763, 30.702402170807964]\n",
      "[100, 0.01, 14, 0.6, 37.56462732552964, 31.136481437970854]\n",
      "[100, 0.01, 14, 0.7, 37.77198951295483, 31.12646482850454]\n",
      "[100, 0.01, 14, 0.8, 37.92276474449159, 31.126089704115955]\n",
      "[100, 0.01, 14, 0.9, 38.025488868668425, 31.08668161956174]\n",
      "[100, 0.01, 14, 1, 37.82871439125304, 30.858002506493165]\n",
      "[100, 0.01, 15, 0.6, 40.88025272779363, 31.262557551664706]\n",
      "[100, 0.01, 15, 0.7, 41.31778637610345, 31.26653883411231]\n",
      "[100, 0.01, 15, 0.8, 41.64824512518928, 31.27499020296919]\n",
      "[100, 0.01, 15, 0.9, 41.89196394475354, 31.241436226475518]\n",
      "[100, 0.01, 15, 1, 41.67842050293188, 30.89665320657472]\n",
      "[100, 0.01, 16, 0.6, 44.707379295477864, 31.293509599547807]\n",
      "[100, 0.01, 16, 0.7, 45.45925523073632, 31.313368664489893]\n",
      "[100, 0.01, 16, 0.8, 46.07541246838696, 31.34178898962041]\n",
      "[100, 0.01, 16, 0.9, 46.56408570648015, 31.30461332330259]\n",
      "[100, 0.01, 16, 1, 46.42580467284824, 30.826841919736747]\n",
      "[100, 0.1, 3, 0.6, 35.37732469797399, 35.343429242177336]\n",
      "[100, 0.1, 3, 0.7, 35.37564360097684, 35.35240402688823]\n",
      "[100, 0.1, 3, 0.8, 35.377126599989786, 35.34156002223773]\n",
      "[100, 0.1, 3, 0.9, 35.45431182534675, 35.40035941985862]\n",
      "[100, 0.1, 3, 1, 35.37858603402325, 35.357152315388085]\n",
      "[100, 0.1, 4, 0.6, 36.162986294499845, 36.02415127377216]\n",
      "[100, 0.1, 4, 0.7, 36.13115490982598, 35.9833541524619]\n",
      "[100, 0.1, 4, 0.8, 36.155528158146396, 36.03228755316369]\n",
      "[100, 0.1, 4, 0.9, 36.13872282263778, 35.97135815205183]\n",
      "[100, 0.1, 4, 1, 36.110467356613704, 35.96310080239158]\n",
      "[100, 0.1, 5, 0.6, 36.75927848834791, 36.424359943255055]\n",
      "[100, 0.1, 5, 0.7, 36.80085537320015, 36.45671816665056]\n",
      "[100, 0.1, 5, 0.8, 36.81936977108799, 36.46376279471211]\n",
      "[100, 0.1, 5, 0.9, 36.820144181686445, 36.46922808725675]\n",
      "[100, 0.1, 5, 1, 36.81647211326954, 36.4541269506101]\n",
      "[100, 0.1, 6, 0.6, 37.41953810778285, 36.821304392323725]\n",
      "[100, 0.1, 6, 0.7, 37.4680388955439, 36.821867062603545]\n",
      "[100, 0.1, 6, 0.8, 37.46254699147894, 36.845087133397804]\n",
      "[100, 0.1, 6, 0.9, 37.495197014889655, 36.86529013564011]\n",
      "[100, 0.1, 6, 1, 37.51388379032473, 36.82014021960788]\n",
      "[100, 0.1, 7, 0.6, 38.22122868376508, 37.14899833354828]\n",
      "[100, 0.1, 7, 0.7, 38.27771736413862, 37.13854520546549]\n",
      "[100, 0.1, 7, 0.8, 38.294737606233596, 37.132822195960266]\n",
      "[100, 0.1, 7, 0.9, 38.37926255121571, 37.18413220420366]\n",
      "[100, 0.1, 7, 1, 38.3548554955871, 37.118818371977866]\n",
      "[100, 0.1, 8, 0.6, 39.32279343895154, 37.39432880292587]\n",
      "[100, 0.1, 8, 0.7, 39.42931765922864, 37.4478317214984]\n",
      "[100, 0.1, 8, 0.8, 39.464878583826476, 37.430267042330655]\n",
      "[100, 0.1, 8, 0.9, 39.543199739139226, 37.47668690964618]\n",
      "[100, 0.1, 8, 1, 39.57598218206987, 37.4406831761228]\n",
      "[100, 0.1, 9, 0.6, 41.036092730733756, 37.61852851565879]\n",
      "[100, 0.1, 9, 0.7, 41.17586267344424, 37.71324604600721]\n",
      "[100, 0.1, 9, 0.8, 41.26748817099145, 37.65025146997152]\n",
      "[100, 0.1, 9, 0.9, 41.344290915032374, 37.73297101668066]\n",
      "[100, 0.1, 9, 1, 41.40772237779685, 37.69148345386034]\n",
      "[100, 0.1, 10, 0.6, 43.69257982039275, 37.71052765187682]\n",
      "[100, 0.1, 10, 0.7, 43.89500581705694, 37.73509485372885]\n",
      "[100, 0.1, 10, 0.8, 44.037767973676544, 37.81390586119403]\n",
      "[100, 0.1, 10, 0.9, 44.18083941427311, 37.86874085655793]\n",
      "[100, 0.1, 10, 1, 44.28954793744586, 37.84495552158742]\n",
      "[100, 0.1, 11, 0.6, 47.84596276534053, 37.60897989203351]\n",
      "[100, 0.1, 11, 0.7, 48.14298152135817, 37.81417239996641]\n",
      "[100, 0.1, 11, 0.8, 48.34289398003787, 37.919068276565135]\n",
      "[100, 0.1, 11, 0.9, 48.54644599410983, 37.898251486389526]\n",
      "[100, 0.1, 11, 1, 48.75843069678524, 37.77743970946316]\n",
      "[100, 0.1, 12, 0.6, 53.61947886441221, 37.45688919223529]\n",
      "[100, 0.1, 12, 0.7, 54.18722315118718, 37.532721340704775]\n",
      "[100, 0.1, 12, 0.8, 54.606912473483845, 37.74744616765542]\n",
      "[100, 0.1, 12, 0.9, 54.87678982747426, 37.81086698214396]\n",
      "[100, 0.1, 12, 1, 55.18798373655693, 37.948075275117546]\n",
      "[100, 0.1, 13, 0.6, 61.29576211750663, 36.99555569803311]\n",
      "[100, 0.1, 13, 0.7, 62.2062775710598, 37.162674569770296]\n",
      "[100, 0.1, 13, 0.8, 62.74939695245728, 37.47368607020752]\n",
      "[100, 0.1, 13, 0.9, 63.20371531324254, 37.49316990693148]\n",
      "[100, 0.1, 13, 1, 63.554212792806275, 37.6334465688966]\n",
      "[100, 0.1, 14, 0.6, 70.24117886430392, 36.29140695895533]\n",
      "[100, 0.1, 14, 0.7, 71.45468737383338, 36.65553564271199]\n",
      "[100, 0.1, 14, 0.8, 72.208780280091, 36.85464988015895]\n",
      "[100, 0.1, 14, 0.9, 72.7663992106214, 37.18606169190339]\n",
      "[100, 0.1, 14, 1, 73.20970717903374, 37.12945652033726]\n",
      "[100, 0.1, 15, 0.6, 79.20945994941222, 35.791613127589464]\n",
      "[100, 0.1, 15, 0.7, 80.65144595795289, 36.083943323805855]\n",
      "[100, 0.1, 15, 0.8, 81.58187450936774, 36.346688007365834]\n",
      "[100, 0.1, 15, 0.9, 82.2786198684888, 36.63177722881047]\n",
      "[100, 0.1, 15, 1, 82.46325874172963, 36.651236242553054]\n",
      "[100, 0.1, 16, 0.6, 86.7194676338555, 34.9619754311869]\n",
      "[100, 0.1, 16, 0.7, 88.25611112013647, 35.42844953673709]\n",
      "[100, 0.1, 16, 0.8, 89.16212944893623, 36.0111813215707]\n",
      "[100, 0.1, 16, 0.9, 89.8143276670561, 35.98015302862834]\n",
      "[100, 0.1, 16, 1, 90.08845865281924, 35.79154288732197]\n",
      "[200, 0.001, 3, 0.6, 8.07449025890522, 8.087511203714893]\n",
      "[200, 0.001, 3, 0.7, 8.072012959719688, 8.084722167132885]\n",
      "[200, 0.001, 3, 0.8, 8.070782375814234, 8.08351386522702]\n",
      "[200, 0.001, 3, 0.9, 8.068086461799417, 8.08142128546363]\n",
      "[200, 0.001, 3, 1, 8.068913253147603, 8.08341889314147]\n",
      "[200, 0.001, 4, 0.6, 8.969913737286683, 8.985900923066858]\n",
      "[200, 0.001, 4, 0.7, 8.965540619243018, 8.981910800162407]\n",
      "[200, 0.001, 4, 0.8, 8.9625350897518, 8.978349394585205]\n",
      "[200, 0.001, 4, 0.9, 8.96140377225596, 8.978204264347834]\n",
      "[200, 0.001, 4, 1, 8.962191380194895, 8.978806047776732]\n",
      "[200, 0.001, 5, 0.6, 9.588413340476066, 9.597844615131567]\n",
      "[200, 0.001, 5, 0.7, 9.585077031095835, 9.594636878904716]\n",
      "[200, 0.001, 5, 0.8, 9.581582124678967, 9.591769419602958]\n",
      "[200, 0.001, 5, 0.9, 9.580734457498075, 9.591180334045857]\n",
      "[200, 0.001, 5, 1, 9.582163283674905, 9.592876757979607]\n",
      "[200, 0.001, 6, 0.6, 10.045383448890266, 10.04388899899804]\n",
      "[200, 0.001, 6, 0.7, 10.0414508046761, 10.040512183508865]\n",
      "[200, 0.001, 6, 0.8, 10.0363503692659, 10.036061013883135]\n",
      "[200, 0.001, 6, 0.9, 10.033188307885165, 10.03297674456567]\n",
      "[200, 0.001, 6, 1, 10.030157680750618, 10.030202522471187]\n",
      "[200, 0.001, 7, 0.6, 10.393881529190951, 10.380140808877236]\n",
      "[200, 0.001, 7, 0.7, 10.39048469604812, 10.377496531854247]\n",
      "[200, 0.001, 7, 0.8, 10.385870182693912, 10.373346844453046]\n",
      "[200, 0.001, 7, 0.9, 10.382453458468754, 10.369687795685568]\n",
      "[200, 0.001, 7, 1, 10.379752698959077, 10.366031118655405]\n",
      "[200, 0.001, 8, 0.6, 10.6857141943558, 10.652891488561023]\n",
      "[200, 0.001, 8, 0.7, 10.682015245017595, 10.648695854313262]\n",
      "[200, 0.001, 8, 0.8, 10.678159096309358, 10.64502487687321]\n",
      "[200, 0.001, 8, 0.9, 10.673450609658774, 10.639466699249878]\n",
      "[200, 0.001, 8, 1, 10.66742245566219, 10.633094583830772]\n",
      "[200, 0.001, 9, 0.6, 10.947613824980163, 10.87989222660929]\n",
      "[200, 0.001, 9, 0.7, 10.945374964958132, 10.877547696408218]\n",
      "[200, 0.001, 9, 0.8, 10.940748390862076, 10.87238091309085]\n",
      "[200, 0.001, 9, 0.9, 10.935304005334178, 10.86718526169208]\n",
      "[200, 0.001, 9, 1, 10.927279492380283, 10.860577803394778]\n",
      "[200, 0.001, 10, 0.6, 11.209216714012161, 11.07282921195929]\n",
      "[200, 0.001, 10, 0.7, 11.208666265911893, 11.073727143919198]\n",
      "[200, 0.001, 10, 0.8, 11.20373910934509, 11.06749437949659]\n",
      "[200, 0.001, 10, 0.9, 11.198127563616811, 11.062936357431797]\n",
      "[200, 0.001, 10, 1, 11.18771732544409, 11.054775727917598]\n",
      "[200, 0.001, 11, 0.6, 11.504231492423001, 11.238362126276824]\n",
      "[200, 0.001, 11, 0.7, 11.506067055514036, 11.23970438487164]\n",
      "[200, 0.001, 11, 0.8, 11.503526923434727, 11.235758880139635]\n",
      "[200, 0.001, 11, 0.9, 11.498012137563428, 11.232274448968605]\n",
      "[200, 0.001, 11, 1, 11.479380489816815, 11.220052570486526]\n",
      "[200, 0.001, 12, 0.6, 11.870674507119293, 11.376144335913619]\n",
      "[200, 0.001, 12, 0.7, 11.880186592948693, 11.380365095060496]\n",
      "[200, 0.001, 12, 0.8, 11.884245391515547, 11.379817390148972]\n",
      "[200, 0.001, 12, 0.9, 11.882195777525496, 11.375189698766718]\n",
      "[200, 0.001, 12, 1, 11.852059675843973, 11.355507587197932]\n",
      "[200, 0.001, 13, 0.6, 12.356184166749006, 11.48577671809562]\n",
      "[200, 0.001, 13, 0.7, 12.38427810208832, 11.494872803662215]\n",
      "[200, 0.001, 13, 0.8, 12.402615686657704, 11.498907215339605]\n",
      "[200, 0.001, 13, 0.9, 12.410814043981755, 11.496888983808674]\n",
      "[200, 0.001, 13, 1, 12.370106724677587, 11.472972703627393]\n",
      "[200, 0.001, 14, 0.6, 12.998208150856815, 11.56272439827668]\n",
      "[200, 0.001, 14, 0.7, 13.063404905397158, 11.579095399457561]\n",
      "[200, 0.001, 14, 0.8, 13.112611578765065, 11.589035905293866]\n",
      "[200, 0.001, 14, 0.9, 13.14543230064491, 11.590216740815162]\n",
      "[200, 0.001, 14, 1, 13.092017272985135, 11.544611112047798]\n",
      "[200, 0.001, 15, 0.6, 13.807075733188379, 11.597419340985615]\n",
      "[200, 0.001, 15, 0.7, 13.93927700451365, 11.61897638221302]\n",
      "[200, 0.001, 15, 0.8, 14.046507613963621, 11.641604435513898]\n",
      "[200, 0.001, 15, 0.9, 14.127743614451438, 11.645671943038504]\n",
      "[200, 0.001, 15, 1, 14.073231690198295, 11.577753187151263]\n",
      "[200, 0.001, 16, 0.6, 14.75963770722527, 11.582875599010634]\n",
      "[200, 0.001, 16, 0.7, 14.994435098366242, 11.613318122087367]\n",
      "[200, 0.001, 16, 0.8, 15.193589908453042, 11.646419811817843]\n",
      "[200, 0.001, 16, 0.9, 15.354228952169146, 11.66013843495678]\n",
      "[200, 0.001, 16, 1, 15.327559647121614, 11.540031007397767]\n",
      "[200, 0.01, 3, 0.6, 30.464271612534578, 30.51719371032473]\n",
      "[200, 0.01, 3, 0.7, 30.45594181812781, 30.5104314299219]\n",
      "[200, 0.01, 3, 0.8, 30.4474467847306, 30.500906559560313]\n",
      "[200, 0.01, 3, 0.9, 30.44869689358396, 30.50267360099317]\n",
      "[200, 0.01, 3, 1, 30.45659125971605, 30.512181013880678]\n",
      "[200, 0.01, 4, 0.6, 31.801542322396514, 31.839063851370696]\n",
      "[200, 0.01, 4, 0.7, 31.797298888930648, 31.831572869278446]\n",
      "[200, 0.01, 4, 0.8, 31.79529135176642, 31.829103599090857]\n",
      "[200, 0.01, 4, 0.9, 31.797273009376404, 31.833426360073613]\n",
      "[200, 0.01, 4, 1, 31.803052817487366, 31.835662954714827]\n",
      "[200, 0.01, 5, 0.6, 32.67782657711735, 32.68579874013725]\n",
      "[200, 0.01, 5, 0.7, 32.67284194843894, 32.674194671287346]\n",
      "[200, 0.01, 5, 0.8, 32.67527183848641, 32.67195156392473]\n",
      "[200, 0.01, 5, 0.9, 32.68096651447938, 32.68159906993282]\n",
      "[200, 0.01, 5, 1, 32.67928383130329, 32.67471453619256]\n",
      "[200, 0.01, 6, 0.6, 33.40492245836628, 33.32156208107314]\n",
      "[200, 0.01, 6, 0.7, 33.39842375005219, 33.31381148818493]\n",
      "[200, 0.01, 6, 0.8, 33.39063294905104, 33.30202579808026]\n",
      "[200, 0.01, 6, 0.9, 33.39128833154186, 33.30187662177578]\n",
      "[200, 0.01, 6, 1, 33.386368898857775, 33.29466756964069]\n",
      "[200, 0.01, 7, 0.6, 34.036592942260924, 33.84252188416745]\n",
      "[200, 0.01, 7, 0.7, 34.0351424126649, 33.834329385566384]\n",
      "[200, 0.01, 7, 0.8, 34.03951545527545, 33.83653282251006]\n",
      "[200, 0.01, 7, 0.9, 34.034295441287114, 33.82509915297407]\n",
      "[200, 0.01, 7, 1, 34.02296633886564, 33.80663359885138]\n",
      "[200, 0.01, 8, 0.6, 34.708250158290056, 34.29654118897578]\n",
      "[200, 0.01, 8, 0.7, 34.70215234046088, 34.28681792115338]\n",
      "[200, 0.01, 8, 0.8, 34.70289647656105, 34.27164823003959]\n",
      "[200, 0.01, 8, 0.9, 34.69797590393515, 34.267430119998274]\n",
      "[200, 0.01, 8, 1, 34.68218267545451, 34.24646504866866]\n",
      "[200, 0.01, 9, 0.6, 35.49206253649393, 34.70362475218135]\n",
      "[200, 0.01, 9, 0.7, 35.49303141525062, 34.687134447690816]\n",
      "[200, 0.01, 9, 0.8, 35.496849788906204, 34.67323396539008]\n",
      "[200, 0.01, 9, 0.9, 35.49374224144064, 34.67032777637665]\n",
      "[200, 0.01, 9, 1, 35.472627228128005, 34.64420733278225]\n",
      "[200, 0.01, 10, 0.6, 36.535897910597015, 35.09453076987893]\n",
      "[200, 0.01, 10, 0.7, 36.53697628429954, 35.07248400607635]\n",
      "[200, 0.01, 10, 0.8, 36.54790699783684, 35.05786723934412]\n",
      "[200, 0.01, 10, 0.9, 36.542161572575026, 35.04324808382566]\n",
      "[200, 0.01, 10, 1, 36.521721807677565, 35.011023362661284]\n",
      "[200, 0.01, 11, 0.6, 38.02296351900098, 35.44950716355064]\n",
      "[200, 0.01, 11, 0.7, 38.051491062856414, 35.43113727950239]\n",
      "[200, 0.01, 11, 0.8, 38.05934309510791, 35.41033224801642]\n",
      "[200, 0.01, 11, 0.9, 38.06930507423424, 35.39730237466946]\n",
      "[200, 0.01, 11, 1, 38.0215237879058, 35.31671494711269]\n",
      "[200, 0.01, 12, 0.6, 40.214718396806525, 35.75318362853691]\n",
      "[200, 0.01, 12, 0.7, 40.28920342507886, 35.74336314670427]\n",
      "[200, 0.01, 12, 0.8, 40.34072271580321, 35.72861648141671]\n",
      "[200, 0.01, 12, 0.9, 40.377907662661585, 35.70415291951385]\n",
      "[200, 0.01, 12, 1, 40.2914891011946, 35.58624532819326]\n",
      "[200, 0.01, 13, 0.6, 43.392704568341244, 36.03410374542759]\n",
      "[200, 0.01, 13, 0.7, 43.56556084362013, 36.00587092558908]\n",
      "[200, 0.01, 13, 0.8, 43.697699219864596, 35.98128224967776]\n",
      "[200, 0.01, 13, 0.9, 43.79929958672613, 35.95667559815682]\n",
      "[200, 0.01, 13, 1, 43.651670865593495, 35.746187137795594]\n",
      "[200, 0.01, 14, 0.6, 47.6917622617176, 36.224596043178856]\n",
      "[200, 0.01, 14, 0.7, 48.064343916417265, 36.19512878778679]\n",
      "[200, 0.01, 14, 0.8, 48.333278820890136, 36.18683871487289]\n",
      "[200, 0.01, 14, 0.9, 48.53149764970427, 36.13833110935537]\n",
      "[200, 0.01, 14, 1, 48.35360376069098, 35.831257309109745]\n",
      "[200, 0.01, 15, 0.6, 52.99516103434985, 36.34359959853807]\n",
      "[200, 0.01, 15, 0.7, 53.6580867159159, 36.302246131459846]\n",
      "[200, 0.01, 15, 0.8, 54.169177536193146, 36.30145922960545]\n",
      "[200, 0.01, 15, 0.9, 54.593911387401015, 36.23016248256419]\n",
      "[200, 0.01, 15, 1, 54.40915351848565, 35.7525321177658]\n",
      "[200, 0.01, 16, 0.6, 58.8466372820158, 36.393185333749145]\n",
      "[200, 0.01, 16, 0.7, 59.9189299824045, 36.36388740171761]\n",
      "[200, 0.01, 16, 0.8, 60.744345871025864, 36.36216508719512]\n",
      "[200, 0.01, 16, 0.9, 61.42431951892311, 36.27396289296866]\n",
      "[200, 0.01, 16, 1, 61.27484702164809, 35.549315546555036]\n",
      "[200, 0.1, 3, 0.6, 36.10349037394766, 36.02537356080836]\n",
      "[200, 0.1, 3, 0.7, 36.118230701563036, 36.0235271426763]\n",
      "[200, 0.1, 3, 0.8, 36.09698731618369, 35.98556806801908]\n",
      "[200, 0.1, 3, 0.9, 36.1746770820746, 36.053013222386085]\n",
      "[200, 0.1, 3, 1, 36.15593205926362, 36.03791858174564]\n",
      "[200, 0.1, 4, 0.6, 36.92726150091353, 36.68282954365739]\n",
      "[200, 0.1, 4, 0.7, 36.96545933835132, 36.679149060594675]\n",
      "[200, 0.1, 4, 0.8, 36.978660398435224, 36.69830527859178]\n",
      "[200, 0.1, 4, 0.9, 36.9829025130878, 36.65358353527996]\n",
      "[200, 0.1, 4, 1, 36.96846232055921, 36.651497176310386]\n",
      "[200, 0.1, 5, 0.6, 37.59602057807785, 37.060838374839854]\n",
      "[200, 0.1, 5, 0.7, 37.64093800177212, 37.077136215510706]\n",
      "[200, 0.1, 5, 0.8, 37.69459501723027, 37.095935202197985]\n",
      "[200, 0.1, 5, 0.9, 37.7279011545518, 37.117601934571]\n",
      "[200, 0.1, 5, 1, 37.70448171549835, 37.03656894013161]\n",
      "[200, 0.1, 6, 0.6, 38.38288259774502, 37.3921945314596]\n",
      "[200, 0.1, 6, 0.7, 38.460758082174216, 37.41943858857915]\n",
      "[200, 0.1, 6, 0.8, 38.494318811974104, 37.45117765384178]\n",
      "[200, 0.1, 6, 0.9, 38.598969564649686, 37.48401543963067]\n",
      "[200, 0.1, 6, 1, 38.624000908295976, 37.36070873932593]\n",
      "[200, 0.1, 7, 0.6, 39.46431029136623, 37.64640365745981]\n",
      "[200, 0.1, 7, 0.7, 39.5726537103777, 37.6900411198392]\n",
      "[200, 0.1, 7, 0.8, 39.65994871902447, 37.72009750163433]\n",
      "[200, 0.1, 7, 0.9, 39.76701409812142, 37.78118080257151]\n",
      "[200, 0.1, 7, 1, 39.826987705496194, 37.63047138707856]\n",
      "[200, 0.1, 8, 0.6, 41.15955175748493, 37.8499341919441]\n",
      "[200, 0.1, 8, 0.7, 41.29786427047621, 37.9158646537894]\n",
      "[200, 0.1, 8, 0.8, 41.38772342608606, 37.95444446196312]\n",
      "[200, 0.1, 8, 0.9, 41.53797662481148, 38.00085392107029]\n",
      "[200, 0.1, 8, 1, 41.70543781600675, 37.9428831605748]\n",
      "[200, 0.1, 9, 0.6, 43.88389328810746, 37.93034337686221]\n",
      "[200, 0.1, 9, 0.7, 44.049007452877994, 38.027953143219115]\n",
      "[200, 0.1, 9, 0.8, 44.23734162408516, 38.048333764191064]\n",
      "[200, 0.1, 9, 0.9, 44.39340993818559, 38.19108596846059]\n",
      "[200, 0.1, 9, 1, 44.595759498897195, 38.092005104058536]\n",
      "[200, 0.1, 10, 0.6, 48.176828345119496, 37.794100307164605]\n",
      "[200, 0.1, 10, 0.7, 48.45182533493657, 37.91612476270719]\n",
      "[200, 0.1, 10, 0.8, 48.64571167566747, 38.04570485901646]\n",
      "[200, 0.1, 10, 0.9, 48.87388684284194, 38.13977307836799]\n",
      "[200, 0.1, 10, 1, 49.08751524111029, 38.17883269647789]\n",
      "[200, 0.1, 11, 0.6, 54.530453004392776, 37.433439563083795]\n",
      "[200, 0.1, 11, 0.7, 54.9183127320886, 37.79435360656006]\n",
      "[200, 0.1, 11, 0.8, 55.24251637985322, 37.94006114783478]\n",
      "[200, 0.1, 11, 0.9, 55.49292905323897, 37.98926841939132]\n",
      "[200, 0.1, 11, 1, 55.68872312286064, 37.96716734969867]\n",
      "[200, 0.1, 12, 0.6, 62.92380093890566, 37.07586325271649]\n",
      "[200, 0.1, 12, 0.7, 63.63764089422539, 37.22168810419954]\n",
      "[200, 0.1, 12, 0.8, 64.03731763212659, 37.49215595468067]\n",
      "[200, 0.1, 12, 0.9, 64.38537073893886, 37.643920840026865]\n",
      "[200, 0.1, 12, 1, 64.68177039539007, 37.91690212670502]\n",
      "[200, 0.1, 13, 0.6, 72.87371798725573, 36.33714927464939]\n",
      "[200, 0.1, 13, 0.7, 73.64774047634758, 36.611144586792776]\n",
      "[200, 0.1, 13, 0.8, 74.29166228979105, 37.02570832796882]\n",
      "[200, 0.1, 13, 0.9, 74.70174587132867, 37.15171019822592]\n",
      "[200, 0.1, 13, 1, 74.6930314412474, 37.48809338311776]\n",
      "[200, 0.1, 14, 0.6, 82.67351509972005, 35.40046927319062]\n",
      "[200, 0.1, 14, 0.7, 83.69563713073612, 35.972125486430684]\n",
      "[200, 0.1, 14, 0.8, 84.34092644181203, 36.25718260009527]\n",
      "[200, 0.1, 14, 0.9, 84.88197439565892, 36.75075515570321]\n",
      "[200, 0.1, 14, 1, 84.44867665123874, 36.77118658280209]\n",
      "[200, 0.1, 15, 0.6, 90.86751544857444, 34.867459882326045]\n",
      "[200, 0.1, 15, 0.7, 91.69494684802783, 35.37763540892572]\n",
      "[200, 0.1, 15, 0.8, 92.27387651709108, 35.7393281773094]\n",
      "[200, 0.1, 15, 0.9, 92.58114967940682, 36.11559920148459]\n",
      "[200, 0.1, 15, 1, 92.11801066646596, 36.252381909743534]\n",
      "[200, 0.1, 16, 0.6, 95.94309018867726, 34.20480730626401]\n",
      "[200, 0.1, 16, 0.7, 96.5634321666299, 34.767387913886]\n",
      "[200, 0.1, 16, 0.8, 96.96725955307896, 35.5485407785034]\n",
      "[200, 0.1, 16, 0.9, 97.19692501442701, 35.58273394903667]\n",
      "[200, 0.1, 16, 1, 96.91081246558637, 35.446806573361144]\n",
      "[300, 0.001, 3, 0.6, 11.202901448642066, 11.225177301305866]\n",
      "[300, 0.001, 3, 0.7, 11.204243535886583, 11.2272870558632]\n",
      "[300, 0.001, 3, 0.8, 11.205427245730192, 11.23018752598577]\n",
      "[300, 0.001, 3, 0.9, 11.206986961535026, 11.232351191016853]\n",
      "[300, 0.001, 3, 1, 11.211416076931148, 11.238256325753138]\n",
      "[300, 0.001, 4, 0.6, 12.387134540460954, 12.410845979873864]\n",
      "[300, 0.001, 4, 0.7, 12.385398285259397, 12.409431380077008]\n",
      "[300, 0.001, 4, 0.8, 12.383863671674966, 12.408938361427758]\n",
      "[300, 0.001, 4, 0.9, 12.383215424102445, 12.409592107735513]\n",
      "[300, 0.001, 4, 1, 12.385562628263724, 12.412532266918463]\n",
      "[300, 0.001, 5, 0.6, 13.202986487346857, 13.216613263533416]\n",
      "[300, 0.001, 5, 0.7, 13.201948490630999, 13.216194980816166]\n",
      "[300, 0.001, 5, 0.8, 13.199467711951163, 13.214020499874069]\n",
      "[300, 0.001, 5, 0.9, 13.199147367030106, 13.214185566521708]\n",
      "[300, 0.001, 5, 1, 13.204583554375004, 13.219351213234221]\n",
      "[300, 0.001, 6, 0.6, 13.808732045008142, 13.808074873859544]\n",
      "[300, 0.001, 6, 0.7, 13.80365510908902, 13.803332270701352]\n",
      "[300, 0.001, 6, 0.8, 13.798091858604057, 13.7982530021175]\n",
      "[300, 0.001, 6, 0.9, 13.793396539655001, 13.793845310479158]\n",
      "[300, 0.001, 6, 1, 13.789350072107098, 13.79048185674796]\n",
      "[300, 0.001, 7, 0.6, 14.278075942133938, 14.259449825404369]\n",
      "[300, 0.001, 7, 0.7, 14.27167999931398, 14.25344491002386]\n",
      "[300, 0.001, 7, 0.8, 14.264587863857658, 14.246968335479748]\n",
      "[300, 0.001, 7, 0.9, 14.259204045491092, 14.241924530949124]\n",
      "[300, 0.001, 7, 1, 14.254771641052022, 14.235426294073827]\n",
      "[300, 0.001, 8, 0.6, 14.67651182535975, 14.627936777174423]\n",
      "[300, 0.001, 8, 0.7, 14.668534343340067, 14.619883415468449]\n",
      "[300, 0.001, 8, 0.8, 14.663164677693397, 14.614903998581298]\n",
      "[300, 0.001, 8, 0.9, 14.655800969144595, 14.606159029570499]\n",
      "[300, 0.001, 8, 1, 14.646191162409238, 14.596110360074388]\n",
      "[300, 0.001, 9, 0.6, 15.03769204535973, 14.93632426146403]\n",
      "[300, 0.001, 9, 0.7, 15.031327674874905, 14.930033195161164]\n",
      "[300, 0.001, 9, 0.8, 15.024853660437621, 14.922874741657067]\n",
      "[300, 0.001, 9, 0.9, 15.01624406007137, 14.91364360686932]\n",
      "[300, 0.001, 9, 1, 15.002612717015328, 14.90171397808263]\n",
      "[300, 0.001, 10, 0.6, 15.403391221194429, 15.199380428373843]\n",
      "[300, 0.001, 10, 0.7, 15.399804698272678, 15.197625756454503]\n",
      "[300, 0.001, 10, 0.8, 15.391245331331838, 15.187829072081893]\n",
      "[300, 0.001, 10, 0.9, 15.38159852823815, 15.177987007205529]\n",
      "[300, 0.001, 10, 1, 15.361862057952614, 15.157585859793887]\n",
      "[300, 0.001, 11, 0.6, 15.822671316271997, 15.425775166020294]\n",
      "[300, 0.001, 11, 0.7, 15.822158196663628, 15.425489388737823]\n",
      "[300, 0.001, 11, 0.8, 15.816322101536262, 15.417300815040546]\n",
      "[300, 0.001, 11, 0.9, 15.806576402486904, 15.408649239358407]\n",
      "[300, 0.001, 11, 1, 15.776384627196393, 15.387746709037964]\n",
      "[300, 0.001, 12, 0.6, 16.351794666454655, 15.616226466498706]\n",
      "[300, 0.001, 12, 0.7, 16.361280010983727, 15.618665846525348]\n",
      "[300, 0.001, 12, 0.8, 16.364480636666713, 15.613824154499357]\n",
      "[300, 0.001, 12, 0.9, 16.358262559616556, 15.604410180253403]\n",
      "[300, 0.001, 12, 1, 16.310215241435166, 15.573848681969382]\n",
      "[300, 0.001, 13, 0.6, 17.059081107193276, 15.768561635156697]\n",
      "[300, 0.001, 13, 0.7, 17.094787421909462, 15.777714332691694]\n",
      "[300, 0.001, 13, 0.8, 17.11771867133165, 15.778361675059715]\n",
      "[300, 0.001, 13, 0.9, 17.12503328205539, 15.771227922154907]\n",
      "[300, 0.001, 13, 1, 17.06277484062061, 15.72481146229473]\n",
      "[300, 0.001, 14, 0.6, 17.998741717501833, 15.877683149207556]\n",
      "[300, 0.001, 14, 0.7, 18.086790659901986, 15.896146105811415]\n",
      "[300, 0.001, 14, 0.8, 18.152375818918443, 15.90393564620104]\n",
      "[300, 0.001, 14, 0.9, 18.19270844920986, 15.900971851656776]\n",
      "[300, 0.001, 14, 1, 18.109539474198044, 15.822909416976705]\n",
      "[300, 0.001, 15, 0.6, 19.183111722795033, 15.930933143090842]\n",
      "[300, 0.001, 15, 0.7, 19.365366179760844, 15.957707528525123]\n",
      "[300, 0.001, 15, 0.8, 19.51248987101738, 15.978998011882284]\n",
      "[300, 0.001, 15, 0.9, 19.61925225726565, 15.980706601030725]\n",
      "[300, 0.001, 15, 1, 19.52558717186608, 15.864436618193366]\n",
      "[300, 0.001, 16, 0.6, 20.575523419641208, 15.917697456101775]\n",
      "[300, 0.001, 16, 0.7, 20.90225336698397, 15.959556313180578]\n",
      "[300, 0.001, 16, 0.8, 21.177768170028198, 15.991636361992667]\n",
      "[300, 0.001, 16, 0.9, 21.39354813215991, 16.003340119145427]\n",
      "[300, 0.001, 16, 1, 21.32072990219871, 15.812105107153407]\n",
      "[300, 0.01, 3, 0.6, 32.76082736675412, 32.81672134700507]\n",
      "[300, 0.01, 3, 0.7, 32.75330239747048, 32.80836736879774]\n",
      "[300, 0.01, 3, 0.8, 32.750819118673625, 32.80853878564517]\n",
      "[300, 0.01, 3, 0.9, 32.74820432185781, 32.806520723527086]\n",
      "[300, 0.01, 3, 1, 32.75578787924115, 32.81522770906717]\n",
      "[300, 0.01, 4, 0.6, 33.74957057531026, 33.764997524245985]\n",
      "[300, 0.01, 4, 0.7, 33.74729244257956, 33.76209048511326]\n",
      "[300, 0.01, 4, 0.8, 33.749953983113734, 33.76372643388258]\n",
      "[300, 0.01, 4, 0.9, 33.7465795246579, 33.76511509796435]\n",
      "[300, 0.01, 4, 1, 33.74840340332609, 33.763196134714626]\n",
      "[300, 0.01, 5, 0.6, 34.4696381119381, 34.42797932584277]\n",
      "[300, 0.01, 5, 0.7, 34.46780677807055, 34.4173820800215]\n",
      "[300, 0.01, 5, 0.8, 34.470761922185524, 34.41545336464431]\n",
      "[300, 0.01, 5, 0.9, 34.476216962042194, 34.424927727567066]\n",
      "[300, 0.01, 5, 1, 34.47742071872648, 34.41768970145597]\n",
      "[300, 0.01, 6, 0.6, 35.117239761359976, 34.93654594894397]\n",
      "[300, 0.01, 6, 0.7, 35.11928079434389, 34.93898895211752]\n",
      "[300, 0.01, 6, 0.8, 35.112648843344104, 34.922465706662024]\n",
      "[300, 0.01, 6, 0.9, 35.11177253350601, 34.92273157050529]\n",
      "[300, 0.01, 6, 1, 35.107439942288146, 34.91175444723594]\n",
      "[300, 0.01, 7, 0.6, 35.73492828194721, 35.37014846911583]\n",
      "[300, 0.01, 7, 0.7, 35.73846394922771, 35.365328748921655]\n",
      "[300, 0.01, 7, 0.8, 35.74370002040237, 35.365002083404015]\n",
      "[300, 0.01, 7, 0.9, 35.745187738563025, 35.35412360014904]\n",
      "[300, 0.01, 7, 1, 35.73704313699542, 35.33811364111582]\n",
      "[300, 0.01, 8, 0.6, 36.448860491094194, 35.752268543969954]\n",
      "[300, 0.01, 8, 0.7, 36.45429378595642, 35.74648417248116]\n",
      "[300, 0.01, 8, 0.8, 36.46422908759622, 35.73893772050546]\n",
      "[300, 0.01, 8, 0.9, 36.46465984942884, 35.7349095451615]\n",
      "[300, 0.01, 8, 1, 36.447262781016356, 35.705897719887425]\n",
      "[300, 0.01, 9, 0.6, 37.34998268841716, 36.102897921091035]\n",
      "[300, 0.01, 9, 0.7, 37.37420663051044, 36.100069899084296]\n",
      "[300, 0.01, 9, 0.8, 37.39594522417581, 36.087649051711644]\n",
      "[300, 0.01, 9, 0.9, 37.40030136843836, 36.087277625755156]\n",
      "[300, 0.01, 9, 1, 37.38874028696506, 36.05468530753917]\n",
      "[300, 0.01, 10, 0.6, 38.63832877567912, 36.455342011177635]\n",
      "[300, 0.01, 10, 0.7, 38.67042557196686, 36.43623944605926]\n",
      "[300, 0.01, 10, 0.8, 38.70480455971944, 36.427509809029004]\n",
      "[300, 0.01, 10, 0.9, 38.71802798615893, 36.40731520715139]\n",
      "[300, 0.01, 10, 1, 38.70630684484586, 36.371999239446176]\n",
      "[300, 0.01, 11, 0.6, 40.542797945241475, 36.760410411301635]\n",
      "[300, 0.01, 11, 0.7, 40.61358589477744, 36.74935327248959]\n",
      "[300, 0.01, 11, 0.8, 40.6607042256154, 36.73342517841057]\n",
      "[300, 0.01, 11, 0.9, 40.702777369417916, 36.725356106150144]\n",
      "[300, 0.01, 11, 1, 40.65985560272737, 36.62800369555982]\n",
      "[300, 0.01, 12, 0.6, 43.41526527956672, 37.02249240597077]\n",
      "[300, 0.01, 12, 0.7, 43.546385740358865, 37.008284073356194]\n",
      "[300, 0.01, 12, 0.8, 43.64313074967632, 37.007544346238184]\n",
      "[300, 0.01, 12, 0.9, 43.733853686487166, 36.98479335391936]\n",
      "[300, 0.01, 12, 1, 43.66187175032184, 36.8546322495097]\n",
      "[300, 0.01, 13, 0.6, 47.53815256177795, 37.2731082782406]\n",
      "[300, 0.01, 13, 0.7, 47.83209845718501, 37.23400106756127]\n",
      "[300, 0.01, 13, 0.8, 48.01567518822887, 37.2226822578699]\n",
      "[300, 0.01, 13, 0.9, 48.19130356461567, 37.19158286922926]\n",
      "[300, 0.01, 13, 1, 48.0784829400874, 36.942281938354945]\n",
      "[300, 0.01, 14, 0.6, 53.005605258878795, 37.427339126703274]\n",
      "[300, 0.01, 14, 0.7, 53.512102244855974, 37.379660522583414]\n",
      "[300, 0.01, 14, 0.8, 53.939926822844505, 37.363844233588125]\n",
      "[300, 0.01, 14, 0.9, 54.2243240378624, 37.33262459391247]\n",
      "[300, 0.01, 14, 1, 54.0684418781658, 36.956134157508124]\n",
      "[300, 0.01, 15, 0.6, 59.59516186072884, 37.490073093035036]\n",
      "[300, 0.01, 15, 0.7, 60.43338420981473, 37.43120125514214]\n",
      "[300, 0.01, 15, 0.8, 61.081255541748156, 37.437654591588995]\n",
      "[300, 0.01, 15, 0.9, 61.53826409360307, 37.34638274248927]\n",
      "[300, 0.01, 15, 1, 61.47759897493601, 36.82264230751549]\n",
      "[300, 0.01, 16, 0.6, 66.56365418771611, 37.49069237155558]\n",
      "[300, 0.01, 16, 0.7, 67.76514290477154, 37.439085230504446]\n",
      "[300, 0.01, 16, 0.8, 68.71658721453451, 37.428345704641764]\n",
      "[300, 0.01, 16, 0.9, 69.4471241157553, 37.3083077156846]\n",
      "[300, 0.01, 16, 1, 69.38212894755851, 36.51395365790796]\n",
      "[300, 0.1, 3, 0.6, 36.55006606675778, 36.434230942544374]\n",
      "[300, 0.1, 3, 0.7, 36.617403142776, 36.482292453353594]\n",
      "[300, 0.1, 3, 0.8, 36.615465343997364, 36.44971328153358]\n",
      "[300, 0.1, 3, 0.9, 36.58462426234858, 36.40322445814114]\n",
      "[300, 0.1, 3, 1, 36.524290955920094, 36.34626177025871]\n",
      "[300, 0.1, 4, 0.6, 37.28360976230485, 36.94627956077496]\n",
      "[300, 0.1, 4, 0.7, 37.33835430214152, 36.96023412135702]\n",
      "[300, 0.1, 4, 0.8, 37.38029164714164, 36.999606528071396]\n",
      "[300, 0.1, 4, 0.9, 37.45433976017139, 36.99688353828011]\n",
      "[300, 0.1, 4, 1, 37.424025029110496, 36.9605282487107]\n",
      "[300, 0.1, 5, 0.6, 38.02382267314489, 37.318394955774856]\n",
      "[300, 0.1, 5, 0.7, 38.09107184045273, 37.3542304580378]\n",
      "[300, 0.1, 5, 0.8, 38.15096899612285, 37.368347502994425]\n",
      "[300, 0.1, 5, 0.9, 38.24403110209048, 37.422594734339356]\n",
      "[300, 0.1, 5, 1, 38.24791759334077, 37.305596324708986]\n",
      "[300, 0.1, 6, 0.6, 38.93865410772405, 37.6190191817504]\n",
      "[300, 0.1, 6, 0.7, 39.03742053317013, 37.64328676116369]\n",
      "[300, 0.1, 6, 0.8, 39.10756056230223, 37.707966668288364]\n",
      "[300, 0.1, 6, 0.9, 39.21787239609481, 37.7280119401376]\n",
      "[300, 0.1, 6, 1, 39.35603439145298, 37.590619224038456]\n",
      "[300, 0.1, 7, 0.6, 40.307746797178076, 37.809748316624294]\n",
      "[300, 0.1, 7, 0.7, 40.44084826150684, 37.88931418505648]\n",
      "[300, 0.1, 7, 0.8, 40.530199773353345, 37.90693061785667]\n",
      "[300, 0.1, 7, 0.9, 40.67487298500932, 37.98750197357836]\n",
      "[300, 0.1, 7, 1, 40.908859318297544, 37.915695990099806]\n",
      "[300, 0.1, 8, 0.6, 42.53343875154143, 37.945191916307905]\n",
      "[300, 0.1, 8, 0.7, 42.70362467538122, 38.06363323534397]\n",
      "[300, 0.1, 8, 0.8, 42.78814034453079, 38.07575140043947]\n",
      "[300, 0.1, 8, 0.9, 42.986914240225694, 38.16402273030312]\n",
      "[300, 0.1, 8, 1, 43.298422778256594, 38.17415515095993]\n",
      "[300, 0.1, 9, 0.6, 46.1297129963483, 37.93320078977944]\n",
      "[300, 0.1, 9, 0.7, 46.33546707330313, 38.05205279491554]\n",
      "[300, 0.1, 9, 0.8, 46.54988441418128, 38.05991354411662]\n",
      "[300, 0.1, 9, 0.9, 46.735354173069446, 38.26282800286004]\n",
      "[300, 0.1, 9, 1, 47.053152142179954, 38.22989517687636]\n",
      "[300, 0.1, 10, 0.6, 51.727187492624715, 37.656593376627434]\n",
      "[300, 0.1, 10, 0.7, 52.05272792336603, 37.76124464292613]\n",
      "[300, 0.1, 10, 0.8, 52.26151515689712, 37.98020557758166]\n",
      "[300, 0.1, 10, 0.9, 52.60427785311015, 38.090641893665875]\n",
      "[300, 0.1, 10, 1, 52.78779773716688, 38.180789704079366]\n",
      "[300, 0.1, 11, 0.6, 59.592987287640575, 37.102486559601275]\n",
      "[300, 0.1, 11, 0.7, 60.113993840073164, 37.47318536514428]\n",
      "[300, 0.1, 11, 0.8, 60.49246721467294, 37.67102339463217]\n",
      "[300, 0.1, 11, 0.9, 60.784774791098386, 37.80451028948876]\n",
      "[300, 0.1, 11, 1, 60.7850248615621, 37.79233865759366]\n",
      "[300, 0.1, 12, 0.6, 69.56285806211045, 36.546815788085816]\n",
      "[300, 0.1, 12, 0.7, 70.24723125649395, 36.74386165958935]\n",
      "[300, 0.1, 12, 0.8, 70.66536696931256, 37.093943819426286]\n",
      "[300, 0.1, 12, 0.9, 70.98842274037725, 37.30583934214409]\n",
      "[300, 0.1, 12, 1, 71.10880652474725, 37.68980599612129]\n",
      "[300, 0.1, 13, 0.6, 80.35943534288307, 35.64548181367583]\n",
      "[300, 0.1, 13, 0.7, 81.00961886975861, 36.10530043575775]\n",
      "[300, 0.1, 13, 0.8, 81.51680915010931, 36.53521417466169]\n",
      "[300, 0.1, 13, 0.9, 81.78170467413514, 36.699786635468236]\n",
      "[300, 0.1, 13, 1, 81.26537006865962, 37.17134358535006]\n",
      "[300, 0.1, 14, 0.6, 89.5102011275961, 34.70220005075478]\n",
      "[300, 0.1, 14, 0.7, 90.25202156778151, 35.35337628369922]\n",
      "[300, 0.1, 14, 0.8, 90.66352714528747, 35.731075515646495]\n",
      "[300, 0.1, 14, 0.9, 90.98907379597215, 36.338130979803]\n",
      "[300, 0.1, 14, 1, 90.32705583355737, 36.404907604247484]\n",
      "[300, 0.1, 15, 0.6, 95.71016230312043, 34.32186519910127]\n",
      "[300, 0.1, 15, 0.7, 96.2076693413006, 34.85108822595063]\n",
      "[300, 0.1, 15, 0.8, 96.54966278216139, 35.325347277840315]\n",
      "[300, 0.1, 15, 0.9, 96.71383960851, 35.77557050721551]\n",
      "[300, 0.1, 15, 1, 96.15624518193499, 35.9800891650189]\n",
      "[300, 0.1, 16, 0.6, 98.65294611287553, 33.80834737778613]\n",
      "[300, 0.1, 16, 0.7, 98.92610546097742, 34.457318248210456]\n",
      "[300, 0.1, 16, 0.8, 99.08080705850065, 35.2899822571956]\n",
      "[300, 0.1, 16, 0.9, 99.15438777469943, 35.37144251453876]\n",
      "[300, 0.1, 16, 1, 98.95306095516084, 35.27568063163613]\n",
      "[400, 0.001, 3, 0.6, 13.89688280763517, 13.930492691003305]\n",
      "[400, 0.001, 3, 0.7, 13.89932627625785, 13.93377923949094]\n",
      "[400, 0.001, 3, 0.8, 13.904480930163754, 13.939491464284615]\n",
      "[400, 0.001, 3, 0.9, 13.906908067425494, 13.942431441211689]\n",
      "[400, 0.001, 3, 1, 13.916410541940694, 13.953137179888941]\n",
      "[400, 0.001, 4, 0.6, 15.287790295941228, 15.321207216484966]\n",
      "[400, 0.001, 4, 0.7, 15.28643523673151, 15.320285611226437]\n",
      "[400, 0.001, 4, 0.8, 15.285152437378112, 15.320569280979035]\n",
      "[400, 0.001, 4, 0.9, 15.285045155285049, 15.32070890643774]\n",
      "[400, 0.001, 4, 1, 15.294675124011103, 15.332633587962452]\n",
      "[400, 0.001, 5, 0.6, 16.253510522913338, 16.27222043571468]\n",
      "[400, 0.001, 5, 0.7, 16.25239784425704, 16.27205778027311]\n",
      "[400, 0.001, 5, 0.8, 16.250038466295237, 16.269341947621076]\n",
      "[400, 0.001, 5, 0.9, 16.248643639123173, 16.26885400696341]\n",
      "[400, 0.001, 5, 1, 16.249833130267387, 16.27071343151406]\n",
      "[400, 0.001, 6, 0.6, 16.964505859567247, 16.966948268155747]\n",
      "[400, 0.001, 6, 0.7, 16.959045159343965, 16.96142879389877]\n",
      "[400, 0.001, 6, 0.8, 16.95400408939006, 16.957080403244817]\n",
      "[400, 0.001, 6, 0.9, 16.951356006875816, 16.954681359230285]\n",
      "[400, 0.001, 6, 1, 16.953317873890196, 16.956259565266517]\n",
      "[400, 0.001, 7, 0.6, 17.505332540868412, 17.48434220936488]\n",
      "[400, 0.001, 7, 0.7, 17.500731954555437, 17.47949270235147]\n",
      "[400, 0.001, 7, 0.8, 17.492736174356306, 17.472391167874257]\n",
      "[400, 0.001, 7, 0.9, 17.48659726212569, 17.466739614406833]\n",
      "[400, 0.001, 7, 1, 17.485722451654485, 17.46317445244059]\n",
      "[400, 0.001, 8, 0.6, 17.981669706641778, 17.918469523564706]\n",
      "[400, 0.001, 8, 0.7, 17.97218132011007, 17.90808424571675]\n",
      "[400, 0.001, 8, 0.8, 17.96530063243209, 17.90165668642878]\n",
      "[400, 0.001, 8, 0.9, 17.956019474899154, 17.890602374414012]\n",
      "[400, 0.001, 8, 1, 17.947117342042574, 17.880974926589456]\n",
      "[400, 0.001, 9, 0.6, 18.422185851097705, 18.28817550205988]\n",
      "[400, 0.001, 9, 0.7, 18.41530937635696, 18.28081799732849]\n",
      "[400, 0.001, 9, 0.8, 18.405713076662387, 18.271095381057933]\n",
      "[400, 0.001, 9, 0.9, 18.3953111684386, 18.258457754013314]\n",
      "[400, 0.001, 9, 1, 18.380129933423273, 18.244496964542435]\n",
      "[400, 0.001, 10, 0.6, 18.87859944439345, 18.608547639237074]\n",
      "[400, 0.001, 10, 0.7, 18.8732278253399, 18.60431301417018]\n",
      "[400, 0.001, 10, 0.8, 18.86261790158811, 18.592827651402732]\n",
      "[400, 0.001, 10, 0.9, 18.849594556714166, 18.57778234575076]\n",
      "[400, 0.001, 10, 1, 18.824455252598682, 18.54926947964991]\n",
      "[400, 0.001, 11, 0.6, 19.409831345946984, 18.885199132440366]\n",
      "[400, 0.001, 11, 0.7, 19.407800387285036, 18.8811509957982]\n",
      "[400, 0.001, 11, 0.8, 19.39941555645559, 18.87078837870658]\n",
      "[400, 0.001, 11, 0.9, 19.385675819153334, 18.85694031597618]\n",
      "[400, 0.001, 11, 1, 19.34191030738255, 18.820025933549278]\n",
      "[400, 0.001, 12, 0.6, 20.08992931890692, 19.119609475381395]\n",
      "[400, 0.001, 12, 0.7, 20.100330986943014, 19.117838384529527]\n",
      "[400, 0.001, 12, 0.8, 20.102811248124052, 19.110350015657616]\n",
      "[400, 0.001, 12, 0.9, 20.0925399913759, 19.09462465826869]\n",
      "[400, 0.001, 12, 1, 20.02718836194395, 19.048568658032828]\n",
      "[400, 0.001, 13, 0.6, 21.005865105414212, 19.308847335715328]\n",
      "[400, 0.001, 13, 0.7, 21.04961323361537, 19.3149224854275]\n",
      "[400, 0.001, 13, 0.8, 21.075607849947442, 19.31295078240025]\n",
      "[400, 0.001, 13, 0.9, 21.081581914287707, 19.298432746602913]\n",
      "[400, 0.001, 13, 1, 20.997709277241018, 19.228890236677497]\n",
      "[400, 0.001, 14, 0.6, 22.227876495657426, 19.446768461862053]\n",
      "[400, 0.001, 14, 0.7, 22.338168988169382, 19.46467657982508]\n",
      "[400, 0.001, 14, 0.8, 22.416670086185952, 19.467816600836706]\n",
      "[400, 0.001, 14, 0.9, 22.46475660731553, 19.45841182996453]\n",
      "[400, 0.001, 14, 1, 22.35318124884588, 19.345784206639227]\n",
      "[400, 0.001, 15, 0.6, 23.76974428222286, 19.51985048476296]\n",
      "[400, 0.001, 15, 0.7, 23.997760367045107, 19.545005082862986]\n",
      "[400, 0.001, 15, 0.8, 24.179467933134536, 19.563017806646776]\n",
      "[400, 0.001, 15, 0.9, 24.30787022322951, 19.55710634860687]\n",
      "[400, 0.001, 15, 1, 24.178882245159595, 19.388646058120486]\n",
      "[400, 0.001, 16, 0.6, 25.577100227756887, 19.509811809956588]\n",
      "[400, 0.001, 16, 0.7, 25.986387019539325, 19.555252610536368]\n",
      "[400, 0.001, 16, 0.8, 26.329375173482806, 19.58574186281131]\n",
      "[400, 0.001, 16, 0.9, 26.5913340311558, 19.589184680254768]\n",
      "[400, 0.001, 16, 1, 26.478452110898587, 19.312988694214827]\n",
      "[400, 0.01, 3, 0.6, 33.79010226647778, 33.83484564699364]\n",
      "[400, 0.01, 3, 0.7, 33.78444540898492, 33.829343789358454]\n",
      "[400, 0.01, 3, 0.8, 33.78344616162331, 33.83121414143277]\n",
      "[400, 0.01, 3, 0.9, 33.77912441141391, 33.82529669501475]\n",
      "[400, 0.01, 3, 1, 33.78508050756244, 33.832601391141004]\n",
      "[400, 0.01, 4, 0.6, 34.62590382517878, 34.61116455633749]\n",
      "[400, 0.01, 4, 0.7, 34.617861629861714, 34.60341963964429]\n",
      "[400, 0.01, 4, 0.8, 34.624844289978654, 34.60903206936384]\n",
      "[400, 0.01, 4, 0.9, 34.62546452615371, 34.61044489366668]\n",
      "[400, 0.01, 4, 1, 34.62585531182749, 34.60616358106476]\n",
      "[400, 0.01, 5, 0.6, 35.27823191834263, 35.18172690699114]\n",
      "[400, 0.01, 5, 0.7, 35.281276581816186, 35.17979375542145]\n",
      "[400, 0.01, 5, 0.8, 35.29204787190686, 35.179951330288084]\n",
      "[400, 0.01, 5, 0.9, 35.290834861580024, 35.17784118931726]\n",
      "[400, 0.01, 5, 1, 35.285737912892, 35.17002314444658]\n",
      "[400, 0.01, 6, 0.6, 35.91392266880851, 35.643147496356086]\n",
      "[400, 0.01, 6, 0.7, 35.909608474479626, 35.63905626317896]\n",
      "[400, 0.01, 6, 0.8, 35.91549962883656, 35.63219100860078]\n",
      "[400, 0.01, 6, 0.9, 35.91658653557482, 35.629028651709916]\n",
      "[400, 0.01, 6, 1, 35.90834787227693, 35.61776485107766]\n",
      "[400, 0.01, 7, 0.6, 36.547636610855214, 36.029827966017244]\n",
      "[400, 0.01, 7, 0.7, 36.55268573892795, 36.02831126783305]\n",
      "[400, 0.01, 7, 0.8, 36.569770044066864, 36.04039197068841]\n",
      "[400, 0.01, 7, 0.9, 36.57915615051323, 36.02893661254549]\n",
      "[400, 0.01, 7, 1, 36.57448082326636, 36.01568198784555]\n",
      "[400, 0.01, 8, 0.6, 37.32368116207879, 36.3907685526562]\n",
      "[400, 0.01, 8, 0.7, 37.340632575409096, 36.38991007963851]\n",
      "[400, 0.01, 8, 0.8, 37.357256399096116, 36.38116878760631]\n",
      "[400, 0.01, 8, 0.9, 37.36898675205632, 36.383446679385486]\n",
      "[400, 0.01, 8, 1, 37.35777972890105, 36.360366353680796]\n",
      "[400, 0.01, 9, 0.6, 38.359065807523365, 36.71693620130385]\n",
      "[400, 0.01, 9, 0.7, 38.39200438858864, 36.71967610092995]\n",
      "[400, 0.01, 9, 0.8, 38.42583452987799, 36.71132583007816]\n",
      "[400, 0.01, 9, 0.9, 38.440315953955576, 36.705223450199696]\n",
      "[400, 0.01, 9, 1, 38.44236575658505, 36.68723302852987]\n",
      "[400, 0.01, 10, 0.6, 39.888902134329626, 37.04762284949752]\n",
      "[400, 0.01, 10, 0.7, 39.939824959014956, 37.0282754805611]\n",
      "[400, 0.01, 10, 0.8, 39.989100764415696, 37.02077515548744]\n",
      "[400, 0.01, 10, 0.9, 40.02436808627413, 37.01143663382918]\n",
      "[400, 0.01, 10, 1, 40.00452650158244, 36.96879418831887]\n",
      "[400, 0.01, 11, 0.6, 42.20363622814619, 37.32474040773002]\n",
      "[400, 0.01, 11, 0.7, 42.30516661152003, 37.31935922114331]\n",
      "[400, 0.01, 11, 0.8, 42.38586315789655, 37.30815790361866]\n",
      "[400, 0.01, 11, 0.9, 42.45275831221447, 37.290524174289075]\n",
      "[400, 0.01, 11, 1, 42.40918210537878, 37.17549234089784]\n",
      "[400, 0.01, 12, 0.6, 45.690652089731564, 37.55630727843765]\n",
      "[400, 0.01, 12, 0.7, 45.86254889931819, 37.555107903712624]\n",
      "[400, 0.01, 12, 0.8, 46.018802227844915, 37.55252526489416]\n",
      "[400, 0.01, 12, 0.9, 46.155676432956184, 37.52910782769757]\n",
      "[400, 0.01, 12, 1, 46.09165349691211, 37.386878657953304]\n",
      "[400, 0.01, 13, 0.6, 50.61593268249658, 37.800505121909175]\n",
      "[400, 0.01, 13, 0.7, 50.97445052422949, 37.750153048430555]\n",
      "[400, 0.01, 13, 0.8, 51.24126933914299, 37.73263477599797]\n",
      "[400, 0.01, 13, 0.9, 51.449945636534025, 37.71888423056758]\n",
      "[400, 0.01, 13, 1, 51.3719367165572, 37.438406483459964]\n",
      "[400, 0.01, 14, 0.6, 57.00619015214379, 37.91106466909645]\n",
      "[400, 0.01, 14, 0.7, 57.61476534904237, 37.88269524846921]\n",
      "[400, 0.01, 14, 0.8, 58.126756522801706, 37.86482765354262]\n",
      "[400, 0.01, 14, 0.9, 58.462882887137546, 37.847163754958835]\n",
      "[400, 0.01, 14, 1, 58.40413322028566, 37.39845299598641]\n",
      "[400, 0.01, 15, 0.6, 64.41791909274059, 37.952400010080154]\n",
      "[400, 0.01, 15, 0.7, 65.38816771656724, 37.91073344370864]\n",
      "[400, 0.01, 15, 0.8, 66.07275011731808, 37.904076611475666]\n",
      "[400, 0.01, 15, 0.9, 66.67514806621908, 37.8174579155806]\n",
      "[400, 0.01, 15, 1, 66.70564393843193, 37.22075247231036]\n",
      "[400, 0.01, 16, 0.6, 71.9024580557013, 37.911509596749994]\n",
      "[400, 0.01, 16, 0.7, 73.21818678881206, 37.858529819446176]\n",
      "[400, 0.01, 16, 0.8, 74.23857084892045, 37.8475468163045]\n",
      "[400, 0.01, 16, 0.9, 75.06923447065286, 37.718705747914704]\n",
      "[400, 0.01, 16, 1, 75.08195663195704, 36.857616185107844]\n",
      "[400, 0.1, 3, 0.6, 36.78752482796098, 36.63360657295378]\n",
      "[400, 0.1, 3, 0.7, 36.848975539077614, 36.6814469547658]\n",
      "[400, 0.1, 3, 0.8, 36.90636161982529, 36.70628517199147]\n",
      "[400, 0.1, 3, 0.9, 36.94415100189731, 36.711577521938224]\n",
      "[400, 0.1, 3, 1, 36.79091563505506, 36.543769254012226]\n",
      "[400, 0.1, 4, 0.6, 37.521834181322376, 37.10792479265734]\n",
      "[400, 0.1, 4, 0.7, 37.57381696671837, 37.12582613738265]\n",
      "[400, 0.1, 4, 0.8, 37.64953814315505, 37.17979417968363]\n",
      "[400, 0.1, 4, 0.9, 37.736173725500336, 37.18695559456374]\n",
      "[400, 0.1, 4, 1, 37.76401063591963, 37.159621083302476]\n",
      "[400, 0.1, 5, 0.6, 38.30233032151895, 37.445034211029906]\n",
      "[400, 0.1, 5, 0.7, 38.38763329148783, 37.48847948806585]\n",
      "[400, 0.1, 5, 0.8, 38.469786193812624, 37.52446017769735]\n",
      "[400, 0.1, 5, 0.9, 38.58220318060776, 37.56562627086857]\n",
      "[400, 0.1, 5, 1, 38.68448905572477, 37.48150749926778]\n",
      "[400, 0.1, 6, 0.6, 39.368932818451185, 37.732060881905646]\n",
      "[400, 0.1, 6, 0.7, 39.470239563067565, 37.76037276411307]\n",
      "[400, 0.1, 6, 0.8, 39.564645590559635, 37.822206136028235]\n",
      "[400, 0.1, 6, 0.9, 39.69746515898866, 37.85922863696164]\n",
      "[400, 0.1, 6, 1, 39.96016337155268, 37.77847091573465]\n",
      "[400, 0.1, 7, 0.6, 41.00321543083323, 37.88571925929233]\n",
      "[400, 0.1, 7, 0.7, 41.15536224831317, 37.963130667174006]\n",
      "[400, 0.1, 7, 0.8, 41.25617255567663, 37.97605867126469]\n",
      "[400, 0.1, 7, 0.9, 41.42450147632456, 38.075766182486916]\n",
      "[400, 0.1, 7, 1, 41.73394252674174, 38.05284486334147]\n",
      "[400, 0.1, 8, 0.6, 43.72254694924344, 37.97511060671689]\n",
      "[400, 0.1, 8, 0.7, 43.91291137609266, 38.07914929263908]\n",
      "[400, 0.1, 8, 0.8, 44.0407856121926, 38.11309932455349]\n",
      "[400, 0.1, 8, 0.9, 44.251617367436715, 38.228316862013465]\n",
      "[400, 0.1, 8, 1, 44.62366399334577, 38.197718939502614]\n",
      "[400, 0.1, 9, 0.6, 48.07672265191781, 37.86031656698713]\n",
      "[400, 0.1, 9, 0.7, 48.34185282250488, 38.02640745125092]\n",
      "[400, 0.1, 9, 0.8, 48.59830332458598, 38.00990493377463]\n",
      "[400, 0.1, 9, 0.9, 48.80434581428167, 38.21943666268359]\n",
      "[400, 0.1, 9, 1, 49.14820327199207, 38.19435308674599]\n",
      "[400, 0.1, 10, 0.6, 54.76702751737914, 37.43089030505797]\n",
      "[400, 0.1, 10, 0.7, 55.154480511046685, 37.58545414483107]\n",
      "[400, 0.1, 10, 0.8, 55.409633407380554, 37.83542897388682]\n",
      "[400, 0.1, 10, 0.9, 55.69737141508624, 37.95044358521126]\n",
      "[400, 0.1, 10, 1, 55.890189778743604, 38.07826646453859]\n",
      "[400, 0.1, 11, 0.6, 63.87725849189716, 36.711930250712946]\n",
      "[400, 0.1, 11, 0.7, 64.41072892354846, 37.14198400508596]\n",
      "[400, 0.1, 11, 0.8, 64.78408707021384, 37.37493309346526]\n",
      "[400, 0.1, 11, 0.9, 65.07588447229548, 37.557192521249185]\n",
      "[400, 0.1, 11, 1, 64.95040759737142, 37.62397629709411]\n",
      "[400, 0.1, 12, 0.6, 74.70539248982739, 36.021095588303645]\n",
      "[400, 0.1, 12, 0.7, 75.36408425352631, 36.289823639130404]\n",
      "[400, 0.1, 12, 0.8, 75.83215737456804, 36.72992424471231]\n",
      "[400, 0.1, 12, 0.9, 76.04292615905965, 37.00252059098067]\n",
      "[400, 0.1, 12, 1, 75.79341593282395, 37.41752750115983]\n",
      "[400, 0.1, 13, 0.6, 85.45091105554896, 35.01279005274651]\n",
      "[400, 0.1, 13, 0.7, 86.09224767144536, 35.598561273296205]\n",
      "[400, 0.1, 13, 0.8, 86.48314945999937, 36.11510747609206]\n",
      "[400, 0.1, 13, 0.9, 86.67385907032208, 36.287453032640094]\n",
      "[400, 0.1, 13, 1, 86.0739425929553, 36.84720332292033]\n",
      "[400, 0.1, 14, 0.6, 93.50213657018635, 34.21646050094442]\n",
      "[400, 0.1, 14, 0.7, 94.02119189970776, 34.90589683861786]\n",
      "[400, 0.1, 14, 0.8, 94.33611748429003, 35.36889970950173]\n",
      "[400, 0.1, 14, 0.9, 94.52443897716033, 35.99894943999086]\n",
      "[400, 0.1, 14, 1, 93.86038439129801, 36.141171220422684]\n",
      "[400, 0.1, 15, 0.6, 97.93134308227013, 33.97962036919672]\n",
      "[400, 0.1, 15, 0.7, 98.22837908426828, 34.571850672380535]\n",
      "[400, 0.1, 15, 0.8, 98.40112407633127, 35.068287261746256]\n",
      "[400, 0.1, 15, 0.9, 98.48296252262823, 35.54887406042722]\n",
      "[400, 0.1, 15, 1, 98.06766981290377, 35.79414304021435]\n",
      "[400, 0.1, 16, 0.6, 99.53056493816835, 33.630710899143104]\n",
      "[400, 0.1, 16, 0.7, 99.64568350039977, 34.30662049011676]\n",
      "[400, 0.1, 16, 0.8, 99.70534331640192, 35.180208546056214]\n",
      "[400, 0.1, 16, 0.9, 99.7291199439457, 35.265221706864565]\n",
      "[400, 0.1, 16, 1, 99.61849215341556, 35.16155114776347]\n",
      "[500, 0.001, 3, 0.6, 16.22032182994483, 16.262776473035025]\n",
      "[500, 0.001, 3, 0.7, 16.2171714537076, 16.259527605669167]\n",
      "[500, 0.001, 3, 0.8, 16.22528670316542, 16.268541903120703]\n",
      "[500, 0.001, 3, 0.9, 16.226041112273393, 16.26874323294073]\n",
      "[500, 0.001, 3, 1, 16.231294656988815, 16.274616356169304]\n",
      "[500, 0.001, 4, 0.6, 17.75272121862168, 17.794168726519498]\n",
      "[500, 0.001, 4, 0.7, 17.753102154709154, 17.79494995983686]\n",
      "[500, 0.001, 4, 0.8, 17.754409362722555, 17.796705797427247]\n",
      "[500, 0.001, 4, 0.9, 17.753961792755213, 17.796437162806956]\n",
      "[500, 0.001, 4, 1, 17.764380728544182, 17.809299977101745]\n",
      "[500, 0.001, 5, 0.6, 18.818061701748036, 18.842027782243733]\n",
      "[500, 0.001, 5, 0.7, 18.815772436424094, 18.840467119834734]\n",
      "[500, 0.001, 5, 0.8, 18.813693704990563, 18.838571023416062]\n",
      "[500, 0.001, 5, 0.9, 18.813861444746248, 18.8395463532534]\n",
      "[500, 0.001, 5, 1, 18.82326593193736, 18.848880767075336]\n",
      "[500, 0.001, 6, 0.6, 19.605956065358033, 19.610456475011283]\n",
      "[500, 0.001, 6, 0.7, 19.60063436348539, 19.60512653226518]\n",
      "[500, 0.001, 6, 0.8, 19.59751304257423, 19.60337897546568]\n",
      "[500, 0.001, 6, 0.9, 19.59730818123232, 19.603480488621727]\n",
      "[500, 0.001, 6, 1, 19.603133586132216, 19.609720188483102]\n",
      "[500, 0.001, 7, 0.6, 20.213662309617852, 20.190979584052116]\n",
      "[500, 0.001, 7, 0.7, 20.20898848489846, 20.186199008814388]\n",
      "[500, 0.001, 7, 0.8, 20.201226801847007, 20.178980040599814]\n",
      "[500, 0.001, 7, 0.9, 20.196259752804067, 20.174326402783404]\n",
      "[500, 0.001, 7, 1, 20.196891186774046, 20.172060496137934]\n",
      "[500, 0.001, 8, 0.6, 20.73711689063358, 20.66006149071805]\n",
      "[500, 0.001, 8, 0.7, 20.727463317703698, 20.64934457149582]\n",
      "[500, 0.001, 8, 0.8, 20.719858967462535, 20.64177510479621]\n",
      "[500, 0.001, 8, 0.9, 20.710075667384263, 20.629564746261508]\n",
      "[500, 0.001, 8, 1, 20.70280983355408, 20.622494635606248]\n",
      "[500, 0.001, 9, 0.6, 21.235933507371342, 21.068952065028455]\n",
      "[500, 0.001, 9, 0.7, 21.225994922017975, 21.057633271522423]\n",
      "[500, 0.001, 9, 0.8, 21.213676224157407, 21.04399986654919]\n",
      "[500, 0.001, 9, 0.9, 21.20200242982572, 21.030449647105698]\n",
      "[500, 0.001, 9, 1, 21.18444250622752, 21.012729250129237]\n",
      "[500, 0.001, 10, 0.6, 21.76805551155233, 21.431656208576943]\n",
      "[500, 0.001, 10, 0.7, 21.760243985079754, 21.42334200232302]\n",
      "[500, 0.001, 10, 0.8, 21.747688469307104, 21.409614705484604]\n",
      "[500, 0.001, 10, 0.9, 21.730788665024605, 21.39112199860381]\n",
      "[500, 0.001, 10, 1, 21.70154632667044, 21.35808711383529]\n",
      "[500, 0.001, 11, 0.6, 22.40054026970848, 21.747701107125472]\n",
      "[500, 0.001, 11, 0.7, 22.3966706657875, 21.740007996248455]\n",
      "[500, 0.001, 11, 0.8, 22.38596419661798, 21.72673749956108]\n",
      "[500, 0.001, 11, 0.9, 22.36802354009111, 21.7085630051147]\n",
      "[500, 0.001, 11, 1, 22.31844572144357, 21.663591426518657]\n",
      "[500, 0.001, 12, 0.6, 23.221092135648615, 22.01733711735734]\n",
      "[500, 0.001, 12, 0.7, 23.232513586828908, 22.01267563511674]\n",
      "[500, 0.001, 12, 0.8, 23.233493987086117, 22.00241673730854]\n",
      "[500, 0.001, 12, 0.9, 23.21986263131247, 21.979364083405372]\n",
      "[500, 0.001, 12, 1, 23.140042262531303, 21.919976648690454]\n",
      "[500, 0.001, 13, 0.6, 24.33455527944952, 22.23816358217978]\n",
      "[500, 0.001, 13, 0.7, 24.385329423579872, 22.24099203278903]\n",
      "[500, 0.001, 13, 0.8, 24.413652578978674, 22.235934144720247]\n",
      "[500, 0.001, 13, 0.9, 24.418326579806205, 22.213357675765653]\n",
      "[500, 0.001, 13, 1, 24.310703366441178, 22.11729343456038]\n",
      "[500, 0.001, 14, 0.6, 25.82561890861529, 22.400270562560564]\n",
      "[500, 0.001, 14, 0.7, 25.95558085215437, 22.416378719760644]\n",
      "[500, 0.001, 14, 0.8, 26.045344894543433, 22.415385456672887]\n",
      "[500, 0.001, 14, 0.9, 26.098752578858996, 22.397006980487653]\n",
      "[500, 0.001, 14, 1, 25.960842761523317, 22.248185526282782]\n",
      "[500, 0.001, 15, 0.6, 27.706284969672655, 22.490004633717952]\n",
      "[500, 0.001, 15, 0.7, 27.974991107400747, 22.514230168899406]\n",
      "[500, 0.001, 15, 0.8, 28.186327628972784, 22.526837580490643]\n",
      "[500, 0.001, 15, 0.9, 28.333609082041512, 22.51366560344198]\n",
      "[500, 0.001, 15, 1, 28.172918956517613, 22.301068143318915]\n",
      "[500, 0.001, 16, 0.6, 29.906733911899497, 22.49003508318258]\n",
      "[500, 0.001, 16, 0.7, 30.387032329873286, 22.53485144226466]\n",
      "[500, 0.001, 16, 0.8, 30.785281994972703, 22.56049562526401]\n",
      "[500, 0.001, 16, 0.9, 31.091622821989883, 22.55514387579819]\n",
      "[500, 0.001, 16, 1, 30.952993303983522, 22.224365128963562]\n",
      "[500, 0.01, 3, 0.6, 34.35880122339642, 34.387026371333704]\n",
      "[500, 0.01, 3, 0.7, 34.35183518704271, 34.37962541299326]\n",
      "[500, 0.01, 3, 0.8, 34.34951603009926, 34.38072306078972]\n",
      "[500, 0.01, 3, 0.9, 34.33946919351077, 34.36954631992501]\n",
      "[500, 0.01, 3, 1, 34.34462246263088, 34.37677553984464]\n",
      "[500, 0.01, 4, 0.6, 35.126019962004186, 35.08035723628274]\n",
      "[500, 0.01, 4, 0.7, 35.11497157503829, 35.06851958744412]\n",
      "[500, 0.01, 4, 0.8, 35.11821092401465, 35.07190346368454]\n",
      "[500, 0.01, 4, 0.9, 35.12497307889794, 35.07836662138494]\n",
      "[500, 0.01, 4, 1, 35.118205507099375, 35.062744378659396]\n",
      "[500, 0.01, 5, 0.6, 35.763747241327025, 35.61744884149141]\n",
      "[500, 0.01, 5, 0.7, 35.76176850942239, 35.607705023195656]\n",
      "[500, 0.01, 5, 0.8, 35.77593843097869, 35.61018555125099]\n",
      "[500, 0.01, 5, 0.9, 35.776328683977056, 35.61176235433273]\n",
      "[500, 0.01, 5, 1, 35.76520229433162, 35.5966296143017]\n",
      "[500, 0.01, 6, 0.6, 36.394850520798414, 36.04961282645497]\n",
      "[500, 0.01, 6, 0.7, 36.39374873701618, 36.042186372841314]\n",
      "[500, 0.01, 6, 0.8, 36.40684543227789, 36.04133600291226]\n",
      "[500, 0.01, 6, 0.9, 36.40536699882272, 36.03665203733173]\n",
      "[500, 0.01, 6, 1, 36.40131444161479, 36.02741280441075]\n",
      "[500, 0.01, 7, 0.6, 37.05375988808252, 36.41032261947495]\n",
      "[500, 0.01, 7, 0.7, 37.07129242605309, 36.420867776086894]\n",
      "[500, 0.01, 7, 0.8, 37.0921235032579, 36.43033053333921]\n",
      "[500, 0.01, 7, 0.9, 37.10830743752144, 36.42345314558916]\n",
      "[500, 0.01, 7, 1, 37.090333437439185, 36.399162666096565]\n",
      "[500, 0.01, 8, 0.6, 37.8997720267273, 36.763396457806394]\n",
      "[500, 0.01, 8, 0.7, 37.92805779649788, 36.77297404878046]\n",
      "[500, 0.01, 8, 0.8, 37.944169386266005, 36.761296195306116]\n",
      "[500, 0.01, 8, 0.9, 37.966667031067544, 36.76453676999542]\n",
      "[500, 0.01, 8, 1, 37.95098772132642, 36.73777617796663]\n",
      "[500, 0.01, 9, 0.6, 39.07134719714931, 37.07669899967435]\n",
      "[500, 0.01, 9, 0.7, 39.11229819035744, 37.089741000692925]\n",
      "[500, 0.01, 9, 0.8, 39.15003159376313, 37.07904534905758]\n",
      "[500, 0.01, 9, 0.9, 39.17785494357968, 37.08100651402598]\n",
      "[500, 0.01, 9, 1, 39.17138920578677, 37.058918431156144]\n",
      "[500, 0.01, 10, 0.6, 40.83219059795905, 37.393652526615284]\n",
      "[500, 0.01, 10, 0.7, 40.90148576246106, 37.386466294000044]\n",
      "[500, 0.01, 10, 0.8, 40.963013827016795, 37.37655850613976]\n",
      "[500, 0.01, 10, 0.9, 41.01345864915218, 37.375767847698214]\n",
      "[500, 0.01, 10, 1, 40.98963909750991, 37.340016054964174]\n",
      "[500, 0.01, 11, 0.6, 43.544470693305136, 37.66977310183244]\n",
      "[500, 0.01, 11, 0.7, 43.665279510575914, 37.6660990836906]\n",
      "[500, 0.01, 11, 0.8, 43.776263460134224, 37.66910659644241]\n",
      "[500, 0.01, 11, 0.9, 43.86441698753464, 37.65009383194634]\n",
      "[500, 0.01, 11, 1, 43.834152156300355, 37.54366657527633]\n",
      "[500, 0.01, 12, 0.6, 47.59175195376271, 37.898630132543886]\n",
      "[500, 0.01, 12, 0.7, 47.81520908144712, 37.898551112483744]\n",
      "[500, 0.01, 12, 0.8, 48.01530997365209, 37.89617159105633]\n",
      "[500, 0.01, 12, 0.9, 48.176870032778595, 37.86527366664001]\n",
      "[500, 0.01, 12, 1, 48.14287694358907, 37.72043583558802]\n",
      "[500, 0.01, 13, 0.6, 53.245178945026474, 38.12599615621569]\n",
      "[500, 0.01, 13, 0.7, 53.64690868158344, 38.08373465413567]\n",
      "[500, 0.01, 13, 0.8, 53.97466956566516, 38.06250295758339]\n",
      "[500, 0.01, 13, 0.9, 54.23687627371552, 38.05512549964056]\n",
      "[500, 0.01, 13, 1, 54.12079650404902, 37.724413439599225]\n",
      "[500, 0.01, 14, 0.6, 60.3714161743504, 38.22371197205072]\n",
      "[500, 0.01, 14, 0.7, 61.025138769368105, 38.19417729918403]\n",
      "[500, 0.01, 14, 0.8, 61.61897443899469, 38.173559906835955]\n",
      "[500, 0.01, 14, 0.9, 61.992241811666325, 38.155087871539806]\n",
      "[500, 0.01, 14, 1, 61.87321214856492, 37.683890115522836]\n",
      "[500, 0.01, 15, 0.6, 68.3049273740729, 38.24876404157119]\n",
      "[500, 0.01, 15, 0.7, 69.3522694912714, 38.205214769994086]\n",
      "[500, 0.01, 15, 0.8, 70.09428043902845, 38.18586469237049]\n",
      "[500, 0.01, 15, 0.9, 70.72132512490634, 38.10868553954606]\n",
      "[500, 0.01, 15, 1, 70.73413536491417, 37.49659288032338]\n",
      "[500, 0.01, 16, 0.6, 76.04826633244838, 38.15376726672258]\n",
      "[500, 0.01, 16, 0.7, 77.38061755234477, 38.104687324086406]\n",
      "[500, 0.01, 16, 0.8, 78.41954149286994, 38.11679317508836]\n",
      "[500, 0.01, 16, 0.9, 79.2708926699959, 37.977616100269984]\n",
      "[500, 0.01, 16, 1, 79.2246162475475, 37.063287158782096]\n",
      "[500, 0.1, 3, 0.6, 36.95016298827498, 36.765555288701826]\n",
      "[500, 0.1, 3, 0.7, 37.00808088280637, 36.80229632075459]\n",
      "[500, 0.1, 3, 0.8, 37.08065006607335, 36.84027091125069]\n",
      "[500, 0.1, 3, 0.9, 37.14253914257951, 36.86562744104938]\n",
      "[500, 0.1, 3, 1, 37.03848269919065, 36.719366226602155]\n",
      "[500, 0.1, 4, 0.6, 37.69632495695079, 37.218880113244026]\n",
      "[500, 0.1, 4, 0.7, 37.747290204128944, 37.231624654480235]\n",
      "[500, 0.1, 4, 0.8, 37.847777425224436, 37.30298134566753]\n",
      "[500, 0.1, 4, 0.9, 37.94700394406707, 37.315855869195346]\n",
      "[500, 0.1, 4, 1, 38.02297173035711, 37.28800882634003]\n",
      "[500, 0.1, 5, 0.6, 38.53326499199488, 37.525095913868554]\n",
      "[500, 0.1, 5, 0.7, 38.62157499251359, 37.57767341227633]\n",
      "[500, 0.1, 5, 0.8, 38.72587494091735, 37.62905896360618]\n",
      "[500, 0.1, 5, 0.9, 38.854821597913855, 37.66016969377911]\n",
      "[500, 0.1, 5, 1, 39.06224854687977, 37.63598328525782]\n",
      "[500, 0.1, 6, 0.6, 39.7293793907195, 37.79494862007638]\n",
      "[500, 0.1, 6, 0.7, 39.828506050127054, 37.826629418702005]\n",
      "[500, 0.1, 6, 0.8, 39.948200436930534, 37.89588440681339]\n",
      "[500, 0.1, 6, 0.9, 40.09839700191864, 37.93291359885421]\n",
      "[500, 0.1, 6, 1, 40.43077352812867, 37.88844808759849]\n",
      "[500, 0.1, 7, 0.6, 41.61207747093102, 37.924484369496334]\n",
      "[500, 0.1, 7, 0.7, 41.78176314818458, 38.005359014412655]\n",
      "[500, 0.1, 7, 0.8, 41.91056922697819, 38.00976050940888]\n",
      "[500, 0.1, 7, 0.9, 42.10196820361097, 38.12617502077745]\n",
      "[500, 0.1, 7, 1, 42.46326496130172, 38.11548708353718]\n",
      "[500, 0.1, 8, 0.6, 44.78236168939299, 37.935434005672796]\n",
      "[500, 0.1, 8, 0.7, 45.00006615080806, 38.07545713967484]\n",
      "[500, 0.1, 8, 0.8, 45.16343104942416, 38.0967420357602]\n",
      "[500, 0.1, 8, 0.9, 45.398173930452266, 38.22604542497435]\n",
      "[500, 0.1, 8, 1, 45.80125920390682, 38.23183425394468]\n",
      "[500, 0.1, 9, 0.6, 49.8437227092227, 37.78145423241618]\n",
      "[500, 0.1, 9, 0.7, 50.14911790408711, 37.920404162724545]\n",
      "[500, 0.1, 9, 0.8, 50.41793565092956, 37.908860486109056]\n",
      "[500, 0.1, 9, 0.9, 50.662574115859194, 38.15620018521121]\n",
      "[500, 0.1, 9, 1, 51.03227004524315, 38.134553451335954]\n",
      "[500, 0.1, 10, 0.6, 57.43041602888624, 37.23377945173698]\n",
      "[500, 0.1, 10, 0.7, 57.87153688109436, 37.397168876653396]\n",
      "[500, 0.1, 10, 0.8, 58.15667071525738, 37.6566622079206]\n",
      "[500, 0.1, 10, 0.9, 58.47099468691044, 37.81479914365286]\n",
      "[500, 0.1, 10, 1, 58.66145073868314, 37.9029313146691]\n",
      "[500, 0.1, 11, 0.6, 67.45536677413718, 36.37296960867009]\n",
      "[500, 0.1, 11, 0.7, 68.03734567775011, 36.8359079771539]\n",
      "[500, 0.1, 11, 0.8, 68.42602934004721, 37.112895413457245]\n",
      "[500, 0.1, 11, 0.9, 68.7117844002068, 37.31464120354472]\n",
      "[500, 0.1, 11, 1, 68.52909951237616, 37.42033683901539]\n",
      "[500, 0.1, 12, 0.6, 78.74271335935678, 35.563069744425356]\n",
      "[500, 0.1, 12, 0.7, 79.3746172952543, 35.89248520647838]\n",
      "[500, 0.1, 12, 0.8, 79.8296809238245, 36.378519987339764]\n",
      "[500, 0.1, 12, 0.9, 80.02841092659231, 36.70415116207968]\n",
      "[500, 0.1, 12, 1, 79.73566158121558, 37.17541909466093]\n",
      "[500, 0.1, 13, 0.6, 89.07968776922185, 34.54502238873898]\n",
      "[500, 0.1, 13, 0.7, 89.63215047302754, 35.174210566862705]\n",
      "[500, 0.1, 13, 0.8, 89.9496450837868, 35.742270306669695]\n",
      "[500, 0.1, 13, 0.9, 90.10338559793738, 35.96281449603952]\n",
      "[500, 0.1, 13, 1, 89.48356161547136, 36.527824062016954]\n",
      "[500, 0.1, 14, 0.6, 95.88733270141113, 33.88635368337369]\n",
      "[500, 0.1, 14, 0.7, 96.24989117923975, 34.58511896101976]\n",
      "[500, 0.1, 14, 0.8, 96.48895438989753, 35.06980322878476]\n",
      "[500, 0.1, 14, 0.9, 96.60007249991047, 35.73696745794373]\n",
      "[500, 0.1, 14, 1, 96.04482827762315, 35.916554847352636]\n",
      "[500, 0.1, 15, 0.6, 98.9671620171484, 33.79254287306516]\n",
      "[500, 0.1, 15, 0.7, 99.12939269353616, 34.41331405416592]\n",
      "[500, 0.1, 15, 0.8, 99.23405843776443, 34.90693581205592]\n",
      "[500, 0.1, 15, 0.9, 99.283121301406, 35.386401299529766]\n",
      "[500, 0.1, 15, 1, 99.00961294924723, 35.67673678041271]\n",
      "[500, 0.1, 16, 0.6, 99.82897500865406, 33.53224858163143]\n",
      "[500, 0.1, 16, 0.7, 99.87568462984157, 34.23677467669267]\n",
      "[500, 0.1, 16, 0.8, 99.89966471335828, 35.11550765107838]\n",
      "[500, 0.1, 16, 0.9, 99.90983420795546, 35.20821985573854]\n",
      "[500, 0.1, 16, 1, 99.8628345618871, 35.10531576739354]\n",
      "[600, 0.001, 3, 0.6, 18.24999780185953, 18.29904208791051]\n",
      "[600, 0.001, 3, 0.7, 18.24947422459575, 18.298190377851874]\n",
      "[600, 0.001, 3, 0.8, 18.25471692508612, 18.304033721937163]\n",
      "[600, 0.001, 3, 0.9, 18.255491661392732, 18.304787427679557]\n",
      "[600, 0.001, 3, 1, 18.26102565496085, 18.311305992766947]\n",
      "[600, 0.001, 4, 0.6, 19.85913260999288, 19.90752208345742]\n",
      "[600, 0.001, 4, 0.7, 19.859495513778636, 19.90736440816463]\n",
      "[600, 0.001, 4, 0.8, 19.862332130633618, 19.911363266556357]\n",
      "[600, 0.001, 4, 0.9, 19.858182633716904, 19.906572390760214]\n",
      "[600, 0.001, 4, 1, 19.868501079622437, 19.91950696818946]\n",
      "[600, 0.001, 5, 0.6, 20.990278547471576, 21.019184532657075]\n",
      "[600, 0.001, 5, 0.7, 20.99067368719415, 21.020500647597938]\n",
      "[600, 0.001, 5, 0.8, 20.98961799249095, 21.019809386934774]\n",
      "[600, 0.001, 5, 0.9, 20.990138769693957, 21.020519914270185]\n",
      "[600, 0.001, 5, 1, 20.99773261275306, 21.027172065545884]\n",
      "[600, 0.001, 6, 0.6, 21.82664140133853, 21.833992037326066]\n",
      "[600, 0.001, 6, 0.7, 21.82232525031058, 21.82967453394362]\n",
      "[600, 0.001, 6, 0.8, 21.818450003632563, 21.826806679412204]\n",
      "[600, 0.001, 6, 0.9, 21.81742971408278, 21.826538965275212]\n",
      "[600, 0.001, 6, 1, 21.821047501067625, 21.83046627137624]\n",
      "[600, 0.001, 7, 0.6, 22.476124911784524, 22.451635506318922]\n",
      "[600, 0.001, 7, 0.7, 22.469819139055602, 22.445152399646375]\n",
      "[600, 0.001, 7, 0.8, 22.462834864742863, 22.43841767790836]\n",
      "[600, 0.001, 7, 0.9, 22.45925240106359, 22.43517101520589]\n",
      "[600, 0.001, 7, 1, 22.458875423778345, 22.43159358418012]\n",
      "[600, 0.001, 8, 0.6, 23.04574633131784, 22.954546280827426]\n",
      "[600, 0.001, 8, 0.7, 23.03526503936051, 22.942901419125285]\n",
      "[600, 0.001, 8, 0.8, 23.027632695502376, 22.935490523179038]\n",
      "[600, 0.001, 8, 0.9, 23.018933472893732, 22.924889930724625]\n",
      "[600, 0.001, 8, 1, 23.011995711260656, 22.918831242387206]\n",
      "[600, 0.001, 9, 0.6, 23.582276472048257, 23.382269900436437]\n",
      "[600, 0.001, 9, 0.7, 23.572672232432325, 23.37077780548431]\n",
      "[600, 0.001, 9, 0.8, 23.561761650914768, 23.357046277191394]\n",
      "[600, 0.001, 9, 0.9, 23.55002771896434, 23.344325387153354]\n",
      "[600, 0.001, 9, 1, 23.536429743001154, 23.331506725497274]\n",
      "[600, 0.001, 10, 0.6, 24.177066514647837, 23.77283242201491]\n",
      "[600, 0.001, 10, 0.7, 24.166666043383778, 23.762001926571884]\n",
      "[600, 0.001, 10, 0.8, 24.152714298156997, 23.745661473618963]\n",
      "[600, 0.001, 10, 0.9, 24.133786622926213, 23.72437156746606]\n",
      "[600, 0.001, 10, 1, 24.097310307805664, 23.686412049291782]\n",
      "[600, 0.001, 11, 0.6, 24.900213382339032, 24.11829717849755]\n",
      "[600, 0.001, 11, 0.7, 24.895328280744433, 24.109031670291724]\n",
      "[600, 0.001, 11, 0.8, 24.882457938169168, 24.092655146373232]\n",
      "[600, 0.001, 11, 0.9, 24.86207135981655, 24.07107494721291]\n",
      "[600, 0.001, 11, 1, 24.805369956145352, 24.01924802931241]\n",
      "[600, 0.001, 12, 0.6, 25.851610234156254, 24.416606222991255]\n",
      "[600, 0.001, 12, 0.7, 25.86474591904855, 24.410756706160285]\n",
      "[600, 0.001, 12, 0.8, 25.865247230599287, 24.39673072694105]\n",
      "[600, 0.001, 12, 0.9, 25.849277124813362, 24.367947796421586]\n",
      "[600, 0.001, 12, 1, 25.757008463214383, 24.2989320931156]\n",
      "[600, 0.001, 13, 0.6, 27.153054030578904, 24.66386981579375]\n",
      "[600, 0.001, 13, 0.7, 27.210749176894144, 24.665525126557085]\n",
      "[600, 0.001, 13, 0.8, 27.242428771676064, 24.65582402304387]\n",
      "[600, 0.001, 13, 0.9, 27.246079044228534, 24.62622274113313]\n",
      "[600, 0.001, 13, 1, 27.120848129047303, 24.509750933855955]\n",
      "[600, 0.001, 14, 0.6, 28.897944479238014, 24.846863535593165]\n",
      "[600, 0.001, 14, 0.7, 29.046945228367093, 24.860855967885563]\n",
      "[600, 0.001, 14, 0.8, 29.148517328791336, 24.854988435148783]\n",
      "[600, 0.001, 14, 0.9, 29.208569655876072, 24.829603500679042]\n",
      "[600, 0.001, 14, 1, 29.040030664969652, 24.645565002838353]\n",
      "[600, 0.001, 15, 0.6, 31.099799344765966, 24.95284862214886]\n",
      "[600, 0.001, 15, 0.7, 31.40722177373686, 24.975349665221202]\n",
      "[600, 0.001, 15, 0.8, 31.64511849070951, 24.98150141080382]\n",
      "[600, 0.001, 15, 0.9, 31.812066433430285, 24.95916186222995]\n",
      "[600, 0.001, 15, 1, 31.61703364531204, 24.694045984350133]\n",
      "[600, 0.001, 16, 0.6, 33.66935736587408, 24.961662166885702]\n",
      "[600, 0.001, 16, 0.7, 34.2177472623566, 25.00488865114313]\n",
      "[600, 0.001, 16, 0.8, 34.66365214080837, 25.022130353865613]\n",
      "[600, 0.001, 16, 0.9, 35.00880072176906, 25.01035666925391]\n",
      "[600, 0.001, 16, 1, 34.83224331753229, 24.62306179190188]\n",
      "[600, 0.01, 3, 0.6, 34.72351050092259, 34.735783726527316]\n",
      "[600, 0.01, 3, 0.7, 34.71896796834054, 34.73132129476976]\n",
      "[600, 0.01, 3, 0.8, 34.71442126412745, 34.72930543141772]\n",
      "[600, 0.01, 3, 0.9, 34.70844617857013, 34.72289446374144]\n",
      "[600, 0.01, 3, 1, 34.712355733794155, 34.72859179874903]\n",
      "[600, 0.01, 4, 0.6, 35.46546810239004, 35.39227094422004]\n",
      "[600, 0.01, 4, 0.7, 35.459380984237065, 35.38699278351384]\n",
      "[600, 0.01, 4, 0.8, 35.46488753868806, 35.3923754422736]\n",
      "[600, 0.01, 4, 0.9, 35.46835199770031, 35.39647651514611]\n",
      "[600, 0.01, 4, 1, 35.46746982369255, 35.38446732904964]\n",
      "[600, 0.01, 5, 0.6, 36.09101433641657, 35.900532209621176]\n",
      "[600, 0.01, 5, 0.7, 36.09358998049837, 35.89840017569196]\n",
      "[600, 0.01, 5, 0.8, 36.10594441675495, 35.8998600042538]\n",
      "[600, 0.01, 5, 0.9, 36.11309336188874, 35.906975943351924]\n",
      "[600, 0.01, 5, 1, 36.1019820604591, 35.896439803764494]\n",
      "[600, 0.01, 6, 0.6, 36.73496542580554, 36.3250759487435]\n",
      "[600, 0.01, 6, 0.7, 36.73770736755117, 36.317456436355855]\n",
      "[600, 0.01, 6, 0.8, 36.75404366370122, 36.31784822324396]\n",
      "[600, 0.01, 6, 0.9, 36.75548778555796, 36.320882983785665]\n",
      "[600, 0.01, 6, 1, 36.74859019550753, 36.30868230746835]\n",
      "[600, 0.01, 7, 0.6, 37.428856188823566, 36.67564553096001]\n",
      "[600, 0.01, 7, 0.7, 37.45114965056058, 36.687602004267085]\n",
      "[600, 0.01, 7, 0.8, 37.478951617091305, 36.706151191375355]\n",
      "[600, 0.01, 7, 0.9, 37.48484997606003, 36.68501498095753]\n",
      "[600, 0.01, 7, 1, 37.469871918623895, 36.666197077600295]\n",
      "[600, 0.01, 8, 0.6, 38.33800222562611, 37.01262019370098]\n",
      "[600, 0.01, 8, 0.7, 38.372880523869824, 37.029225720418346]\n",
      "[600, 0.01, 8, 0.8, 38.39864063536881, 37.02730073115757]\n",
      "[600, 0.01, 8, 0.9, 38.41844003199062, 37.02399213459581]\n",
      "[600, 0.01, 8, 1, 38.389897954300686, 36.983775413970946]\n",
      "[600, 0.01, 9, 0.6, 39.6425372271009, 37.32363100346293]\n",
      "[600, 0.01, 9, 0.7, 39.69211517554116, 37.33987821504384]\n",
      "[600, 0.01, 9, 0.8, 39.73591071601683, 37.335694375173844]\n",
      "[600, 0.01, 9, 0.9, 39.770015232655076, 37.33777730214792]\n",
      "[600, 0.01, 9, 1, 39.75074521738243, 37.30293046777159]\n",
      "[600, 0.01, 10, 0.6, 41.637539680063576, 37.64981022758889]\n",
      "[600, 0.01, 10, 0.7, 41.71892462403982, 37.642482229436865]\n",
      "[600, 0.01, 10, 0.8, 41.786265358305755, 37.62538651364217]\n",
      "[600, 0.01, 10, 0.9, 41.847414699259744, 37.63126644223453]\n",
      "[600, 0.01, 10, 1, 41.823272968496575, 37.58361017165392]\n",
      "[600, 0.01, 11, 0.6, 44.717303603098244, 37.931095165371566]\n",
      "[600, 0.01, 11, 0.7, 44.86886040814922, 37.93160694058694]\n",
      "[600, 0.01, 11, 0.8, 44.97586149135533, 37.915250433022884]\n",
      "[600, 0.01, 11, 0.9, 45.08895999818168, 37.896021561306185]\n",
      "[600, 0.01, 11, 1, 45.060524296233126, 37.769898341733075]\n",
      "[600, 0.01, 12, 0.6, 49.26653586900951, 38.1520053535659]\n",
      "[600, 0.01, 12, 0.7, 49.532249936205666, 38.152391914851655]\n",
      "[600, 0.01, 12, 0.8, 49.75869544400033, 38.14980284934656]\n",
      "[600, 0.01, 12, 0.9, 49.95406012698784, 38.117491889224006]\n",
      "[600, 0.01, 12, 1, 49.89790703395622, 37.92782835425024]\n",
      "[600, 0.01, 13, 0.6, 55.517512526548295, 38.35951889932253]\n",
      "[600, 0.01, 13, 0.7, 55.98232296112269, 38.323444098884316]\n",
      "[600, 0.01, 13, 0.8, 56.35849110782769, 38.298137217236025]\n",
      "[600, 0.01, 13, 0.9, 56.65589982503935, 38.28069135097175]\n",
      "[600, 0.01, 13, 1, 56.548727906318355, 37.922941815242005]\n",
      "[600, 0.01, 14, 0.6, 63.23569430003397, 38.44448288299759]\n",
      "[600, 0.01, 14, 0.7, 63.95073511979448, 38.41708737759069]\n",
      "[600, 0.01, 14, 0.8, 64.61082449851236, 38.40147552554045]\n",
      "[600, 0.01, 14, 0.9, 65.01222347863117, 38.369752154700834]\n",
      "[600, 0.01, 14, 1, 64.88885306265963, 37.88029516747545]\n",
      "[600, 0.01, 15, 0.6, 71.54710339426077, 38.444592125402544]\n",
      "[600, 0.01, 15, 0.7, 72.63037293269407, 38.4012427068149]\n",
      "[600, 0.01, 15, 0.8, 73.44096575265218, 38.3962465287774]\n",
      "[600, 0.01, 15, 0.9, 74.09409961712818, 38.313324475360055]\n",
      "[600, 0.01, 15, 1, 74.0978117440498, 37.67270372707458]\n",
      "[600, 0.01, 16, 0.6, 79.4036829017172, 38.322860316233786]\n",
      "[600, 0.01, 16, 0.7, 80.72052499485312, 38.27942295783868]\n",
      "[600, 0.01, 16, 0.8, 81.72829648734374, 38.3017439192057]\n",
      "[600, 0.01, 16, 0.9, 82.5447375027856, 38.15969557343705]\n",
      "[600, 0.01, 16, 1, 82.46981443729334, 37.204871238774075]\n",
      "[600, 0.1, 3, 0.6, 37.05396837466658, 36.8388289429385]\n",
      "[600, 0.1, 3, 0.7, 37.12540940693451, 36.88661496121918]\n",
      "[600, 0.1, 3, 0.8, 37.21192198241447, 36.92925298710944]\n",
      "[600, 0.1, 3, 0.9, 37.284422156242925, 36.968051409979864]\n",
      "[600, 0.1, 3, 1, 37.24151296211426, 36.85260933666468]\n",
      "[600, 0.1, 4, 0.6, 37.83226262506497, 37.28442127528844]\n",
      "[600, 0.1, 4, 0.7, 37.88721509579308, 37.30882283654934]\n",
      "[600, 0.1, 4, 0.8, 37.9995304012237, 37.381585144607286]\n",
      "[600, 0.1, 4, 0.9, 38.11635362452169, 37.410323734950765]\n",
      "[600, 0.1, 4, 1, 38.27604763257227, 37.43255575192175]\n",
      "[600, 0.1, 5, 0.6, 38.72614548375224, 37.585197617244404]\n",
      "[600, 0.1, 5, 0.7, 38.81784998879575, 37.636129431689255]\n",
      "[600, 0.1, 5, 0.8, 38.930219032760924, 37.68778656365086]\n",
      "[600, 0.1, 5, 0.9, 39.0749221589508, 37.71404051657831]\n",
      "[600, 0.1, 5, 1, 39.349077837603076, 37.727219435204795]\n",
      "[600, 0.1, 6, 0.6, 40.0444866760996, 37.83142456571246]\n",
      "[600, 0.1, 6, 0.7, 40.15484726070313, 37.8767562553705]\n",
      "[600, 0.1, 6, 0.8, 40.289123023767424, 37.93925421022739]\n",
      "[600, 0.1, 6, 0.9, 40.45006996554089, 37.96744316939943]\n",
      "[600, 0.1, 6, 1, 40.8433404185349, 37.954678078687486]\n",
      "[600, 0.1, 7, 0.6, 42.173395027706675, 37.94045847462575]\n",
      "[600, 0.1, 7, 0.7, 42.354747046923436, 38.007011976996566]\n",
      "[600, 0.1, 7, 0.8, 42.509477950918, 38.01060792280175]\n",
      "[600, 0.1, 7, 0.9, 42.72222141769161, 38.143555311210434]\n",
      "[600, 0.1, 7, 1, 43.14625949898453, 38.142771963852695]\n",
      "[600, 0.1, 8, 0.6, 45.76911217304027, 37.91213607799446]\n",
      "[600, 0.1, 8, 0.7, 46.00496385675087, 38.03148979553615]\n",
      "[600, 0.1, 8, 0.8, 46.19201486525086, 38.07212074369891]\n",
      "[600, 0.1, 8, 0.9, 46.45503168933883, 38.18750718979458]\n",
      "[600, 0.1, 8, 1, 46.94087334171753, 38.23199883527426]\n",
      "[600, 0.1, 9, 0.6, 51.445185960296016, 37.63241029570155]\n",
      "[600, 0.1, 9, 0.7, 51.778916788767205, 37.78624766765256]\n",
      "[600, 0.1, 9, 0.8, 52.08935737352791, 37.79450943072824]\n",
      "[600, 0.1, 9, 0.9, 52.36135554563681, 38.05572044983667]\n",
      "[600, 0.1, 9, 1, 52.75097554191708, 38.02630095223741]\n",
      "[600, 0.1, 10, 0.6, 59.83097456474151, 36.96302495555632]\n",
      "[600, 0.1, 10, 0.7, 60.26933230450046, 37.20027977799084]\n",
      "[600, 0.1, 10, 0.8, 60.60272663648494, 37.4710073674694]\n",
      "[600, 0.1, 10, 0.9, 60.942740879374256, 37.63632489069756]\n",
      "[600, 0.1, 10, 1, 61.1294454616352, 37.747276552090305]\n",
      "[600, 0.1, 11, 0.6, 70.51385640765231, 36.02505557811485]\n",
      "[600, 0.1, 11, 0.7, 71.0927824960462, 36.545638253019305]\n",
      "[600, 0.1, 11, 0.8, 71.54509889201832, 36.84590462697797]\n",
      "[600, 0.1, 11, 0.9, 71.82802190221305, 37.03961681128103]\n",
      "[600, 0.1, 11, 1, 71.76733669172538, 37.235573864579784]\n",
      "[600, 0.1, 12, 0.6, 82.03144105640305, 35.16248902805905]\n",
      "[600, 0.1, 12, 0.7, 82.64076643989299, 35.514344746545866]\n",
      "[600, 0.1, 12, 0.8, 83.09462123104043, 36.030592768873014]\n",
      "[600, 0.1, 12, 0.9, 83.29609122799779, 36.42726383937009]\n",
      "[600, 0.1, 12, 1, 82.96910355117372, 36.91195662136801]\n",
      "[600, 0.1, 13, 0.6, 91.7098870486488, 34.167837615252175]\n",
      "[600, 0.1, 13, 0.7, 92.16901325116818, 34.853818384611536]\n",
      "[600, 0.1, 13, 0.8, 92.45836432368282, 35.41850139293874]\n",
      "[600, 0.1, 13, 0.9, 92.60341763639792, 35.66915330156103]\n",
      "[600, 0.1, 13, 1, 92.10738596938813, 36.26231776352342]\n",
      "[600, 0.1, 14, 0.6, 97.32914980531054, 33.624215510545696]\n",
      "[600, 0.1, 14, 0.7, 97.60971225781385, 34.368713142132954]\n",
      "[600, 0.1, 14, 0.8, 97.79256881637662, 34.86991847821172]\n",
      "[600, 0.1, 14, 0.9, 97.86507210818968, 35.52751180949589]\n",
      "[600, 0.1, 14, 1, 97.4077649523038, 35.754201454599844]\n",
      "[600, 0.1, 15, 0.6, 99.46846359073493, 33.67015985207542]\n",
      "[600, 0.1, 15, 0.7, 99.56664526825827, 34.306080057595466]\n",
      "[600, 0.1, 15, 0.8, 99.62113550918971, 34.81048504971337]\n",
      "[600, 0.1, 15, 0.9, 99.64897715374227, 35.29415374711932]\n",
      "[600, 0.1, 15, 1, 99.47943307887289, 35.59197996408161]\n",
      "[600, 0.1, 16, 0.6, 99.93455857901523, 33.48338484786905]\n",
      "[600, 0.1, 16, 0.7, 99.95415085668576, 34.19416641097609]\n",
      "[600, 0.1, 16, 0.8, 99.96387754313517, 35.08045329595323]\n",
      "[600, 0.1, 16, 0.9, 99.96866369991125, 35.17873473434906]\n",
      "[600, 0.1, 16, 1, 99.94804568575769, 35.07026752229264]\n",
      "[700, 0.001, 3, 0.6, 20.023288882672908, 20.077446027821733]\n",
      "[700, 0.001, 3, 0.7, 20.02319594015425, 20.077283843851447]\n",
      "[700, 0.001, 3, 0.8, 20.02867633378218, 20.083250473627356]\n",
      "[700, 0.001, 3, 0.9, 20.028448201088935, 20.0832084016772]\n",
      "[700, 0.001, 3, 1, 20.033544455120712, 20.089065773207025]\n",
      "[700, 0.001, 4, 0.6, 21.679982932772802, 21.73212461659826]\n",
      "[700, 0.001, 4, 0.7, 21.677828314936576, 21.73022569276597]\n",
      "[700, 0.001, 4, 0.8, 21.680798298918546, 21.7345014456613]\n",
      "[700, 0.001, 4, 0.9, 21.677334824400962, 21.73100363825413]\n",
      "[700, 0.001, 4, 1, 21.691492132836764, 21.747513015817134]\n",
      "[700, 0.001, 5, 0.6, 22.835410484441688, 22.868910757534078]\n",
      "[700, 0.001, 5, 0.7, 22.83397237614786, 22.867955931315066]\n",
      "[700, 0.001, 5, 0.8, 22.831278312688198, 22.865825670890118]\n",
      "[700, 0.001, 5, 0.9, 22.83055610796999, 22.864671798234948]\n",
      "[700, 0.001, 5, 1, 22.836683085653686, 22.86926469302847]\n",
      "[700, 0.001, 6, 0.6, 23.699739526276563, 23.708704179576547]\n",
      "[700, 0.001, 6, 0.7, 23.695405247489234, 23.703605963094976]\n",
      "[700, 0.001, 6, 0.8, 23.690842593712002, 23.70034102599423]\n",
      "[700, 0.001, 6, 0.9, 23.687575108656677, 23.697259988735563]\n",
      "[700, 0.001, 6, 1, 23.689770567370992, 23.69899518641797]\n",
      "[700, 0.001, 7, 0.6, 24.37370604656115, 24.346184355826374]\n",
      "[700, 0.001, 7, 0.7, 24.36852950164081, 24.340898282734635]\n",
      "[700, 0.001, 7, 0.8, 24.359924429949096, 24.332731184833968]\n",
      "[700, 0.001, 7, 0.9, 24.35517030005878, 24.3283158719522]\n",
      "[700, 0.001, 7, 1, 24.354275030592987, 24.323257317689073]\n",
      "[700, 0.001, 8, 0.6, 24.97579458576916, 24.87019215820362]\n",
      "[700, 0.001, 8, 0.7, 24.964821341350863, 24.858246079454094]\n",
      "[700, 0.001, 8, 0.8, 24.957113570441535, 24.85126218020347]\n",
      "[700, 0.001, 8, 0.9, 24.94784056529533, 24.840139719394315]\n",
      "[700, 0.001, 8, 1, 24.939568523319267, 24.832461794941572]\n",
      "[700, 0.001, 9, 0.6, 25.554324986262944, 25.319583510354015]\n",
      "[700, 0.001, 9, 0.7, 25.5438731130177, 25.307400835506535]\n",
      "[700, 0.001, 9, 0.8, 25.535321058676363, 25.296446260309537]\n",
      "[700, 0.001, 9, 0.9, 25.524885967311917, 25.2851363589338]\n",
      "[700, 0.001, 9, 1, 25.510957111058975, 25.273813328685858]\n",
      "[700, 0.001, 10, 0.6, 26.193153655478184, 25.7212794365694]\n",
      "[700, 0.001, 10, 0.7, 26.18275942711026, 25.708824382655916]\n",
      "[700, 0.001, 10, 0.8, 26.1680203822781, 25.691893272130507]\n",
      "[700, 0.001, 10, 0.9, 26.14846112637509, 25.669399546993365]\n",
      "[700, 0.001, 10, 1, 26.112366352604198, 25.630871995039605]\n",
      "[700, 0.001, 11, 0.6, 26.998068141044516, 26.088418332668482]\n",
      "[700, 0.001, 11, 0.7, 26.992411961413467, 26.075237050357238]\n",
      "[700, 0.001, 11, 0.8, 26.978834791476693, 26.058292160379114]\n",
      "[700, 0.001, 11, 0.9, 26.95709925292039, 26.03395137335436]\n",
      "[700, 0.001, 11, 1, 26.888863953186316, 25.971673422446784]\n",
      "[700, 0.001, 12, 0.6, 28.07222552500376, 26.408736564399483]\n",
      "[700, 0.001, 12, 0.7, 28.087030681472815, 26.39988925772172]\n",
      "[700, 0.001, 12, 0.8, 28.088410457912005, 26.384112166411867]\n",
      "[700, 0.001, 12, 0.9, 28.071260204882865, 26.351628875475676]\n",
      "[700, 0.001, 12, 1, 27.96640564050946, 26.266843863284794]\n",
      "[700, 0.001, 13, 0.6, 29.55038969407504, 26.678361519320802]\n",
      "[700, 0.001, 13, 0.7, 29.61635912893793, 26.67490318257424]\n",
      "[700, 0.001, 13, 0.8, 29.652390984319975, 26.6648578154806]\n",
      "[700, 0.001, 13, 0.9, 29.65600249963475, 26.62746179688309]\n",
      "[700, 0.001, 13, 1, 29.510987910913432, 26.494947219240107]\n",
      "[700, 0.001, 14, 0.6, 31.538578512998537, 26.879833401546694]\n",
      "[700, 0.001, 14, 0.7, 31.705866997806385, 26.88490886779322]\n",
      "[700, 0.001, 14, 0.8, 31.820348316634618, 26.87848959064644]\n",
      "[700, 0.001, 14, 0.9, 31.88481994932446, 26.846408504056875]\n",
      "[700, 0.001, 14, 1, 31.697621040783652, 26.64053290097097]\n",
      "[700, 0.001, 15, 0.6, 34.04406115767377, 26.997879711005822]\n",
      "[700, 0.001, 15, 0.7, 34.38767799379645, 27.014922135746676]\n",
      "[700, 0.001, 15, 0.8, 34.65235651308392, 27.01866357159297]\n",
      "[700, 0.001, 15, 0.9, 34.83444435441836, 26.989977690381593]\n",
      "[700, 0.001, 15, 1, 34.611484742381, 26.686965172271403]\n",
      "[700, 0.001, 16, 0.6, 36.95921548110485, 27.015799163557652]\n",
      "[700, 0.001, 16, 0.7, 37.56888631779142, 27.05836856823759]\n",
      "[700, 0.001, 16, 0.8, 38.06142116613125, 27.067334880103534]\n",
      "[700, 0.001, 16, 0.9, 38.441736518767364, 27.047643108323438]\n",
      "[700, 0.001, 16, 1, 38.243455684037066, 26.623878975543047]\n",
      "[700, 0.01, 3, 0.6, 34.98279392333996, 34.982423632096385]\n",
      "[700, 0.01, 3, 0.7, 34.97631334600126, 34.97542067834293]\n",
      "[700, 0.01, 3, 0.8, 34.975288652472216, 34.97562222008046]\n",
      "[700, 0.01, 3, 0.9, 34.966242704167485, 34.965143556797976]\n",
      "[700, 0.01, 3, 1, 34.97103801136273, 34.97315102958927]\n",
      "[700, 0.01, 4, 0.6, 35.70836494890798, 35.614352373892025]\n",
      "[700, 0.01, 4, 0.7, 35.702387257061716, 35.60839242431657]\n",
      "[700, 0.01, 4, 0.8, 35.70620088060213, 35.610332729520145]\n",
      "[700, 0.01, 4, 0.9, 35.71091702244915, 35.61496336787015]\n",
      "[700, 0.01, 4, 1, 35.71085992640278, 35.60331197867836]\n",
      "[700, 0.01, 5, 0.6, 36.34123784122567, 36.11451758488202]\n",
      "[700, 0.01, 5, 0.7, 36.34057124169539, 36.10840783753273]\n",
      "[700, 0.01, 5, 0.8, 36.356748712869766, 36.1118092062966]\n",
      "[700, 0.01, 5, 0.9, 36.360390455135175, 36.11798165774731]\n",
      "[700, 0.01, 5, 1, 36.35690772785166, 36.111649792818625]\n",
      "[700, 0.01, 6, 0.6, 36.99836060987201, 36.526305600856666]\n",
      "[700, 0.01, 6, 0.7, 37.005745663677146, 36.5233774266971]\n",
      "[700, 0.01, 6, 0.8, 37.01975326508363, 36.52420199362998]\n",
      "[700, 0.01, 6, 0.9, 37.0202371316373, 36.524043343670755]\n",
      "[700, 0.01, 6, 1, 37.01839710286055, 36.515976789694435]\n",
      "[700, 0.01, 7, 0.6, 37.721724653566, 36.86875791946073]\n",
      "[700, 0.01, 7, 0.7, 37.75327527783928, 36.88787092619405]\n",
      "[700, 0.01, 7, 0.8, 37.77721926351748, 36.898131989720596]\n",
      "[700, 0.01, 7, 0.9, 37.786764553068465, 36.88394176511886]\n",
      "[700, 0.01, 7, 1, 37.76557818029486, 36.85805990848069]\n",
      "[700, 0.01, 8, 0.6, 38.70489887054207, 37.21351692217259]\n",
      "[700, 0.01, 8, 0.7, 38.74475099618847, 37.22628568916213]\n",
      "[700, 0.01, 8, 0.8, 38.766869404515504, 37.213947227904775]\n",
      "[700, 0.01, 8, 0.9, 38.789774002575875, 37.2173349462525]\n",
      "[700, 0.01, 8, 1, 38.752988968974556, 37.16627129730126]\n",
      "[700, 0.01, 9, 0.6, 40.138716329666636, 37.53305250905349]\n",
      "[700, 0.01, 9, 0.7, 40.205116690393936, 37.553118321443826]\n",
      "[700, 0.01, 9, 0.8, 40.24145571436638, 37.52375345697553]\n",
      "[700, 0.01, 9, 0.9, 40.280387196713605, 37.52522376021514]\n",
      "[700, 0.01, 9, 1, 40.25024402381552, 37.47741905148049]\n",
      "[700, 0.01, 10, 0.6, 42.35874003219181, 37.85032301139215]\n",
      "[700, 0.01, 10, 0.7, 42.446401649173424, 37.84764408988058]\n",
      "[700, 0.01, 10, 0.8, 42.52426356167336, 37.82873717899249]\n",
      "[700, 0.01, 10, 0.9, 42.59371343509033, 37.81744730309436]\n",
      "[700, 0.01, 10, 1, 42.557446203427475, 37.75239881856234]\n",
      "[700, 0.01, 11, 0.6, 45.777123343549476, 38.1266005031998]\n",
      "[700, 0.01, 11, 0.7, 45.931551189230625, 38.13512888136172]\n",
      "[700, 0.01, 11, 0.8, 46.07310276569162, 38.12565675329716]\n",
      "[700, 0.01, 11, 0.9, 46.18916498849198, 38.080661385109]\n",
      "[700, 0.01, 11, 1, 46.14896841098286, 37.934265114761324]\n",
      "[700, 0.01, 12, 0.6, 50.76656093221577, 38.3255729009272]\n",
      "[700, 0.01, 12, 0.7, 51.070196276390604, 38.34481355331797]\n",
      "[700, 0.01, 12, 0.8, 51.3284137884644, 38.360782547141184]\n",
      "[700, 0.01, 12, 0.9, 51.54772121959448, 38.290276927403674]\n",
      "[700, 0.01, 12, 1, 51.44628819933299, 38.07424535438432]\n",
      "[700, 0.01, 13, 0.6, 57.540006180798265, 38.52439790684071]\n",
      "[700, 0.01, 13, 0.7, 58.05521931652908, 38.48799553164719]\n",
      "[700, 0.01, 13, 0.8, 58.46369940362133, 38.48639072567782]\n",
      "[700, 0.01, 13, 0.9, 58.80154208291452, 38.45609424179538]\n",
      "[700, 0.01, 13, 1, 58.606541232081014, 38.057563730612806]\n",
      "[700, 0.01, 14, 0.6, 65.72355432544376, 38.59631067424459]\n",
      "[700, 0.01, 14, 0.7, 66.49306238643342, 38.563385921617055]\n",
      "[700, 0.01, 14, 0.8, 67.18121286345432, 38.56921919859461]\n",
      "[700, 0.01, 14, 0.9, 67.622527393188, 38.543248277546915]\n",
      "[700, 0.01, 14, 1, 67.40180618274334, 37.9853174740164]\n",
      "[700, 0.01, 15, 0.6, 74.29354846440003, 38.57840677757506]\n",
      "[700, 0.01, 15, 0.7, 75.4137925176829, 38.53553530151862]\n",
      "[700, 0.01, 15, 0.8, 76.23004140939851, 38.539184279949104]\n",
      "[700, 0.01, 15, 0.9, 76.92207653791968, 38.46956077870276]\n",
      "[700, 0.01, 15, 1, 76.76354302187744, 37.761241714819086]\n",
      "[700, 0.01, 16, 0.6, 82.15810375250443, 38.427477165212565]\n",
      "[700, 0.01, 16, 0.7, 83.43571242374274, 38.39582037451803]\n",
      "[700, 0.01, 16, 0.8, 84.41027275497645, 38.42147476063641]\n",
      "[700, 0.01, 16, 0.9, 85.16934380319393, 38.280118531337806]\n",
      "[700, 0.01, 16, 1, 84.94952247247177, 37.27932962058076]\n",
      "[700, 0.1, 3, 0.6, 37.1452827111905, 36.905429448643766]\n",
      "[700, 0.1, 3, 0.7, 37.227229057264246, 36.95978362975498]\n",
      "[700, 0.1, 3, 0.8, 37.32431115049781, 37.004279359219616]\n",
      "[700, 0.1, 3, 0.9, 37.400146186497295, 37.04031272381108]\n",
      "[700, 0.1, 3, 1, 37.37413928557477, 36.932007635194765]\n",
      "[700, 0.1, 4, 0.6, 37.950217142528196, 37.33998200082873]\n",
      "[700, 0.1, 4, 0.7, 38.01070031249162, 37.36678759747072]\n",
      "[700, 0.1, 4, 0.8, 38.12223548912302, 37.44421383509247]\n",
      "[700, 0.1, 4, 0.9, 38.257207385403646, 37.47859043203049]\n",
      "[700, 0.1, 4, 1, 38.460336574986506, 37.509417425821255]\n",
      "[700, 0.1, 5, 0.6, 38.89198597200214, 37.62243878032642]\n",
      "[700, 0.1, 5, 0.7, 38.99047622230252, 37.66999485359078]\n",
      "[700, 0.1, 5, 0.8, 39.11329756629388, 37.737805323328345]\n",
      "[700, 0.1, 5, 0.9, 39.265199776815074, 37.76343061515318]\n",
      "[700, 0.1, 5, 1, 39.588934112096005, 37.7903439738143]\n",
      "[700, 0.1, 6, 0.6, 40.3293790704499, 37.85548856668511]\n",
      "[700, 0.1, 6, 0.7, 40.45139048972679, 37.896898131855004]\n",
      "[700, 0.1, 6, 0.8, 40.599209115528765, 37.97242757475021]\n",
      "[700, 0.1, 6, 0.9, 40.77867596817585, 37.9813657209129]\n",
      "[700, 0.1, 6, 1, 41.222476667090056, 37.98073624225652]\n",
      "[700, 0.1, 7, 0.6, 42.69211736342419, 37.92636730473138]\n",
      "[700, 0.1, 7, 0.7, 42.89147707140374, 37.99814138501469]\n",
      "[700, 0.1, 7, 0.8, 43.061211353092254, 38.00414993077733]\n",
      "[700, 0.1, 7, 0.9, 43.30108125327735, 38.147259697952386]\n",
      "[700, 0.1, 7, 1, 43.79471584846326, 38.13639100100704]\n",
      "[700, 0.1, 8, 0.6, 46.675514496962755, 37.854947361453185]\n",
      "[700, 0.1, 8, 0.7, 46.94268374186829, 37.95069161016289]\n",
      "[700, 0.1, 8, 0.8, 47.16382443515299, 38.0334489464655]\n",
      "[700, 0.1, 8, 0.9, 47.43543117960296, 38.156399570978735]\n",
      "[700, 0.1, 8, 1, 48.01457438272803, 38.18226537173317]\n",
      "[700, 0.1, 9, 0.6, 52.91253903511182, 37.46407517241083]\n",
      "[700, 0.1, 9, 0.7, 53.30934651905599, 37.67564451377526]\n",
      "[700, 0.1, 9, 0.8, 53.64116499834593, 37.7126845668887]\n",
      "[700, 0.1, 9, 0.9, 53.94145104908714, 37.94314850888292]\n",
      "[700, 0.1, 9, 1, 54.37028953162463, 37.910099933401]\n",
      "[700, 0.1, 10, 0.6, 62.01248248684864, 36.7016367505134]\n",
      "[700, 0.1, 10, 0.7, 62.46710308143461, 36.99384757006799]\n",
      "[700, 0.1, 10, 0.8, 62.81825202226127, 37.2813314073419]\n",
      "[700, 0.1, 10, 0.9, 63.190138238950325, 37.44438005135605]\n",
      "[700, 0.1, 10, 1, 63.43465766551179, 37.595527715673214]\n",
      "[700, 0.1, 11, 0.6, 73.19975937290837, 35.69300052320822]\n",
      "[700, 0.1, 11, 0.7, 73.79495372207016, 36.251593347200014]\n",
      "[700, 0.1, 11, 0.8, 74.23871536105263, 36.56689494875541]\n",
      "[700, 0.1, 11, 0.9, 74.52597175471767, 36.809921331112186]\n",
      "[700, 0.1, 11, 1, 74.5303522035775, 36.988346158143656]\n",
      "[700, 0.1, 12, 0.6, 84.7406858834071, 34.798507477547666]\n",
      "[700, 0.1, 12, 0.7, 85.2851911006932, 35.20556959425881]\n",
      "[700, 0.1, 12, 0.8, 85.71151625615612, 35.732044754623224]\n",
      "[700, 0.1, 12, 0.9, 85.91673042077434, 36.15636202059106]\n",
      "[700, 0.1, 12, 1, 85.57221688843677, 36.67376774498783]\n",
      "[700, 0.1, 13, 0.6, 93.64821876008128, 33.86626801170338]\n",
      "[700, 0.1, 13, 0.7, 94.03944223409579, 34.61333714167918]\n",
      "[700, 0.1, 13, 0.8, 94.27276352433289, 35.174167364919285]\n",
      "[700, 0.1, 13, 0.9, 94.43655251895069, 35.44999664301158]\n",
      "[700, 0.1, 13, 1, 93.93971781536396, 36.065088602105064]\n",
      "[700, 0.1, 14, 0.6, 98.25055277047584, 33.421351429967196]\n",
      "[700, 0.1, 14, 0.7, 98.45840753248561, 34.21204079804505]\n",
      "[700, 0.1, 14, 0.8, 98.59158214918263, 34.71949982740005]\n",
      "[700, 0.1, 14, 0.9, 98.63236268971576, 35.38136574702917]\n",
      "[700, 0.1, 14, 1, 98.26964373486483, 35.63270772663765]\n",
      "[700, 0.1, 15, 0.6, 99.71928319844, 33.589294655925904]\n",
      "[700, 0.1, 15, 0.7, 99.77693059480795, 34.233482906862676]\n",
      "[700, 0.1, 15, 0.8, 99.80707597343475, 34.74434851922774]\n",
      "[700, 0.1, 15, 0.9, 99.82575498295405, 35.232830612503605]\n",
      "[700, 0.1, 15, 1, 99.71731620066869, 35.53148204413752]\n",
      "[700, 0.1, 16, 0.6, 99.9734490382193, 33.45244981019832]\n",
      "[700, 0.1, 16, 0.7, 99.98240065218226, 34.169188970527905]\n",
      "[700, 0.1, 16, 0.8, 99.9862430230383, 35.06250167318604]\n",
      "[700, 0.1, 16, 0.9, 99.98873378764426, 35.161647847784906]\n",
      "[700, 0.1, 16, 1, 99.98042476100683, 35.047207540220306]\n",
      "[800, 0.001, 3, 0.6, 21.561870203458145, 21.61923996096602]\n",
      "[800, 0.001, 3, 0.7, 21.56090554506439, 21.618253091586315]\n",
      "[800, 0.001, 3, 0.8, 21.56594330527486, 21.62372881631822]\n",
      "[800, 0.001, 3, 0.9, 21.56629104855424, 21.624229935113114]\n",
      "[800, 0.001, 3, 1, 21.57057690443547, 21.62945229846356]\n",
      "[800, 0.001, 4, 0.6, 23.2583923461526, 23.313743692225554]\n",
      "[800, 0.001, 4, 0.7, 23.258242760166283, 23.313949020380107]\n",
      "[800, 0.001, 4, 0.8, 23.26124544178154, 23.31755932823415]\n",
      "[800, 0.001, 4, 0.9, 23.260120662022345, 23.317127285667848]\n",
      "[800, 0.001, 4, 1, 23.27401699120183, 23.332225050761167]\n",
      "[800, 0.001, 5, 0.6, 24.404743211230063, 24.44183544298415]\n",
      "[800, 0.001, 5, 0.7, 24.40264762913128, 24.438992996682952]\n",
      "[800, 0.001, 5, 0.8, 24.3995166839295, 24.435607146016956]\n",
      "[800, 0.001, 5, 0.9, 24.398745012826783, 24.43461854018416]\n",
      "[800, 0.001, 5, 1, 24.403737392082945, 24.437229749366974]\n",
      "[800, 0.001, 6, 0.6, 25.280624530423534, 25.288583693747036]\n",
      "[800, 0.001, 6, 0.7, 25.277861902299424, 25.28544790411401]\n",
      "[800, 0.001, 6, 0.8, 25.273067345128975, 25.28161901159943]\n",
      "[800, 0.001, 6, 0.9, 25.269613469775276, 25.278155059935838]\n",
      "[800, 0.001, 6, 1, 25.27273242607916, 25.281460823175316]\n",
      "[800, 0.001, 7, 0.6, 25.972041001539182, 25.938802949067053]\n",
      "[800, 0.001, 7, 0.7, 25.96739373578405, 25.934280805740094]\n",
      "[800, 0.001, 7, 0.8, 25.958843516062803, 25.92650097001924]\n",
      "[800, 0.001, 7, 0.9, 25.952787672417898, 25.920233947179703]\n",
      "[800, 0.001, 7, 1, 25.950945352740174, 25.915999803342192]\n",
      "[800, 0.001, 8, 0.6, 26.592889912609618, 26.470989644793196]\n",
      "[800, 0.001, 8, 0.7, 26.582668992832602, 26.460020659403995]\n",
      "[800, 0.001, 8, 0.8, 26.57521324088532, 26.45303855205906]\n",
      "[800, 0.001, 8, 0.9, 26.56535151952949, 26.441672999651324]\n",
      "[800, 0.001, 8, 1, 26.554705011843083, 26.433806898476007]\n",
      "[800, 0.001, 9, 0.6, 27.209853176949206, 26.939944268210013]\n",
      "[800, 0.001, 9, 0.7, 27.20034560483453, 26.92913370067983]\n",
      "[800, 0.001, 9, 0.8, 27.190772836540123, 26.91630038381575]\n",
      "[800, 0.001, 9, 0.9, 27.17895800648693, 26.904161898688283]\n",
      "[800, 0.001, 9, 1, 27.162008893760582, 26.889700354402592]\n",
      "[800, 0.001, 10, 0.6, 27.895078803685593, 27.35398803508129]\n",
      "[800, 0.001, 10, 0.7, 27.885966268206076, 27.34207469305212]\n",
      "[800, 0.001, 10, 0.8, 27.872870039697673, 27.32621904014827]\n",
      "[800, 0.001, 10, 0.9, 27.85673997419017, 27.30719454076469]\n",
      "[800, 0.001, 10, 1, 27.820730491288536, 27.269866944338016]\n",
      "[800, 0.001, 11, 0.6, 28.767453011054467, 27.729686274396016]\n",
      "[800, 0.001, 11, 0.7, 28.761675392471307, 27.713780956623026]\n",
      "[800, 0.001, 11, 0.8, 28.74743215224631, 27.695231860459547]\n",
      "[800, 0.001, 11, 0.9, 28.725263027224244, 27.66881412781097]\n",
      "[800, 0.001, 11, 1, 28.64880127594043, 27.5984456092927]\n",
      "[800, 0.001, 12, 0.6, 29.955366029446175, 28.06557432980211]\n",
      "[800, 0.001, 12, 0.7, 29.972250149789037, 28.054057354265318]\n",
      "[800, 0.001, 12, 0.8, 29.974079554651766, 28.0352559440309]\n",
      "[800, 0.001, 12, 0.9, 29.957228719886054, 28.00184868841128]\n",
      "[800, 0.001, 12, 1, 29.84118147435738, 27.905244902890193]\n",
      "[800, 0.001, 13, 0.6, 31.601377614659153, 28.351558572378366]\n",
      "[800, 0.001, 13, 0.7, 31.674239846290064, 28.34522725453451]\n",
      "[800, 0.001, 13, 0.8, 31.71500146424977, 28.33043316065553]\n",
      "[800, 0.001, 13, 0.9, 31.72381985041791, 28.29169165955556]\n",
      "[800, 0.001, 13, 1, 31.55976121564934, 28.14372014950546]\n",
      "[800, 0.001, 14, 0.6, 33.82142339928165, 28.56625420162685]\n",
      "[800, 0.001, 14, 0.7, 34.004535606834786, 28.569136795719928]\n",
      "[800, 0.001, 14, 0.8, 34.13191024232248, 28.558024905740776]\n",
      "[800, 0.001, 14, 0.9, 34.20631332127703, 28.522546492683443]\n",
      "[800, 0.001, 14, 1, 34.00020950203096, 28.29703488843165]\n",
      "[800, 0.001, 15, 0.6, 36.61558271133435, 28.69659438334874]\n",
      "[800, 0.001, 15, 0.7, 36.99079769877296, 28.71009467625969]\n",
      "[800, 0.001, 15, 0.8, 37.27978313635714, 28.709368507772837]\n",
      "[800, 0.001, 15, 0.9, 37.481062774716676, 28.674556723151913]\n",
      "[800, 0.001, 15, 1, 37.230433274157285, 28.340129309591777]\n",
      "[800, 0.001, 16, 0.6, 39.85723735683202, 28.724114574002435]\n",
      "[800, 0.001, 16, 0.7, 40.519880872017055, 28.76583569361031]\n",
      "[800, 0.001, 16, 0.8, 41.05324274259999, 28.766252554737626]\n",
      "[800, 0.001, 16, 0.9, 41.46504521158918, 28.739216473877693]\n",
      "[800, 0.001, 16, 1, 41.24775247510686, 28.271871297933238]\n",
      "[800, 0.01, 3, 0.6, 35.17437361745554, 35.160300634239285]\n",
      "[800, 0.01, 3, 0.7, 35.16984719142704, 35.15510645175929]\n",
      "[800, 0.01, 3, 0.8, 35.16913714068196, 35.155223489540646]\n",
      "[800, 0.01, 3, 0.9, 35.16580497877222, 35.15008671923465]\n",
      "[800, 0.01, 3, 1, 35.16256516568844, 35.15137761780868]\n",
      "[800, 0.01, 4, 0.6, 35.90142220704, 35.785866359522686]\n",
      "[800, 0.01, 4, 0.7, 35.898530989130705, 35.78381714116391]\n",
      "[800, 0.01, 4, 0.8, 35.90276506633294, 35.78584936990222]\n",
      "[800, 0.01, 4, 0.9, 35.902085567986134, 35.7838214021766]\n",
      "[800, 0.01, 4, 1, 35.89159443928492, 35.762163985959695]\n",
      "[800, 0.01, 5, 0.6, 36.54106951782661, 36.28360554000374]\n",
      "[800, 0.01, 5, 0.7, 36.54836476778647, 36.28515294931126]\n",
      "[800, 0.01, 5, 0.8, 36.559357144955165, 36.282661524710335]\n",
      "[800, 0.01, 5, 0.9, 36.569969957909144, 36.29210496882877]\n",
      "[800, 0.01, 5, 1, 36.55924485255654, 36.27881827138525]\n",
      "[800, 0.01, 6, 0.6, 37.209107869157506, 36.68394115007874]\n",
      "[800, 0.01, 6, 0.7, 37.22373734426622, 36.68753263256114]\n",
      "[800, 0.01, 6, 0.8, 37.23628302515885, 36.68361985623137]\n",
      "[800, 0.01, 6, 0.9, 37.242181884934624, 36.68751186957026]\n",
      "[800, 0.01, 6, 1, 37.23514951671834, 36.67060774847116]\n",
      "[800, 0.01, 7, 0.6, 37.96952878561428, 37.031082457898265]\n",
      "[800, 0.01, 7, 0.7, 38.004894537266644, 37.044016558087336]\n",
      "[800, 0.01, 7, 0.8, 38.032097844204735, 37.05617340255335]\n",
      "[800, 0.01, 7, 0.9, 38.04098005554165, 37.036072353946324]\n",
      "[800, 0.01, 7, 1, 38.005613440778774, 36.9997096654846]\n",
      "[800, 0.01, 8, 0.6, 39.02999409731414, 37.384141550636265]\n",
      "[800, 0.01, 8, 0.7, 39.06653100861315, 37.384976823374686]\n",
      "[800, 0.01, 8, 0.8, 39.09366274695726, 37.36791512661182]\n",
      "[800, 0.01, 8, 0.9, 39.12006782175298, 37.36707367919424]\n",
      "[800, 0.01, 8, 1, 39.082860290144204, 37.317718499675415]\n",
      "[800, 0.01, 9, 0.6, 40.584916934540026, 37.704160701319836]\n",
      "[800, 0.01, 9, 0.7, 40.661280500065054, 37.724835493023534]\n",
      "[800, 0.01, 9, 0.8, 40.707099057491604, 37.68899676966105]\n",
      "[800, 0.01, 9, 0.9, 40.750255653201876, 37.681793817455144]\n",
      "[800, 0.01, 9, 1, 40.710460453072, 37.61936700353371]\n",
      "[800, 0.01, 10, 0.6, 43.016140267026735, 38.004805470496386]\n",
      "[800, 0.01, 10, 0.7, 43.114920706211365, 38.01066295934782]\n",
      "[800, 0.01, 10, 0.8, 43.203758300669406, 37.99522938060183]\n",
      "[800, 0.01, 10, 0.9, 43.283199558302066, 37.96865668529418]\n",
      "[800, 0.01, 10, 1, 43.23248827892392, 37.88123610824003]\n",
      "[800, 0.01, 11, 0.6, 46.752895580567646, 38.27724210946635]\n",
      "[800, 0.01, 11, 0.7, 46.930344930806086, 38.29450661923649]\n",
      "[800, 0.01, 11, 0.8, 47.08773864781277, 38.29120823149223]\n",
      "[800, 0.01, 11, 0.9, 47.22483402639192, 38.2419674303433]\n",
      "[800, 0.01, 11, 1, 47.13375050349069, 38.04509667710798]\n",
      "[800, 0.01, 12, 0.6, 52.158597024419336, 38.46534458132596]\n",
      "[800, 0.01, 12, 0.7, 52.498802493710016, 38.49620804252424]\n",
      "[800, 0.01, 12, 0.8, 52.78189743695927, 38.5085215166399]\n",
      "[800, 0.01, 12, 0.9, 53.003634807155045, 38.4386899536302]\n",
      "[800, 0.01, 12, 1, 52.88929998943714, 38.19158443145388]\n",
      "[800, 0.01, 13, 0.6, 59.38645792779904, 38.63638335867595]\n",
      "[800, 0.01, 13, 0.7, 59.93436752910295, 38.62456426881934]\n",
      "[800, 0.01, 13, 0.8, 60.377847430125584, 38.62264273801449]\n",
      "[800, 0.01, 13, 0.9, 60.74946813741976, 38.60079156822556]\n",
      "[800, 0.01, 13, 1, 60.52895420458246, 38.152514946895664]\n",
      "[800, 0.01, 14, 0.6, 67.95093748411605, 38.68656039461194]\n",
      "[800, 0.01, 14, 0.7, 68.7238056959529, 38.67331186274598]\n",
      "[800, 0.01, 14, 0.8, 69.44467510103736, 38.684161146073656]\n",
      "[800, 0.01, 14, 0.9, 69.93735972607078, 38.67656057768992]\n",
      "[800, 0.01, 14, 1, 69.67129922323113, 38.05542072779268]\n",
      "[800, 0.01, 15, 0.6, 76.68206053923069, 38.66110737457682]\n",
      "[800, 0.01, 15, 0.7, 77.77633921697951, 38.626062088839305]\n",
      "[800, 0.01, 15, 0.8, 78.59745030622976, 38.63429307161614]\n",
      "[800, 0.01, 15, 0.9, 79.31587891762584, 38.56785442343096]\n",
      "[800, 0.01, 15, 1, 79.13610762928231, 37.829185379564244]\n",
      "[800, 0.01, 16, 0.6, 84.45103685904758, 38.49465176344253]\n",
      "[800, 0.01, 16, 0.7, 85.62982654957175, 38.472798293368285]\n",
      "[800, 0.01, 16, 0.8, 86.59901426834061, 38.500384344295334]\n",
      "[800, 0.01, 16, 0.9, 87.2869622998138, 38.3674626298548]\n",
      "[800, 0.01, 16, 1, 86.91815040768871, 37.32913323983777]\n",
      "[800, 0.1, 3, 0.6, 37.21364297925551, 36.95394414076348]\n",
      "[800, 0.1, 3, 0.7, 37.298092503417635, 37.006298401923374]\n",
      "[800, 0.1, 3, 0.8, 37.40821725681872, 37.05464435543065]\n",
      "[800, 0.1, 3, 0.9, 37.495456664876684, 37.10080284028754]\n",
      "[800, 0.1, 3, 1, 37.53441505811163, 37.04177546024406]\n",
      "[800, 0.1, 4, 0.6, 38.045181187160026, 37.38190547923034]\n",
      "[800, 0.1, 4, 0.7, 38.10939808093599, 37.41181441096618]\n",
      "[800, 0.1, 4, 0.8, 38.2268190806284, 37.48667037133164]\n",
      "[800, 0.1, 4, 0.9, 38.366812831859484, 37.51892052258674]\n",
      "[800, 0.1, 4, 1, 38.616066045435325, 37.56897802176265]\n",
      "[800, 0.1, 5, 0.6, 39.04138398636155, 37.65830675879256]\n",
      "[800, 0.1, 5, 0.7, 39.14806374755329, 37.69839158619668]\n",
      "[800, 0.1, 5, 0.8, 39.27463715008962, 37.76253897643461]\n",
      "[800, 0.1, 5, 0.9, 39.44446585615737, 37.8086104437078]\n",
      "[800, 0.1, 5, 1, 39.80812405725782, 37.83329153193418]\n",
      "[800, 0.1, 6, 0.6, 40.59948940472828, 37.87089707053847]\n",
      "[800, 0.1, 6, 0.7, 40.72997198478829, 37.90113455244878]\n",
      "[800, 0.1, 6, 0.8, 40.89037462158657, 37.9906184530457]\n",
      "[800, 0.1, 6, 0.9, 41.088038401364926, 37.99200758219909]\n",
      "[800, 0.1, 6, 1, 41.5816780168423, 37.99221907653442]\n",
      "[800, 0.1, 7, 0.6, 43.18532925345726, 37.91418730870627]\n",
      "[800, 0.1, 7, 0.7, 43.39908683799756, 37.985302904906504]\n",
      "[800, 0.1, 7, 0.8, 43.58097599312164, 38.00216847043766]\n",
      "[800, 0.1, 7, 0.9, 43.847318057847474, 38.14577035474651]\n",
      "[800, 0.1, 7, 1, 44.403706756080716, 38.13086907809464]\n",
      "[800, 0.1, 8, 0.6, 47.53064711653362, 37.79899258756064]\n",
      "[800, 0.1, 8, 0.7, 47.83187091890993, 37.886482905999664]\n",
      "[800, 0.1, 8, 0.8, 48.073357460501, 37.97766637572272]\n",
      "[800, 0.1, 8, 0.9, 48.37746692949645, 38.104551623760166]\n",
      "[800, 0.1, 8, 1, 48.98451983392328, 38.15433129855823]\n",
      "[800, 0.1, 9, 0.6, 54.29310670575682, 37.325504948415514]\n",
      "[800, 0.1, 9, 0.7, 54.729794078156424, 37.54758851807386]\n",
      "[800, 0.1, 9, 0.8, 55.092443533333224, 37.60943337955667]\n",
      "[800, 0.1, 9, 0.9, 55.4356254072411, 37.8597153395748]\n",
      "[800, 0.1, 9, 1, 55.88888962871054, 37.8091053369177]\n",
      "[800, 0.1, 10, 0.6, 63.945894757560474, 36.45505920107307]\n",
      "[800, 0.1, 10, 0.7, 64.46431156719655, 36.795483772198125]\n",
      "[800, 0.1, 10, 0.8, 64.8483133855333, 37.09959694188998]\n",
      "[800, 0.1, 10, 0.9, 65.22671130793796, 37.25738119791464]\n",
      "[800, 0.1, 10, 1, 65.50686690338578, 37.46289114797936]\n",
      "[800, 0.1, 11, 0.6, 75.55896456411091, 35.37764903759465]\n",
      "[800, 0.1, 11, 0.7, 76.16969169841721, 35.96883267293497]\n",
      "[800, 0.1, 11, 0.8, 76.60466509132642, 36.29354174776983]\n",
      "[800, 0.1, 11, 0.9, 76.92580949179666, 36.58817852692054]\n",
      "[800, 0.1, 11, 1, 76.84654238919661, 36.79920098523935]\n",
      "[800, 0.1, 12, 0.6, 86.95021853842829, 34.47168098731225]\n",
      "[800, 0.1, 12, 0.7, 87.46177493207435, 34.8855665685602]\n",
      "[800, 0.1, 12, 0.8, 87.87211676841171, 35.45964224531364]\n",
      "[800, 0.1, 12, 0.9, 88.07602911321891, 35.930384415443875]\n",
      "[800, 0.1, 12, 1, 87.69175403190616, 36.486568523903415]\n",
      "[800, 0.1, 13, 0.6, 95.07825385357263, 33.610180752136095]\n",
      "[800, 0.1, 13, 0.7, 95.42417869473978, 34.3941385957711]\n",
      "[800, 0.1, 13, 0.8, 95.63327422387547, 34.9370493727157]\n",
      "[800, 0.1, 13, 0.9, 95.76790139280186, 35.25820116454415]\n",
      "[800, 0.1, 13, 1, 95.25905737562896, 35.910844482943816]\n",
      "[800, 0.1, 14, 0.6, 98.83902783385709, 33.281932614195874]\n",
      "[800, 0.1, 14, 0.7, 98.98745799042432, 34.088110707902075]\n",
      "[800, 0.1, 14, 0.8, 99.08145634099826, 34.59875167240566]\n",
      "[800, 0.1, 14, 0.9, 99.11512092464547, 35.279788480651476]\n",
      "[800, 0.1, 14, 1, 98.8387613518675, 35.541030862249144]\n",
      "[800, 0.1, 15, 0.6, 99.84843832070334, 33.52846221526039]\n",
      "[800, 0.1, 15, 0.7, 99.88078178892754, 34.19013644839779]\n",
      "[800, 0.1, 15, 0.8, 99.89905643329654, 34.70482748399194]\n",
      "[800, 0.1, 15, 0.9, 99.90992892840855, 35.19275668820055]\n",
      "[800, 0.1, 15, 1, 99.84642107726874, 35.49361072270003]\n",
      "[800, 0.1, 16, 0.6, 99.98869149937477, 33.434887106106295]\n",
      "[800, 0.1, 16, 0.7, 99.99263375004561, 34.15724601670394]\n",
      "[800, 0.1, 16, 0.8, 99.99443570227442, 35.052093435513655]\n",
      "[800, 0.1, 16, 0.9, 99.99557284952641, 35.15154669451087]\n",
      "[800, 0.1, 16, 1, 99.99190040735326, 35.03588562548047]\n",
      "[900, 0.001, 3, 0.6, 22.90584196696084, 22.964103850684403]\n",
      "[900, 0.001, 3, 0.7, 22.905042370355964, 22.963463053876566]\n",
      "[900, 0.001, 3, 0.8, 22.9092610596765, 22.96772525502835]\n",
      "[900, 0.001, 3, 0.9, 22.909704892850826, 22.968280049919187]\n",
      "[900, 0.001, 3, 1, 22.91469106912517, 22.974321561050914]\n",
      "[900, 0.001, 4, 0.6, 24.62138348696573, 24.677043330824123]\n",
      "[900, 0.001, 4, 0.7, 24.62066767385338, 24.67623634452696]\n",
      "[900, 0.001, 4, 0.8, 24.62514419944284, 24.680980980686694]\n",
      "[900, 0.001, 4, 0.9, 24.623662991068162, 24.679995066547345]\n",
      "[900, 0.001, 4, 1, 24.6374731240805, 24.693988391309084]\n",
      "[900, 0.001, 5, 0.6, 25.753440784220782, 25.791810924863412]\n",
      "[900, 0.001, 5, 0.7, 25.751197715941366, 25.788538418769193]\n",
      "[900, 0.001, 5, 0.8, 25.749948805158528, 25.786671271631246]\n",
      "[900, 0.001, 5, 0.9, 25.751096724976495, 25.787172463630746]\n",
      "[900, 0.001, 5, 1, 25.75788954182704, 25.79210209162942]\n",
      "[900, 0.001, 6, 0.6, 26.622316862825258, 26.627973238729872]\n",
      "[900, 0.001, 6, 0.7, 26.618540990157168, 26.623140989612903]\n",
      "[900, 0.001, 6, 0.8, 26.613121241676275, 26.619273077214313]\n",
      "[900, 0.001, 6, 0.9, 26.61075327099448, 26.616493761019754]\n",
      "[900, 0.001, 6, 1, 26.613705344188443, 26.618560507933154]\n",
      "[900, 0.001, 7, 0.6, 27.323512997918932, 27.28393198816873]\n",
      "[900, 0.001, 7, 0.7, 27.31778161754608, 27.27781164804377]\n",
      "[900, 0.001, 7, 0.8, 27.30972659627956, 27.2705959875274]\n",
      "[900, 0.001, 7, 0.9, 27.30390198347633, 27.264966943288105]\n",
      "[900, 0.001, 7, 1, 27.301477201589964, 27.261175622247833]\n",
      "[900, 0.001, 8, 0.6, 27.9574724917507, 27.818071070603835]\n",
      "[900, 0.001, 8, 0.7, 27.946381552964727, 27.80525238965429]\n",
      "[900, 0.001, 8, 0.8, 27.937458445798235, 27.7970123324633]\n",
      "[900, 0.001, 8, 0.9, 27.92836641889481, 27.786618251298012]\n",
      "[900, 0.001, 8, 1, 27.917701666495653, 27.779803330462084]\n",
      "[900, 0.001, 9, 0.6, 28.60252435674481, 28.29596148921216]\n",
      "[900, 0.001, 9, 0.7, 28.592363496064145, 28.283532495342367]\n",
      "[900, 0.001, 9, 0.8, 28.58141014806408, 28.26914443056673]\n",
      "[900, 0.001, 9, 0.9, 28.568871045413115, 28.256642337993643]\n",
      "[900, 0.001, 9, 1, 28.5497514000874, 28.24129902787169]\n",
      "[900, 0.001, 10, 0.6, 29.33482399508226, 28.724165388890377]\n",
      "[900, 0.001, 10, 0.7, 29.32634259751469, 28.711601122021023]\n",
      "[900, 0.001, 10, 0.8, 29.31347857833303, 28.695102889957003]\n",
      "[900, 0.001, 10, 0.9, 29.29728924186037, 28.6759009531787]\n",
      "[900, 0.001, 10, 1, 29.257997701263083, 28.635833141906964]\n",
      "[900, 0.001, 11, 0.6, 30.269142183427235, 29.103676300977742]\n",
      "[900, 0.001, 11, 0.7, 30.264334999854203, 29.08562337622309]\n",
      "[900, 0.001, 11, 0.8, 30.25258155454139, 29.068279468026827]\n",
      "[900, 0.001, 11, 0.9, 30.232463973278, 29.042832545601883]\n",
      "[900, 0.001, 11, 1, 30.15959141496346, 28.980214851076347]\n",
      "[900, 0.001, 12, 0.6, 31.562148393526847, 29.448756936285868]\n",
      "[900, 0.001, 12, 0.7, 31.581129762629367, 29.43396577592886]\n",
      "[900, 0.001, 12, 0.8, 31.58378406466651, 29.411898338136368]\n",
      "[900, 0.001, 12, 0.9, 31.567954566848044, 29.37693142254465]\n",
      "[900, 0.001, 12, 1, 31.44423668351317, 29.272065026970417]\n",
      "[900, 0.001, 13, 0.6, 33.3676153327439, 29.744410805206833]\n",
      "[900, 0.001, 13, 0.7, 33.447488175954895, 29.7347145028647]\n",
      "[900, 0.001, 13, 0.8, 33.49204639069833, 29.717893062485334]\n",
      "[900, 0.001, 13, 0.9, 33.504785834024176, 29.676177775716994]\n",
      "[900, 0.001, 13, 1, 33.32689433084407, 29.51321394528228]\n",
      "[900, 0.001, 14, 0.6, 35.80809527893266, 29.971382643961796]\n",
      "[900, 0.001, 14, 0.7, 36.004733613618455, 29.96985519919415]\n",
      "[900, 0.001, 14, 0.8, 36.145244461230895, 29.954277559502895]\n",
      "[900, 0.001, 14, 0.9, 36.22901161805404, 29.91659397985216]\n",
      "[900, 0.001, 14, 1, 36.00566505862641, 29.66391930425798]\n",
      "[900, 0.001, 15, 0.6, 38.87595244018542, 30.109350034810667]\n",
      "[900, 0.001, 15, 0.7, 39.27959858221228, 30.121930132068865]\n",
      "[900, 0.001, 15, 0.8, 39.59233079873869, 30.11493922857821]\n",
      "[900, 0.001, 15, 0.9, 39.81147134429309, 30.075530211389434]\n",
      "[900, 0.001, 15, 1, 39.532468611069774, 29.70579765431277]\n",
      "[900, 0.001, 16, 0.6, 42.422669955601556, 30.147445776358627]\n",
      "[900, 0.001, 16, 0.7, 43.133039982544, 30.18454010982523]\n",
      "[900, 0.001, 16, 0.8, 43.70372954262686, 30.17987083462259]\n",
      "[900, 0.001, 16, 0.9, 44.14319158892071, 30.145617662175017]\n",
      "[900, 0.001, 16, 1, 43.95081645812524, 29.64944809272606]\n",
      "[900, 0.01, 3, 0.6, 35.32344994837305, 35.298086995733925]\n",
      "[900, 0.01, 3, 0.7, 35.321213766530555, 35.294849999827804]\n",
      "[900, 0.01, 3, 0.8, 35.320754221535466, 35.294997143218595]\n",
      "[900, 0.01, 3, 0.9, 35.31363376491511, 35.288147507253285]\n",
      "[900, 0.01, 3, 1, 35.31353323272094, 35.29125946681083]\n",
      "[900, 0.01, 4, 0.6, 36.05758697020459, 35.92354883817642]\n",
      "[900, 0.01, 4, 0.7, 36.05990893078778, 35.928296674046024]\n",
      "[900, 0.01, 4, 0.8, 36.068200429189226, 35.932543508415925]\n",
      "[900, 0.01, 4, 0.9, 36.06434696886953, 35.92696967347838]\n",
      "[900, 0.01, 4, 1, 36.04832186413787, 35.90212982007347]\n",
      "[900, 0.01, 5, 0.6, 36.70697385178274, 36.42144245967527]\n",
      "[900, 0.01, 5, 0.7, 36.71919463171426, 36.426186956178384]\n",
      "[900, 0.01, 5, 0.8, 36.731937806589364, 36.42425361963038]\n",
      "[900, 0.01, 5, 0.9, 36.73614781087361, 36.42595921105816]\n",
      "[900, 0.01, 5, 1, 36.724673060698464, 36.40884262209292]\n",
      "[900, 0.01, 6, 0.6, 37.394196877695194, 36.81819322081874]\n",
      "[900, 0.01, 6, 0.7, 37.409933874012424, 36.82226345985321]\n",
      "[900, 0.01, 6, 0.8, 37.426226662311045, 36.81757981766209]\n",
      "[900, 0.01, 6, 0.9, 37.43182736224083, 36.82177785294092]\n",
      "[900, 0.01, 6, 1, 37.41469091935529, 36.79230100034652]\n",
      "[900, 0.01, 7, 0.6, 38.19011311711981, 37.169203879896116]\n",
      "[900, 0.01, 7, 0.7, 38.232564421770434, 37.183385242447784]\n",
      "[900, 0.01, 7, 0.8, 38.2563871598973, 37.186965413772114]\n",
      "[900, 0.01, 7, 0.9, 38.26814556087016, 37.164951300285395]\n",
      "[900, 0.01, 7, 1, 38.23160627893181, 37.12696527230749]\n",
      "[900, 0.01, 8, 0.6, 39.32023026209579, 37.524259087333704]\n",
      "[900, 0.01, 8, 0.7, 39.364360559363206, 37.53262336252522]\n",
      "[900, 0.01, 8, 0.8, 39.38807515680234, 37.49800293651647]\n",
      "[900, 0.01, 8, 0.9, 39.425314377628474, 37.500629712219165]\n",
      "[900, 0.01, 8, 1, 39.378240606412476, 37.431177471042986]\n",
      "[900, 0.01, 9, 0.6, 40.99915481272725, 37.84271403587655]\n",
      "[900, 0.01, 9, 0.7, 41.077631125756106, 37.85964848490877]\n",
      "[900, 0.01, 9, 0.8, 41.132462196843676, 37.83101821717823]\n",
      "[900, 0.01, 9, 0.9, 41.18249564733134, 37.8084343367057]\n",
      "[900, 0.01, 9, 1, 41.12823026063835, 37.71417749144567]\n",
      "[900, 0.01, 10, 0.6, 43.630239587195085, 38.13197371957675]\n",
      "[900, 0.01, 10, 0.7, 43.74058371327638, 38.142635969510685]\n",
      "[900, 0.01, 10, 0.8, 43.83644347541213, 38.129239282061214]\n",
      "[900, 0.01, 10, 0.9, 43.925300022079874, 38.10399996797056]\n",
      "[900, 0.01, 10, 1, 43.87673851606774, 37.97981840447996]\n",
      "[900, 0.01, 11, 0.6, 47.670802217619055, 38.394984238103426]\n",
      "[900, 0.01, 11, 0.7, 47.85630296782221, 38.41304691511631]\n",
      "[900, 0.01, 11, 0.8, 48.02959774551832, 38.40988470012368]\n",
      "[900, 0.01, 11, 0.9, 48.18907555207649, 38.38583824386903]\n",
      "[900, 0.01, 11, 1, 48.080020063153924, 38.135976276455196]\n",
      "[900, 0.01, 12, 0.6, 53.46465732045084, 38.569997116774765]\n",
      "[900, 0.01, 12, 0.7, 53.828080840774795, 38.596289580766054]\n",
      "[900, 0.01, 12, 0.8, 54.131732177013824, 38.62631012349905]\n",
      "[900, 0.01, 12, 0.9, 54.364824196383324, 38.56679477333195]\n",
      "[900, 0.01, 12, 1, 54.243996100437975, 38.28734510063975]\n",
      "[900, 0.01, 13, 0.6, 61.084212139304924, 38.73405692797072]\n",
      "[900, 0.01, 13, 0.7, 61.67870303236644, 38.71323310225141]\n",
      "[900, 0.01, 13, 0.8, 62.12548586762146, 38.726930969947084]\n",
      "[900, 0.01, 13, 0.9, 62.51040784744042, 38.702334490750566]\n",
      "[900, 0.01, 13, 1, 62.29341538120012, 38.22419629271838]\n",
      "[900, 0.01, 14, 0.6, 69.95633677252403, 38.764402831992406]\n",
      "[900, 0.01, 14, 0.7, 70.75629311919853, 38.75172507313655]\n",
      "[900, 0.01, 14, 0.8, 71.46396768499856, 38.76409106476852]\n",
      "[900, 0.01, 14, 0.9, 71.98630968263495, 38.75532012443797]\n",
      "[900, 0.01, 14, 1, 71.60090111246484, 38.14563585320647]\n",
      "[900, 0.01, 15, 0.6, 78.78740021990383, 38.70785724563692]\n",
      "[900, 0.01, 15, 0.7, 79.85233001168336, 38.67888280026467]\n",
      "[900, 0.01, 15, 0.8, 80.67086183719317, 38.694204012304844]\n",
      "[900, 0.01, 15, 0.9, 81.33910428991648, 38.64258268881595]\n",
      "[900, 0.01, 15, 1, 80.9215905331094, 37.877630382411596]\n",
      "[900, 0.01, 16, 0.6, 86.39686311320767, 38.533850657716904]\n",
      "[900, 0.01, 16, 0.7, 87.49310899023413, 38.505965827718235]\n",
      "[900, 0.01, 16, 0.8, 88.41340826779114, 38.545182750870374]\n",
      "[900, 0.01, 16, 0.9, 89.03695283626702, 38.428911660047625]\n",
      "[900, 0.01, 16, 1, 88.37521203223217, 37.362522369746266]\n",
      "[900, 0.1, 3, 0.6, 37.27789363282782, 36.995482086825106]\n",
      "[900, 0.1, 3, 0.7, 37.36213254647532, 37.048238500470475]\n",
      "[900, 0.1, 3, 0.8, 37.47865251993233, 37.09946544895182]\n",
      "[900, 0.1, 3, 0.9, 37.57821703179353, 37.15428540904474]\n",
      "[900, 0.1, 3, 1, 37.663403569805254, 37.128024039209386]\n",
      "[900, 0.1, 4, 0.6, 38.13146566469501, 37.41674263232311]\n",
      "[900, 0.1, 4, 0.7, 38.19905413348535, 37.45071594976128]\n",
      "[900, 0.1, 4, 0.8, 38.31598788951629, 37.52133178090433]\n",
      "[900, 0.1, 4, 0.9, 38.466315614859816, 37.555940527875386]\n",
      "[900, 0.1, 4, 1, 38.761779771163894, 37.6185067238584]\n",
      "[900, 0.1, 5, 0.6, 39.176100644168876, 37.690113362186715]\n",
      "[900, 0.1, 5, 0.7, 39.28808291420286, 37.726848116147046]\n",
      "[900, 0.1, 5, 0.8, 39.421884443885865, 37.79297707779497]\n",
      "[900, 0.1, 5, 0.9, 39.60107021856606, 37.832705205593506]\n",
      "[900, 0.1, 5, 1, 40.00326299380526, 37.86147873361089]\n",
      "[900, 0.1, 6, 0.6, 40.85216754557499, 37.89062812574557]\n",
      "[900, 0.1, 6, 0.7, 40.992998557650594, 37.91975448928607]\n",
      "[900, 0.1, 6, 0.8, 41.16058289982442, 37.9999772752108]\n",
      "[900, 0.1, 6, 0.9, 41.37613693056495, 37.99960674606287]\n",
      "[900, 0.1, 6, 1, 41.910073952239976, 38.0103825903065]\n",
      "[900, 0.1, 7, 0.6, 43.65605513942617, 37.906291883118584]\n",
      "[900, 0.1, 7, 0.7, 43.87888876622099, 37.97187525767735]\n",
      "[900, 0.1, 7, 0.8, 44.080168267756626, 37.992169503635]\n",
      "[900, 0.1, 7, 0.9, 44.36649137675225, 38.14742815916748]\n",
      "[900, 0.1, 7, 1, 44.974103430044906, 38.11012885214918]\n",
      "[900, 0.1, 8, 0.6, 48.34411649355401, 37.7503402230008]\n",
      "[900, 0.1, 8, 0.7, 48.67242244821012, 37.84257301412559]\n",
      "[900, 0.1, 8, 0.8, 48.938370332515156, 37.915661402924194]\n",
      "[900, 0.1, 8, 0.9, 49.27047837181028, 38.05572041037415]\n",
      "[900, 0.1, 8, 1, 49.9588774229887, 38.100339404219476]\n",
      "[900, 0.1, 9, 0.6, 55.5939851796474, 37.203229247134686]\n",
      "[900, 0.1, 9, 0.7, 56.053915975203616, 37.40699839749956]\n",
      "[900, 0.1, 9, 0.8, 56.453693046795905, 37.50524886610596]\n",
      "[900, 0.1, 9, 0.9, 56.812762028962105, 37.76027081655386]\n",
      "[900, 0.1, 9, 1, 57.31686441322263, 37.6953932672252]\n",
      "[900, 0.1, 10, 0.6, 65.73935232411246, 36.24056202217457]\n",
      "[900, 0.1, 10, 0.7, 66.2908042115539, 36.581247353237764]\n",
      "[900, 0.1, 10, 0.8, 66.70656872626692, 36.93288338807049]\n",
      "[900, 0.1, 10, 0.9, 67.10036577645526, 37.11026702594036]\n",
      "[900, 0.1, 10, 1, 67.40713722624889, 37.296133658459055]\n",
      "[900, 0.1, 11, 0.6, 77.62803435820275, 35.104585585554474]\n",
      "[900, 0.1, 11, 0.7, 78.23838102661355, 35.697264182264036]\n",
      "[900, 0.1, 11, 0.8, 78.70636763334903, 36.04806806759178]\n",
      "[900, 0.1, 11, 0.9, 79.03430143596154, 36.36771118080636]\n",
      "[900, 0.1, 11, 1, 78.94004288683344, 36.61849761384015]\n",
      "[900, 0.1, 12, 0.6, 88.79238362627491, 34.208408828011684]\n",
      "[900, 0.1, 12, 0.7, 89.2481830538091, 34.625132083409284]\n",
      "[900, 0.1, 12, 0.8, 89.64740787626792, 35.21906031223393]\n",
      "[900, 0.1, 12, 0.9, 89.84342981804207, 35.73775792792622]\n",
      "[900, 0.1, 12, 1, 89.43796868254043, 36.28526667121142]\n",
      "[900, 0.1, 13, 0.6, 96.16637342953182, 33.392525955277705]\n",
      "[900, 0.1, 13, 0.7, 96.46120687152873, 34.20198581110393]\n",
      "[900, 0.1, 13, 0.8, 96.65032855186091, 34.74689843666241]\n",
      "[900, 0.1, 13, 0.9, 96.75284733520061, 35.09300369206802]\n",
      "[900, 0.1, 13, 1, 96.3028936494406, 35.75308318706591]\n",
      "[900, 0.1, 14, 0.6, 99.22278129741616, 33.173794529844734]\n",
      "[900, 0.1, 14, 0.7, 99.32693764212426, 33.99818921233494]\n",
      "[900, 0.1, 14, 0.8, 99.39405341067842, 34.506943635020846]\n",
      "[900, 0.1, 14, 0.9, 99.41853300264626, 35.20451074168049]\n",
      "[900, 0.1, 14, 1, 99.2214389006057, 35.46752655973858]\n",
      "[900, 0.1, 15, 0.6, 99.91567610594137, 33.49512654094361]\n",
      "[900, 0.1, 15, 0.7, 99.9348242577753, 34.159754298932654]\n",
      "[900, 0.1, 15, 0.8, 99.94553459877372, 34.67957253151346]\n",
      "[900, 0.1, 15, 0.9, 99.95285800595545, 35.16737170347335]\n",
      "[900, 0.1, 15, 1, 99.91836563561974, 35.4598738139658]\n",
      "[900, 0.1, 16, 0.6, 99.99480350269344, 33.42354581146624]\n",
      "[900, 0.1, 16, 0.7, 99.99659103195592, 34.14955155333911]\n",
      "[900, 0.1, 16, 0.8, 99.99739234331783, 35.04581649935182]\n",
      "[900, 0.1, 16, 0.9, 99.99787970765433, 35.14653342334127]\n",
      "[900, 0.1, 16, 1, 99.9963233252116, 35.02896089813736]\n",
      "[1000, 0.001, 3, 0.6, 24.083150250651098, 24.141606136150372]\n",
      "[1000, 0.001, 3, 0.7, 24.079916717502126, 24.13894209068198]\n",
      "[1000, 0.001, 3, 0.8, 24.083692362691757, 24.142881791603788]\n",
      "[1000, 0.001, 3, 0.9, 24.084040897065208, 24.143334247235327]\n",
      "[1000, 0.001, 3, 1, 24.089198020086698, 24.14913180313182]\n",
      "[1000, 0.001, 4, 0.6, 25.800170550194878, 25.85410792255728]\n",
      "[1000, 0.001, 4, 0.7, 25.796247221644908, 25.8506413075276]\n",
      "[1000, 0.001, 4, 0.8, 25.80185192705415, 25.855824845032917]\n",
      "[1000, 0.001, 4, 0.9, 25.79820681360987, 25.85316244460859]\n",
      "[1000, 0.001, 4, 1, 25.812603155205906, 25.86635119987776]\n",
      "[1000, 0.001, 5, 0.6, 26.91992783989806, 26.957873369957184]\n",
      "[1000, 0.001, 5, 0.7, 26.915638596682978, 26.952245479878812]\n",
      "[1000, 0.001, 5, 0.8, 26.91396839018323, 26.950891742633644]\n",
      "[1000, 0.001, 5, 0.9, 26.915707037747083, 26.95097457378852]\n",
      "[1000, 0.001, 5, 1, 26.92126842374626, 26.953453709328468]\n",
      "[1000, 0.001, 6, 0.6, 27.76766299010084, 27.769316275024003]\n",
      "[1000, 0.001, 6, 0.7, 27.761633716034783, 27.762315213765532]\n",
      "[1000, 0.001, 6, 0.8, 27.756840488915092, 27.758901253947442]\n",
      "[1000, 0.001, 6, 0.9, 27.752156909755044, 27.75308858669785]\n",
      "[1000, 0.001, 6, 1, 27.752271550293873, 27.751302356346162]\n",
      "[1000, 0.001, 7, 0.6, 28.46909504757026, 28.421223190000454]\n",
      "[1000, 0.001, 7, 0.7, 28.463524822376296, 28.41514059926461]\n",
      "[1000, 0.001, 7, 0.8, 28.4565692218519, 28.40810733374468]\n",
      "[1000, 0.001, 7, 0.9, 28.44974118199883, 28.402332184517633]\n",
      "[1000, 0.001, 7, 1, 28.447393046537606, 28.399069547057167]\n",
      "[1000, 0.001, 8, 0.6, 29.115264269085607, 28.95693014321172]\n",
      "[1000, 0.001, 8, 0.7, 29.104277021571058, 28.943925453911177]\n",
      "[1000, 0.001, 8, 0.8, 29.095038828894605, 28.9349831017522]\n",
      "[1000, 0.001, 8, 0.9, 29.085971854293348, 28.92467476429449]\n",
      "[1000, 0.001, 8, 1, 29.072420797498122, 28.91419777330445]\n",
      "[1000, 0.001, 9, 0.6, 29.781171937286032, 29.43563949953227]\n",
      "[1000, 0.001, 9, 0.7, 29.770370481804942, 29.422588285344986]\n",
      "[1000, 0.001, 9, 0.8, 29.758322705855335, 29.406416988300045]\n",
      "[1000, 0.001, 9, 0.9, 29.745640110968818, 29.393671536795996]\n",
      "[1000, 0.001, 9, 1, 29.726218681169758, 29.37907141044961]\n",
      "[1000, 0.001, 10, 0.6, 30.55337797774216, 29.87258721186509]\n",
      "[1000, 0.001, 10, 0.7, 30.545139400928335, 29.857929102392422]\n",
      "[1000, 0.001, 10, 0.8, 30.532402897962964, 29.841391460007806]\n",
      "[1000, 0.001, 10, 0.9, 30.516442904368546, 29.82185149974067]\n",
      "[1000, 0.001, 10, 1, 30.474783932160932, 29.778652682103115]\n",
      "[1000, 0.001, 11, 0.6, 31.551522570153768, 30.259426446974235]\n",
      "[1000, 0.001, 11, 0.7, 31.548438027182936, 30.240543919735806]\n",
      "[1000, 0.001, 11, 0.8, 31.539588214127267, 30.223979165100758]\n",
      "[1000, 0.001, 11, 0.9, 31.521790874037002, 30.199217218874164]\n",
      "[1000, 0.001, 11, 1, 31.44723828591114, 30.135832136846062]\n",
      "[1000, 0.001, 12, 0.6, 32.94146792153481, 30.606556934984585]\n",
      "[1000, 0.001, 12, 0.7, 32.961978896400055, 30.589656880718962]\n",
      "[1000, 0.001, 12, 0.8, 32.96833628453285, 30.565383447472637]\n",
      "[1000, 0.001, 12, 0.9, 32.954565657678145, 30.528598823050967]\n",
      "[1000, 0.001, 12, 1, 32.8237602765271, 30.415142270725138]\n",
      "[1000, 0.001, 13, 0.6, 34.89807101702698, 30.908805855846154]\n",
      "[1000, 0.001, 13, 0.7, 34.984856400797895, 30.896490096370034]\n",
      "[1000, 0.001, 13, 0.8, 35.03524999710945, 30.876705464015153]\n",
      "[1000, 0.001, 13, 0.9, 35.05170128366563, 30.833283643276722]\n",
      "[1000, 0.001, 13, 1, 34.86153351276972, 30.655357751170953]\n",
      "[1000, 0.001, 14, 0.6, 37.54692899291601, 31.143615605080367]\n",
      "[1000, 0.001, 14, 0.7, 37.760414607000314, 31.139656412558647]\n",
      "[1000, 0.001, 14, 0.8, 37.911591981730176, 31.120252591837495]\n",
      "[1000, 0.001, 14, 0.9, 38.00564123148431, 31.078255135389753]\n",
      "[1000, 0.001, 14, 1, 37.76655399533189, 30.807692954270895]\n",
      "[1000, 0.001, 15, 0.6, 40.87345920723521, 31.290676264742643]\n",
      "[1000, 0.001, 15, 0.7, 41.30616227865789, 31.29895454020447]\n",
      "[1000, 0.001, 15, 0.8, 41.64053029071013, 31.287489650811008]\n",
      "[1000, 0.001, 15, 0.9, 41.877028701970076, 31.242175592201903]\n",
      "[1000, 0.001, 15, 1, 41.58208095801798, 30.845175399700043]\n",
      "[1000, 0.001, 16, 0.6, 44.707593520794376, 31.339201350201982]\n",
      "[1000, 0.001, 16, 0.7, 45.45921367920654, 31.36846795256649]\n",
      "[1000, 0.001, 16, 0.8, 46.06643192212591, 31.357838603052514]\n",
      "[1000, 0.001, 16, 0.9, 46.53326597912907, 31.31750172244282]\n",
      "[1000, 0.001, 16, 1, 46.33958048274624, 30.78504997274556]\n",
      "[1000, 0.01, 3, 0.6, 35.44495630804138, 35.40973805450728]\n",
      "[1000, 0.01, 3, 0.7, 35.444429309119194, 35.406410451985124]\n",
      "[1000, 0.01, 3, 0.8, 35.44134988908378, 35.405436378281784]\n",
      "[1000, 0.01, 3, 0.9, 35.43955752982176, 35.40400400958964]\n",
      "[1000, 0.01, 3, 1, 35.43719517165164, 35.40453693338922]\n",
      "[1000, 0.01, 4, 0.6, 36.19664075199635, 36.0465134355107]\n",
      "[1000, 0.01, 4, 0.7, 36.19833515177846, 36.0472895152809]\n",
      "[1000, 0.01, 4, 0.8, 36.204748773588946, 36.0507117984691]\n",
      "[1000, 0.01, 4, 0.9, 36.20568786206888, 36.05166001082727]\n",
      "[1000, 0.01, 4, 1, 36.188894653740476, 36.02432893080895]\n",
      "[1000, 0.01, 5, 0.6, 36.84663685777316, 36.53505242579035]\n",
      "[1000, 0.01, 5, 0.7, 36.86383171990062, 36.54133086403116]\n",
      "[1000, 0.01, 5, 0.8, 36.87868542801738, 36.53951898957886]\n",
      "[1000, 0.01, 5, 0.9, 36.881729923410624, 36.53962589592483]\n",
      "[1000, 0.01, 5, 1, 36.86732100820399, 36.51828521949009]\n",
      "[1000, 0.01, 6, 0.6, 37.55371956889716, 36.93317355222765]\n",
      "[1000, 0.01, 6, 0.7, 37.57307100249183, 36.93450630548946]\n",
      "[1000, 0.01, 6, 0.8, 37.59075749001318, 36.92742895292328]\n",
      "[1000, 0.01, 6, 0.9, 37.599098514227144, 36.93173207670548]\n",
      "[1000, 0.01, 6, 1, 37.57645069998337, 36.898615075191586]\n",
      "[1000, 0.01, 7, 0.6, 38.38966226213657, 37.29103378112866]\n",
      "[1000, 0.01, 7, 0.7, 38.43711728194123, 37.30901012742884]\n",
      "[1000, 0.01, 7, 0.8, 38.45994092406191, 37.29523814188502]\n",
      "[1000, 0.01, 7, 0.9, 38.47332186232215, 37.272706228891735]\n",
      "[1000, 0.01, 7, 1, 38.43446271973418, 37.22390896864195]\n",
      "[1000, 0.01, 8, 0.6, 39.58148033685838, 37.63538842956573]\n",
      "[1000, 0.01, 8, 0.7, 39.63650003363257, 37.65563188362556]\n",
      "[1000, 0.01, 8, 0.8, 39.66819710773035, 37.62320039869936]\n",
      "[1000, 0.01, 8, 0.9, 39.70330413740958, 37.60771914144736]\n",
      "[1000, 0.01, 8, 1, 39.64965147943168, 37.52656436837643]\n",
      "[1000, 0.01, 9, 0.6, 41.374123576676794, 37.943956649075304]\n",
      "[1000, 0.01, 9, 0.7, 41.46802993818625, 37.97323188886772]\n",
      "[1000, 0.01, 9, 0.8, 41.525526615713794, 37.947569492460296]\n",
      "[1000, 0.01, 9, 0.9, 41.59230716797444, 37.9269165750995]\n",
      "[1000, 0.01, 9, 1, 41.52860969228107, 37.81005828412351]\n",
      "[1000, 0.01, 10, 0.6, 44.20771808541869, 38.229323701485384]\n",
      "[1000, 0.01, 10, 0.7, 44.32348764015727, 38.241346599609294]\n",
      "[1000, 0.01, 10, 0.8, 44.42964950127581, 38.24178685428927]\n",
      "[1000, 0.01, 10, 0.9, 44.531484025980895, 38.22069028307388]\n",
      "[1000, 0.01, 10, 1, 44.4837322282047, 38.068565939092835]\n",
      "[1000, 0.01, 11, 0.6, 48.530758102064894, 38.48938190381958]\n",
      "[1000, 0.01, 11, 0.7, 48.7379799726248, 38.51281118974826]\n",
      "[1000, 0.01, 11, 0.8, 48.91526072281025, 38.50701147387454]\n",
      "[1000, 0.01, 11, 0.9, 49.094155011556985, 38.49771070916539]\n",
      "[1000, 0.01, 11, 1, 48.98759750864106, 38.220545082873436]\n",
      "[1000, 0.01, 12, 0.6, 54.69050471450381, 38.64816417634107]\n",
      "[1000, 0.01, 12, 0.7, 55.06804586962497, 38.678027886909206]\n",
      "[1000, 0.01, 12, 0.8, 55.38999077181046, 38.72208549854746]\n",
      "[1000, 0.01, 12, 0.9, 55.622497421497606, 38.660355825626255]\n",
      "[1000, 0.01, 12, 1, 55.48709742769644, 38.36152791459697]\n",
      "[1000, 0.01, 13, 0.6, 62.664853171160686, 38.80160945100326]\n",
      "[1000, 0.01, 13, 0.7, 63.26214639575364, 38.77814254548816]\n",
      "[1000, 0.01, 13, 0.8, 63.72081386119304, 38.796180701574265]\n",
      "[1000, 0.01, 13, 0.9, 64.12790731114659, 38.783612255967505]\n",
      "[1000, 0.01, 13, 1, 63.735449043054146, 38.293080244666896]\n",
      "[1000, 0.01, 14, 0.6, 71.78994350964723, 38.80536582046453]\n",
      "[1000, 0.01, 14, 0.7, 72.57838063637539, 38.80696905138037]\n",
      "[1000, 0.01, 14, 0.8, 73.27601463838486, 38.81921693243814]\n",
      "[1000, 0.01, 14, 0.9, 73.79380919899064, 38.81590416309275]\n",
      "[1000, 0.01, 14, 1, 73.29797331995407, 38.20513514239524]\n",
      "[1000, 0.01, 15, 0.6, 80.66892151137245, 38.74016344929044]\n",
      "[1000, 0.01, 15, 0.7, 81.68026107723652, 38.71321548792059]\n",
      "[1000, 0.01, 15, 0.8, 82.46623267037265, 38.73217319196801]\n",
      "[1000, 0.01, 15, 0.9, 83.08451614411067, 38.69269030307364]\n",
      "[1000, 0.01, 15, 1, 82.53500916700834, 37.91683441954243]\n",
      "[1000, 0.01, 16, 0.6, 88.08467749145107, 38.55069723386349]\n",
      "[1000, 0.01, 16, 0.7, 89.10195786229667, 38.53229891004267]\n",
      "[1000, 0.01, 16, 0.8, 89.93984858531351, 38.57468709256582]\n",
      "[1000, 0.01, 16, 0.9, 90.49105594632765, 38.45800410475398]\n",
      "[1000, 0.01, 16, 1, 89.71467121045778, 37.37838308883114]\n",
      "[1000, 0.1, 3, 0.6, 37.328063871935576, 37.029341227762494]\n",
      "[1000, 0.1, 3, 0.7, 37.42186723815362, 37.08931034299432]\n",
      "[1000, 0.1, 3, 0.8, 37.537067491327555, 37.132913437014615]\n",
      "[1000, 0.1, 3, 0.9, 37.65218964906626, 37.202458570135555]\n",
      "[1000, 0.1, 3, 1, 37.784040874594396, 37.21067065361569]\n",
      "[1000, 0.1, 4, 0.6, 38.20546341697655, 37.446110670577625]\n",
      "[1000, 0.1, 4, 0.7, 38.275919876522316, 37.48066261460614]\n",
      "[1000, 0.1, 4, 0.8, 38.39945227855023, 37.54597790986999]\n",
      "[1000, 0.1, 4, 0.9, 38.56168994459743, 37.59877557101119]\n",
      "[1000, 0.1, 4, 1, 38.88564449489466, 37.662885493425094]\n",
      "[1000, 0.1, 5, 0.6, 39.30075008022271, 37.702499586505766]\n",
      "[1000, 0.1, 5, 0.7, 39.4234796963206, 37.742150955340094]\n",
      "[1000, 0.1, 5, 0.8, 39.56212653646681, 37.814860109867055]\n",
      "[1000, 0.1, 5, 0.9, 39.755183242289775, 37.8614746510843]\n",
      "[1000, 0.1, 5, 1, 40.192328265555, 37.87516774174975]\n",
      "[1000, 0.1, 6, 0.6, 41.09235460015098, 37.8841903529997]\n",
      "[1000, 0.1, 6, 0.7, 41.243335756289326, 37.93508794400893]\n",
      "[1000, 0.1, 6, 0.8, 41.41788486427265, 38.004869704682406]\n",
      "[1000, 0.1, 6, 0.9, 41.655117082242924, 38.00659575757393]\n",
      "[1000, 0.1, 6, 1, 42.24783924153759, 38.03336107674771]\n",
      "[1000, 0.1, 7, 0.6, 44.095443850823116, 37.900432275959275]\n",
      "[1000, 0.1, 7, 0.7, 44.34074339260352, 37.95762287726756]\n",
      "[1000, 0.1, 7, 0.8, 44.55373336164003, 37.96908219373159]\n",
      "[1000, 0.1, 7, 0.9, 44.87060811320557, 38.14974703888967]\n",
      "[1000, 0.1, 7, 1, 45.53372741149897, 38.09103874812906]\n",
      "[1000, 0.1, 8, 0.6, 49.12304872921135, 37.69706130423661]\n",
      "[1000, 0.1, 8, 0.7, 49.464317516534464, 37.76218801926798]\n",
      "[1000, 0.1, 8, 0.8, 49.76237017323778, 37.8585008560178]\n",
      "[1000, 0.1, 8, 0.9, 50.12950511032837, 38.01216023008202]\n",
      "[1000, 0.1, 8, 1, 50.87159496098823, 38.03113726218375]\n",
      "[1000, 0.1, 9, 0.6, 56.809265655410904, 37.06579565057866]\n",
      "[1000, 0.1, 9, 0.7, 57.30472115181355, 37.27899231533242]\n",
      "[1000, 0.1, 9, 0.8, 57.72481401809104, 37.38873782793033]\n",
      "[1000, 0.1, 9, 0.9, 58.128586166336916, 37.66207522075696]\n",
      "[1000, 0.1, 9, 1, 58.72050169628069, 37.60012350548879]\n",
      "[1000, 0.1, 10, 0.6, 67.42504532774589, 36.03594011028505]\n",
      "[1000, 0.1, 10, 0.7, 67.97463351265122, 36.395792761243875]\n",
      "[1000, 0.1, 10, 0.8, 68.39244431957981, 36.76573990033478]\n",
      "[1000, 0.1, 10, 0.9, 68.82468857429456, 36.93850832838944]\n",
      "[1000, 0.1, 10, 1, 69.11726741672399, 37.140039304750985]\n",
      "[1000, 0.1, 11, 0.6, 79.49755880856598, 34.81521450611621]\n",
      "[1000, 0.1, 11, 0.7, 80.08937268813173, 35.42544543944386]\n",
      "[1000, 0.1, 11, 0.8, 80.55251529738388, 35.81474876384691]\n",
      "[1000, 0.1, 11, 0.9, 80.88883894187553, 36.16427206271193]\n",
      "[1000, 0.1, 11, 1, 80.81306846902626, 36.43789784136835]\n",
      "[1000, 0.1, 12, 0.6, 90.33349170861413, 33.962323407753395]\n",
      "[1000, 0.1, 12, 0.7, 90.77252871551383, 34.375429426053394]\n",
      "[1000, 0.1, 12, 0.8, 91.138148838819, 34.98048148774725]\n",
      "[1000, 0.1, 12, 0.9, 91.32539928910971, 35.53276304137146]\n",
      "[1000, 0.1, 12, 1, 90.90824357839628, 36.092000577377384]\n",
      "[1000, 0.1, 13, 0.6, 97.00006452983041, 33.20682572564765]\n",
      "[1000, 0.1, 13, 0.7, 97.25568290898887, 34.03717409958996]\n",
      "[1000, 0.1, 13, 0.8, 97.40792100848834, 34.59097228588719]\n",
      "[1000, 0.1, 13, 0.9, 97.49775074185905, 34.959670790687014]\n",
      "[1000, 0.1, 13, 1, 97.11382803470568, 35.63361317390405]\n",
      "[1000, 0.1, 14, 0.6, 99.47142358887682, 33.08885960912138]\n",
      "[1000, 0.1, 14, 0.7, 99.55047156439488, 33.92920755543037]\n",
      "[1000, 0.1, 14, 0.8, 99.59746528919138, 34.44107606146641]\n",
      "[1000, 0.1, 14, 0.9, 99.61524438503677, 35.13765095407791]\n",
      "[1000, 0.1, 14, 1, 99.47086746207279, 35.40188615477868]\n",
      "[1000, 0.1, 15, 0.6, 99.95226309918468, 33.46647970542811]\n",
      "[1000, 0.1, 15, 0.7, 99.96383579039968, 34.13774124741265]\n",
      "[1000, 0.1, 15, 0.8, 99.97080555817045, 34.65951026887469]\n",
      "[1000, 0.1, 15, 0.9, 99.97477323656533, 35.14992262994561]\n",
      "[1000, 0.1, 15, 1, 99.95480421352599, 35.43892623921475]\n",
      "[1000, 0.1, 16, 0.6, 99.99732107680698, 33.41734876012376]\n",
      "[1000, 0.1, 16, 0.7, 99.99812912608921, 34.144112687300506]\n",
      "[1000, 0.1, 16, 0.8, 99.99848664182194, 35.04234618615616]\n",
      "[1000, 0.1, 16, 0.9, 99.9986650305605, 35.143430073530766]\n",
      "[1000, 0.1, 16, 1, 99.99798391256874, 35.02481856094618]\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for max_depth in max_depth_list:\n",
    "            for subsample in subsample_list:\n",
    "                model = xgb.XGBRegressor(objective='reg:squarederror', device = 'cuda', \n",
    "                                         tree_method='hist', \n",
    "                                         n_estimators = n_estimators, \n",
    "                                         learning_rate = learning_rate, \n",
    "                                         max_depth = max_depth, \n",
    "                                         subsample = subsample,\n",
    "                                         random_state=42, enable_categorical=True  )\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                test_r2 = r2_score(y_test, y_pred) * 100\n",
    "                y_train_pred = model.predict(X_train)\n",
    "                train_r2 = r2_score(y_train, y_train_pred) * 100\n",
    "                row = [n_estimators, learning_rate, max_depth, \n",
    "                       subsample, train_r2, test_r2]\n",
    "                print(row)\n",
    "                results_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "255791be-bf64-41a2-b123-dc1dcf467dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_df = pd.DataFrame(results_list, columns = ['n_estimators', 'learning_rate', 'max_depth', 'subsample', 'train_r2', 'test_r2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17670c5c-ba46-4876-b613-1c5c1fd3ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_df.to_parquet(os.path.join('Results', \"Hyperparameter_TotalDatasetXgboost_ML.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a75b1d5-db98-4d18-a5d7-119465a846f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>0.8</td>\n",
       "      <td>73.276015</td>\n",
       "      <td>38.819217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>0.9</td>\n",
       "      <td>73.793809</td>\n",
       "      <td>38.815904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>72.578381</td>\n",
       "      <td>38.806969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>71.789944</td>\n",
       "      <td>38.805366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13</td>\n",
       "      <td>0.6</td>\n",
       "      <td>62.664853</td>\n",
       "      <td>38.801609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13</td>\n",
       "      <td>0.8</td>\n",
       "      <td>63.720814</td>\n",
       "      <td>38.796181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13</td>\n",
       "      <td>0.9</td>\n",
       "      <td>64.127907</td>\n",
       "      <td>38.783612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7</td>\n",
       "      <td>63.262146</td>\n",
       "      <td>38.778143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>69.956337</td>\n",
       "      <td>38.764403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>0.8</td>\n",
       "      <td>71.463968</td>\n",
       "      <td>38.764091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>0.9</td>\n",
       "      <td>71.986310</td>\n",
       "      <td>38.755320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>70.756293</td>\n",
       "      <td>38.751725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>80.668922</td>\n",
       "      <td>38.740163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13</td>\n",
       "      <td>0.6</td>\n",
       "      <td>61.084212</td>\n",
       "      <td>38.734057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>82.466233</td>\n",
       "      <td>38.732173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13</td>\n",
       "      <td>0.8</td>\n",
       "      <td>62.125486</td>\n",
       "      <td>38.726931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>55.389991</td>\n",
       "      <td>38.722085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7</td>\n",
       "      <td>61.678703</td>\n",
       "      <td>38.713233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>81.680261</td>\n",
       "      <td>38.713215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>78.787400</td>\n",
       "      <td>38.707857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_estimators  learning_rate  max_depth  subsample   train_r2    test_r2\n",
       "2017          1000           0.01         14        0.8  73.276015  38.819217\n",
       "2018          1000           0.01         14        0.9  73.793809  38.815904\n",
       "2016          1000           0.01         14        0.7  72.578381  38.806969\n",
       "2015          1000           0.01         14        0.6  71.789944  38.805366\n",
       "2010          1000           0.01         13        0.6  62.664853  38.801609\n",
       "2012          1000           0.01         13        0.8  63.720814  38.796181\n",
       "2013          1000           0.01         13        0.9  64.127907  38.783612\n",
       "2011          1000           0.01         13        0.7  63.262146  38.778143\n",
       "1805           900           0.01         14        0.6  69.956337  38.764403\n",
       "1807           900           0.01         14        0.8  71.463968  38.764091\n",
       "1808           900           0.01         14        0.9  71.986310  38.755320\n",
       "1806           900           0.01         14        0.7  70.756293  38.751725\n",
       "2020          1000           0.01         15        0.6  80.668922  38.740163\n",
       "1800           900           0.01         13        0.6  61.084212  38.734057\n",
       "2022          1000           0.01         15        0.8  82.466233  38.732173\n",
       "1802           900           0.01         13        0.8  62.125486  38.726931\n",
       "2007          1000           0.01         12        0.8  55.389991  38.722085\n",
       "1801           900           0.01         13        0.7  61.678703  38.713233\n",
       "2021          1000           0.01         15        0.7  81.680261  38.713215\n",
       "1810           900           0.01         15        0.6  78.787400  38.707857"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list_df.sort_values(by='test_r2', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc3810-e4ff-48d4-a758-9528064bcb35",
   "metadata": {},
   "source": [
    "### Fine tune other minor hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ab3d438-f098-4c97-8566-8040ec15ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_list = [0, 0.1, 1, 10]\n",
    "min_child_weight_list = [0, 0.1, 1, 10]\n",
    "max_delta_step_list = [0, 0.1, 1, 10]\n",
    "reg_lambda_list = [0, 0.1, 1, 10]\n",
    "reg_alpha_list = [0, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4b5bf52-c3fa-4210-86cf-7c5e28660a77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 74.58133572083632, 38.81875538628259]\n",
      "[0, 0, 0, 0, 0.1, 74.52356463079538, 38.80324844464739]\n",
      "[0, 0, 0, 0, 1, 73.77540911029969, 38.865454782458684]\n",
      "[0, 0, 0, 0, 10, 65.59706481001322, 38.833987826562]\n",
      "[0, 0, 0, 0.1, 0, 74.33991654963579, 38.77196281917331]\n",
      "[0, 0, 0, 0.1, 0.1, 74.29576741219832, 38.80584482581034]\n",
      "[0, 0, 0, 0.1, 1, 73.56716859162312, 38.82750552230313]\n",
      "[0, 0, 0, 0.1, 10, 65.59510278224437, 38.840330199992046]\n",
      "[0, 0, 0, 1, 0, 73.27601463838486, 38.81921693243814]\n",
      "[0, 0, 0, 1, 0.1, 73.19889984101783, 38.83919545358449]\n",
      "[0, 0, 0, 1, 1, 72.58537780161689, 38.852988567597066]\n",
      "[0, 0, 0, 1, 10, 65.1773119393791, 38.8460101018925]\n",
      "[0, 0, 0, 10, 0, 68.17592362662849, 38.83103191716574]\n",
      "[0, 0, 0, 10, 0.1, 68.17902379886345, 38.8663537582421]\n",
      "[0, 0, 0, 10, 1, 67.65182287510775, 38.86324265148138]\n",
      "[0, 0, 0, 10, 10, 62.248942548114904, 38.82000756994829]\n",
      "[0, 0, 0.1, 0, 0, 26.905007835954965, 25.65514206133853]\n",
      "[0, 0, 0.1, 0, 0.1, 26.37385521854343, 25.404325909849323]\n",
      "[0, 0, 0.1, 0, 1, 26.312658499611764, 25.397362458890772]\n",
      "[0, 0, 0.1, 0, 10, 26.015535524279677, 25.370324506983742]\n",
      "[0, 0, 0.1, 0.1, 0, 26.60696011001138, 25.549850940332853]\n",
      "[0, 0, 0.1, 0.1, 0.1, 26.370343279297103, 25.40235659118003]\n",
      "[0, 0, 0.1, 0.1, 1, 26.312351188679038, 25.39717196351313]\n",
      "[0, 0, 0.1, 0.1, 10, 26.016881441879914, 25.371039594703802]\n",
      "[0, 0, 0.1, 1, 0, 26.371163962634224, 25.402281544060557]\n",
      "[0, 0, 0.1, 1, 0.1, 26.365709809684446, 25.404057137171886]\n",
      "[0, 0, 0.1, 1, 1, 26.311736418486177, 25.395333690202072]\n",
      "[0, 0, 0.1, 1, 10, 26.014453964467176, 25.370011025889326]\n",
      "[0, 0, 0.1, 10, 0, 26.334356069512076, 25.394056483994188]\n",
      "[0, 0, 0.1, 10, 0.1, 26.327767946157376, 25.394317545527667]\n",
      "[0, 0, 0.1, 10, 1, 26.287256238013367, 25.389899761047296]\n",
      "[0, 0, 0.1, 10, 10, 26.010092643721872, 25.36922683050127]\n",
      "[0, 0, 1, 0, 0, 68.41143676668972, 38.85434075574757]\n",
      "[0, 0, 1, 0, 0.1, 68.35888231700436, 38.856161903952]\n",
      "[0, 0, 1, 0, 1, 67.91345983553643, 38.828128955207355]\n",
      "[0, 0, 1, 0, 10, 62.635299216140695, 38.823818934337964]\n",
      "[0, 0, 1, 0.1, 0, 68.38441839193132, 38.83778939850223]\n",
      "[0, 0, 1, 0.1, 0.1, 68.35141117739418, 38.88564798266163]\n",
      "[0, 0, 1, 0.1, 1, 67.90602697545202, 38.837547216343935]\n",
      "[0, 0, 1, 0.1, 10, 62.61559505264965, 38.84241806814166]\n",
      "[0, 0, 1, 1, 0, 68.33465906567847, 38.848988559213126]\n",
      "[0, 0, 1, 1, 0.1, 68.27243198323126, 38.85999152930727]\n",
      "[0, 0, 1, 1, 1, 67.83299558849501, 38.86001705034142]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reg_alpha \u001b[38;5;129;01min\u001b[39;00m reg_alpha_list:\n\u001b[1;32m      8\u001b[0m     model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m,  device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m                              n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m,  learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m, max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m,   subsample \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m     10\u001b[0m                              gamma \u001b[38;5;241m=\u001b[39m gamma, min_child_weight \u001b[38;5;241m=\u001b[39m min_child_weight, max_delta_step \u001b[38;5;241m=\u001b[39m max_delta_step,\n\u001b[1;32m     11\u001b[0m                              reg_lambda \u001b[38;5;241m=\u001b[39m reg_lambda, reg_alpha \u001b[38;5;241m=\u001b[39m reg_alpha, \n\u001b[1;32m     12\u001b[0m                              random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  )\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     15\u001b[0m     test_r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/sklearn.py:1090\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m (\n\u001b[1;32m   1082\u001b[0m     model,\n\u001b[1;32m   1083\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1089\u001b[0m )\n\u001b[0;32m-> 1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1000\t0.01\t14\t0.8\t73.276015\t38.819217\n",
    "results_list_otherhyper = []\n",
    "for gamma in gamma_list:\n",
    "    for min_child_weight in min_child_weight_list:\n",
    "        for max_delta_step in max_delta_step_list:\n",
    "            for reg_lambda in reg_lambda_list:\n",
    "                for reg_alpha in reg_alpha_list:\n",
    "                    model = xgb.XGBRegressor(objective='reg:squarederror',  device = 'cuda', tree_method='hist', \n",
    "                                             n_estimators = 1000,  learning_rate = 0.01, max_depth = 14,   subsample = 0.8,\n",
    "                                             gamma = gamma, min_child_weight = min_child_weight, max_delta_step = max_delta_step,\n",
    "                                             reg_lambda = reg_lambda, reg_alpha = reg_alpha, \n",
    "                                             random_state=42, enable_categorical=True  )\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    test_r2 = r2_score(y_test, y_pred) * 100\n",
    "                    y_train_pred = model.predict(X_train)\n",
    "                    train_r2 = r2_score(y_train, y_train_pred) * 100\n",
    "                    row = [gamma, min_child_weight, max_delta_step, reg_lambda, \n",
    "                           reg_alpha, train_r2, test_r2]\n",
    "                    print(row)\n",
    "                    model = None\n",
    "                    ym_pred = None\n",
    "                    ym_train_pred = None\n",
    "                    results_list_otherhyper.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685648a-fc43-42e8-aee5-32874d43fe86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46623bd5-e3f8-4021-92a8-ffa14abc6a33",
   "metadata": {},
   "source": [
    "### Bayes Search Hyperparameter (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cffedc56-d540-43ea-894c-e89a2cc0d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'n_estimators': Integer(100, 1000),\n",
    "    'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "    'max_depth': Integer(3, 16),\n",
    "    'subsample': Real(0.5, 1.0),\n",
    "    'min_child_weight': Real(0.001, 10, prior='log-uniform'),\n",
    "    'max_delta_step': Real(0.001, 10, prior='log-uniform'),\n",
    "    'reg_lambda': Real(0.001, 10, prior='log-uniform'),\n",
    "    'reg_alpha': Real(0.001, 10, prior='log-uniform'),\n",
    "    'gamma': Real(0.001, 10, prior='log-uniform')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09994470-4348-47a2-b1d3-af622b45d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror',  device = 'cuda', tree_method='hist', random_state=42, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d6a1b70-a769-46d3-8adc-ff4278c9c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_search = BayesSearchCV(\n",
    "    estimator=xgb_reg,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=20,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    n_jobs=10,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c08770b3-f8bf-44e6-8bae-600b43ce986e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:32:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:32:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:32:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:32:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:32:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:33:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:33:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:33:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:33:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:33:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=  17.0s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time= 1.1min\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  26.6s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time= 1.2min\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  28.3s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 2.5min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:46:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END gamma=0.001, learning_rate=0.05934108113313268, max_delta_step=1.7155379671672653, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=3.3562988535636995, subsample=0.5077999920334897; total time=  45.0s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=1.2503684029498734, max_depth=4, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.0026873611586649615, subsample=1.0; total time=  50.4s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.9026190989327987, max_depth=3, min_child_weight=10.0, n_estimators=334, reg_alpha=0.001, reg_lambda=0.001, subsample=0.8227007577862265; total time=  21.1s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=  17.7s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time= 1.1min\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  26.8s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time= 1.3min\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  28.3s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 2.5min\n",
      "[CV] END gamma=0.001, learning_rate=0.05934108113313268, max_delta_step=1.7155379671672653, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=3.3562988535636995, subsample=0.5077999920334897; total time=  45.6s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=1.2503684029498734, max_depth=4, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.0026873611586649615, subsample=1.0; total time=  50.2s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.9026190989327987, max_depth=3, min_child_weight=10.0, n_estimators=334, reg_alpha=0.001, reg_lambda=0.001, subsample=0.8227007577862265; total time=  21.2s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=  17.7s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time= 1.1min\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  26.8s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time= 1.3min\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  28.2s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 2.4min\n",
      "[CV] END gamma=0.001, learning_rate=0.05934108113313268, max_delta_step=1.7155379671672653, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=3.3562988535636995, subsample=0.5077999920334897; total time=  45.6s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=1.2503684029498734, max_depth=4, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.0026873611586649615, subsample=1.0; total time=  50.3s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.9026190989327987, max_depth=3, min_child_weight=10.0, n_estimators=334, reg_alpha=0.001, reg_lambda=0.001, subsample=0.8227007577862265; total time=  21.2s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=  17.6s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time= 1.1min\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  26.7s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time= 1.3min\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  28.1s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 2.5min\n",
      "[CV] END gamma=0.001, learning_rate=0.05934108113313268, max_delta_step=1.7155379671672653, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=3.3562988535636995, subsample=0.5077999920334897; total time=  45.6s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=1.2503684029498734, max_depth=4, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.0026873611586649615, subsample=1.0; total time=  50.5s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.9026190989327987, max_depth=3, min_child_weight=10.0, n_estimators=334, reg_alpha=0.001, reg_lambda=0.001, subsample=0.8227007577862265; total time=  21.1s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=  17.5s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time= 1.1min\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  26.9s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time= 1.3min\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  28.0s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 2.5min\n",
      "[CV] END gamma=0.001, learning_rate=0.05934108113313268, max_delta_step=1.7155379671672653, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=3.3562988535636995, subsample=0.5077999920334897; total time=  45.4s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=1.2503684029498734, max_depth=4, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.0026873611586649615, subsample=1.0; total time=  50.3s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.9026190989327987, max_depth=3, min_child_weight=10.0, n_estimators=334, reg_alpha=0.001, reg_lambda=0.001, subsample=0.8227007577862265; total time=  21.1s\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  41.3s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  39.3s\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 2.4min\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time= 1.8min\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  34.9s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  43.9s\n",
      "[CV] END gamma=0.001, learning_rate=0.0758200696416608, max_delta_step=6.968116892833723, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5695099042811981; total time=  45.1s\n",
      "[CV] END gamma=0.001, learning_rate=0.02611778309604193, max_delta_step=0.9106232964007198, max_depth=3, min_child_weight=0.6902431324809459, n_estimators=765, reg_alpha=10.0, reg_lambda=0.009282203078447272, subsample=0.6289620185166818; total time=  37.8s\n",
      "[CV] END gamma=10.0, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  45.9s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.4924505774678406, max_depth=15, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=36.2min\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  41.4s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  39.1s\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 2.3min\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time= 1.8min\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  34.9s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  43.6s\n",
      "[CV] END gamma=0.001, learning_rate=0.0758200696416608, max_delta_step=6.968116892833723, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5695099042811981; total time=  44.8s\n",
      "[CV] END gamma=0.001, learning_rate=0.02611778309604193, max_delta_step=0.9106232964007198, max_depth=3, min_child_weight=0.6902431324809459, n_estimators=765, reg_alpha=10.0, reg_lambda=0.009282203078447272, subsample=0.6289620185166818; total time=  37.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  45.7s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.4924505774678406, max_depth=15, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=36.3min\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  41.2s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  38.7s\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 2.4min\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time= 1.8min\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  34.5s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  43.7s\n",
      "[CV] END gamma=0.001, learning_rate=0.0758200696416608, max_delta_step=6.968116892833723, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5695099042811981; total time=  44.9s\n",
      "[CV] END gamma=0.001, learning_rate=0.02611778309604193, max_delta_step=0.9106232964007198, max_depth=3, min_child_weight=0.6902431324809459, n_estimators=765, reg_alpha=10.0, reg_lambda=0.009282203078447272, subsample=0.6289620185166818; total time=  37.8s\n",
      "[CV] END gamma=10.0, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  45.8s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.4924505774678406, max_depth=15, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=36.5min\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  41.2s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  39.1s\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 2.3min\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time= 1.8min\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  34.7s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  43.8s\n",
      "[CV] END gamma=0.001, learning_rate=0.0758200696416608, max_delta_step=6.968116892833723, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5695099042811981; total time=  45.0s\n",
      "[CV] END gamma=0.001, learning_rate=0.02611778309604193, max_delta_step=0.9106232964007198, max_depth=3, min_child_weight=0.6902431324809459, n_estimators=765, reg_alpha=10.0, reg_lambda=0.009282203078447272, subsample=0.6289620185166818; total time=  37.5s\n",
      "[CV] END gamma=10.0, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  46.0s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.4924505774678406, max_depth=15, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=36.5min\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  41.4s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  39.1s\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 2.3min\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time= 1.8min\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  34.9s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  43.9s\n",
      "[CV] END gamma=0.001, learning_rate=0.0758200696416608, max_delta_step=6.968116892833723, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5695099042811981; total time=  44.6s\n",
      "[CV] END gamma=0.001, learning_rate=0.02611778309604193, max_delta_step=0.9106232964007198, max_depth=3, min_child_weight=0.6902431324809459, n_estimators=765, reg_alpha=10.0, reg_lambda=0.009282203078447272, subsample=0.6289620185166818; total time=  37.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  45.4s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.4924505774678406, max_depth=15, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=36.6min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [15:27:05] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [15:27:05] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [15:27:05] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [15:27:05] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [15:27:05] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=&#x27;cuda&#x27;,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=True, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None...\n",
       "                             &#x27;min_child_weight&#x27;: Real(low=0.001, high=10, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=100, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_alpha&#x27;: Real(low=0.001, high=10, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0.001, high=10, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;subsample&#x27;: Real(low=0.5, high=1.0, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=&#x27;cuda&#x27;,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=True, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None...\n",
       "                             &#x27;min_child_weight&#x27;: Real(low=0.001, high=10, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=100, high=1000, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_alpha&#x27;: Real(low=0.001, high=10, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;reg_lambda&#x27;: Real(low=0.001, high=10, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;subsample&#x27;: Real(low=0.5, high=1.0, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device='cuda',\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=True, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None...\n",
       "                             'min_child_weight': Real(low=0.001, high=10, prior='log-uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=100, high=1000, prior='uniform', transform='normalize'),\n",
       "                             'reg_alpha': Real(low=0.001, high=10, prior='log-uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=0.001, high=10, prior='log-uniform', transform='normalize'),\n",
       "                             'subsample': Real(low=0.5, high=1.0, prior='uniform', transform='normalize')},\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37d25d1e-ea2b-4587-8375-a2ec1fe7c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_result = bayes_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48b96b64-7e93-4161-8278-c207141b84c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_delta_step</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49.694564</td>\n",
       "      <td>0.135453</td>\n",
       "      <td>0.644396</td>\n",
       "      <td>0.068352</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.250368</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'gamma': 0.001, 'learning_rate': 0.0999999999...</td>\n",
       "      <td>0.375747</td>\n",
       "      <td>0.374343</td>\n",
       "      <td>0.373692</td>\n",
       "      <td>0.375783</td>\n",
       "      <td>0.376273</td>\n",
       "      <td>0.375168</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.628238</td>\n",
       "      <td>0.040589</td>\n",
       "      <td>0.659970</td>\n",
       "      <td>0.071617</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.02854</td>\n",
       "      <td>5.388551</td>\n",
       "      <td>7</td>\n",
       "      <td>0.479283</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652232</td>\n",
       "      <td>{'gamma': 0.04369339947510315, 'learning_rate'...</td>\n",
       "      <td>0.374639</td>\n",
       "      <td>0.373494</td>\n",
       "      <td>0.372273</td>\n",
       "      <td>0.374577</td>\n",
       "      <td>0.374843</td>\n",
       "      <td>0.373965</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34.293579</td>\n",
       "      <td>0.156735</td>\n",
       "      <td>0.475605</td>\n",
       "      <td>0.027637</td>\n",
       "      <td>6.636085</td>\n",
       "      <td>0.025191</td>\n",
       "      <td>3.066251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.033439</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797189</td>\n",
       "      <td>{'gamma': 6.6360850776123375, 'learning_rate':...</td>\n",
       "      <td>0.371472</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.368955</td>\n",
       "      <td>0.371285</td>\n",
       "      <td>0.371509</td>\n",
       "      <td>0.370685</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.630808</td>\n",
       "      <td>0.086621</td>\n",
       "      <td>0.552814</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.043218</td>\n",
       "      <td>0.92285</td>\n",
       "      <td>6</td>\n",
       "      <td>0.206375</td>\n",
       "      <td>347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946919</td>\n",
       "      <td>{'gamma': 0.0010340016434251913, 'learning_rat...</td>\n",
       "      <td>0.370928</td>\n",
       "      <td>0.369633</td>\n",
       "      <td>0.368478</td>\n",
       "      <td>0.370743</td>\n",
       "      <td>0.370781</td>\n",
       "      <td>0.370113</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43.213811</td>\n",
       "      <td>0.104432</td>\n",
       "      <td>0.573386</td>\n",
       "      <td>0.024014</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'gamma': 0.001, 'learning_rate': 0.0999999999...</td>\n",
       "      <td>0.368785</td>\n",
       "      <td>0.367462</td>\n",
       "      <td>0.366433</td>\n",
       "      <td>0.368457</td>\n",
       "      <td>0.368875</td>\n",
       "      <td>0.368002</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44.331663</td>\n",
       "      <td>0.210532</td>\n",
       "      <td>0.557530</td>\n",
       "      <td>0.054852</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.07582</td>\n",
       "      <td>6.968117</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56951</td>\n",
       "      <td>{'gamma': 0.001, 'learning_rate': 0.0758200696...</td>\n",
       "      <td>0.368638</td>\n",
       "      <td>0.367105</td>\n",
       "      <td>0.366308</td>\n",
       "      <td>0.368362</td>\n",
       "      <td>0.368620</td>\n",
       "      <td>0.367807</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>148.455940</td>\n",
       "      <td>3.286484</td>\n",
       "      <td>0.634548</td>\n",
       "      <td>0.179568</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'gamma': 10.0, 'learning_rate': 0.09999999999...</td>\n",
       "      <td>0.368722</td>\n",
       "      <td>0.366784</td>\n",
       "      <td>0.365452</td>\n",
       "      <td>0.367377</td>\n",
       "      <td>0.368151</td>\n",
       "      <td>0.367297</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44.772206</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>0.671334</td>\n",
       "      <td>0.129406</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.059341</td>\n",
       "      <td>1.715538</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5078</td>\n",
       "      <td>{'gamma': 0.001, 'learning_rate': 0.0593410811...</td>\n",
       "      <td>0.367366</td>\n",
       "      <td>0.366057</td>\n",
       "      <td>0.364972</td>\n",
       "      <td>0.367360</td>\n",
       "      <td>0.367449</td>\n",
       "      <td>0.366641</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44.716399</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.571311</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.038965</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'gamma': 0.001, 'learning_rate': 0.0389652389...</td>\n",
       "      <td>0.364797</td>\n",
       "      <td>0.363662</td>\n",
       "      <td>0.362313</td>\n",
       "      <td>0.365305</td>\n",
       "      <td>0.364944</td>\n",
       "      <td>0.364204</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20.528313</td>\n",
       "      <td>0.068313</td>\n",
       "      <td>0.616276</td>\n",
       "      <td>0.057817</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.902619</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822701</td>\n",
       "      <td>{'gamma': 10.0, 'learning_rate': 0.09999999999...</td>\n",
       "      <td>0.364889</td>\n",
       "      <td>0.363329</td>\n",
       "      <td>0.362535</td>\n",
       "      <td>0.365009</td>\n",
       "      <td>0.365063</td>\n",
       "      <td>0.364165</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_gamma  \\\n",
       "15      49.694564      0.135453         0.644396        0.068352       0.001   \n",
       "0       40.628238      0.040589         0.659970        0.071617    0.043693   \n",
       "8       34.293579      0.156735         0.475605        0.027637    6.636085   \n",
       "9       27.630808      0.086621         0.552814        0.067909    0.001034   \n",
       "10      43.213811      0.104432         0.573386        0.024014       0.001   \n",
       "12      44.331663      0.210532         0.557530        0.054852       0.001   \n",
       "11     148.455940      3.286484         0.634548        0.179568        10.0   \n",
       "13      44.772206      0.095400         0.671334        0.129406       0.001   \n",
       "19      44.716399      0.128205         0.571311        0.056044       0.001   \n",
       "17      20.528313      0.068313         0.616276        0.057817        10.0   \n",
       "\n",
       "   param_learning_rate param_max_delta_step param_max_depth  \\\n",
       "15                 0.1             1.250368               4   \n",
       "0              0.02854             5.388551               7   \n",
       "8             0.025191             3.066251               8   \n",
       "9             0.043218              0.92285               6   \n",
       "10                 0.1                 10.0               3   \n",
       "12             0.07582             6.968117               3   \n",
       "11                 0.1                 10.0              16   \n",
       "13            0.059341             1.715538               3   \n",
       "19            0.038965                 10.0               3   \n",
       "17                 0.1             1.902619               3   \n",
       "\n",
       "   param_min_child_weight param_n_estimators  ... param_subsample  \\\n",
       "15                   10.0               1000  ...             1.0   \n",
       "0                0.479283                473  ...        0.652232   \n",
       "8                0.033439                290  ...        0.797189   \n",
       "9                0.206375                347  ...        0.946919   \n",
       "10                  0.001               1000  ...             0.5   \n",
       "12                  0.001               1000  ...         0.56951   \n",
       "11                  0.001                100  ...             0.5   \n",
       "13                  0.001               1000  ...          0.5078   \n",
       "19                  0.001               1000  ...             1.0   \n",
       "17                   10.0                334  ...        0.822701   \n",
       "\n",
       "                                               params split0_test_score  \\\n",
       "15  {'gamma': 0.001, 'learning_rate': 0.0999999999...          0.375747   \n",
       "0   {'gamma': 0.04369339947510315, 'learning_rate'...          0.374639   \n",
       "8   {'gamma': 6.6360850776123375, 'learning_rate':...          0.371472   \n",
       "9   {'gamma': 0.0010340016434251913, 'learning_rat...          0.370928   \n",
       "10  {'gamma': 0.001, 'learning_rate': 0.0999999999...          0.368785   \n",
       "12  {'gamma': 0.001, 'learning_rate': 0.0758200696...          0.368638   \n",
       "11  {'gamma': 10.0, 'learning_rate': 0.09999999999...          0.368722   \n",
       "13  {'gamma': 0.001, 'learning_rate': 0.0593410811...          0.367366   \n",
       "19  {'gamma': 0.001, 'learning_rate': 0.0389652389...          0.364797   \n",
       "17  {'gamma': 10.0, 'learning_rate': 0.09999999999...          0.364889   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "15          0.374343           0.373692           0.375783           0.376273   \n",
       "0           0.373494           0.372273           0.374577           0.374843   \n",
       "8           0.370205           0.368955           0.371285           0.371509   \n",
       "9           0.369633           0.368478           0.370743           0.370781   \n",
       "10          0.367462           0.366433           0.368457           0.368875   \n",
       "12          0.367105           0.366308           0.368362           0.368620   \n",
       "11          0.366784           0.365452           0.367377           0.368151   \n",
       "13          0.366057           0.364972           0.367360           0.367449   \n",
       "19          0.363662           0.362313           0.365305           0.364944   \n",
       "17          0.363329           0.362535           0.365009           0.365063   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "15         0.375168        0.000979                1  \n",
       "0          0.373965        0.000968                2  \n",
       "8          0.370685        0.000988                3  \n",
       "9          0.370113        0.000939                4  \n",
       "10         0.368002        0.000931                5  \n",
       "12         0.367807        0.000938                6  \n",
       "11         0.367297        0.001134                7  \n",
       "13         0.366641        0.000982                8  \n",
       "19         0.364204        0.001094                9  \n",
       "17         0.364165        0.001039               10  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.03896523891612038, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  45.4s\n",
      "[CV] END gamma=0.001, learning_rate=0.03896523891612038, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  45.1s\n",
      "[CV] END gamma=0.001, learning_rate=0.03896523891612038, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  45.2s\n",
      "[CV] END gamma=0.001, learning_rate=0.03896523891612038, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  45.4s\n",
      "[CV] END gamma=0.001, learning_rate=0.03896523891612038, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  45.4s\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(CV_result).sort_values(by='rank_test_score', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14703b0-c200-425b-bd8d-68b47bef81b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a6d03f-8213-4fe0-b3f5-623e79514eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc9b7fc7-e8f4-4624-8653-08e627e9fcd1",
   "metadata": {},
   "source": [
    "### Bayes Search Hyperparameter (Test 3 times 1:9 CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6bfb14e-ad20-45d6-b6c7-5279c5772ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'n_estimators': Integer(100, 1000),\n",
    "    'learning_rate': Real(0.001, 0.1, prior='log-uniform'),\n",
    "    'max_depth': Integer(3, 16),\n",
    "    'subsample': Real(0.5, 1.0),\n",
    "    'min_child_weight': Real(0.001, 10, prior='log-uniform'),\n",
    "    'max_delta_step': Real(0.001, 10, prior='log-uniform'),\n",
    "    'reg_lambda': Real(0.001, 10, prior='log-uniform'),\n",
    "    'reg_alpha': Real(0.001, 10, prior='log-uniform'),\n",
    "    'gamma': Real(0.001, 10, prior='log-uniform')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f4c7fbc-cbbd-4376-a5b1-6de72bd23bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror',  device = 'cuda', tree_method='hist', random_state=42, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef3fa6ad-394e-4823-96e7-59835f4900db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_search = BayesSearchCV(\n",
    "    estimator=xgb_reg,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=200,\n",
    "    scoring='r2',\n",
    "    cv=10,\n",
    "    n_jobs=2,\n",
    "    n_points = 1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    return_train_score = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "964f81a3-5141-4dce-9bf8-e47c90bd6f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:00:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:00:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  18.2s\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  18.7s\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  19.0s\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  18.6s\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  18.8s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   7.7s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   8.7s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   8.3s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   7.6s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   7.7s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.4s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.4s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.4s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.9s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.1s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  27.5s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  28.2s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  28.1s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  28.1s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  27.6s\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  18.7s\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  18.6s\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  18.9s\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  18.6s\n",
      "[CV] END gamma=0.04369339947510315, learning_rate=0.02853983686604182, max_delta_step=5.388550972627239, max_depth=7, min_child_weight=0.47928274405969296, n_estimators=473, reg_alpha=0.025335258486348353, reg_lambda=0.9078559343576645, subsample=0.6522316555182531; total time=  18.8s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   7.7s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   8.7s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   8.3s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   7.7s\n",
      "[CV] END gamma=2.236420282054271, learning_rate=0.058429282697611454, max_delta_step=0.016354619314682416, max_depth=15, min_child_weight=2.8609591832863424, n_estimators=156, reg_alpha=0.0035746551640890665, reg_lambda=0.025962684183737327, subsample=0.8178645509395852; total time=   7.6s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.5s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.4s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.1s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.6s\n",
      "[CV] END gamma=0.06016307829589929, learning_rate=0.06877728743793542, max_delta_step=0.002626858226437905, max_depth=9, min_child_weight=0.005647038458633676, n_estimators=508, reg_alpha=0.00418593245501055, reg_lambda=1.0144020667237337, subsample=0.7786702115169006; total time=  18.5s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  27.7s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  27.0s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  28.3s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  28.0s\n",
      "[CV] END gamma=1.7765766649807682, learning_rate=0.0022066991249460105, max_delta_step=0.24671088435225733, max_depth=13, min_child_weight=0.12365432532396153, n_estimators=186, reg_alpha=1.0548777482285936, reg_lambda=3.094007864244482, subsample=0.9559644307534418; total time=  27.3s\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:09:04] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:09:04] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.1min\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.1min\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.0min\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.0min\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  12.1s\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  11.9s\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  12.3s\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  12.3s\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  12.1s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  50.9s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  49.3s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  48.9s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  49.4s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  49.7s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  33.6s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  33.6s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  31.9s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  33.0s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  32.3s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  15.0s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  15.0s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  15.0s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  14.7s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  15.3s\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.9s\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.6s\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.8s\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.6s\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.1min\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.1min\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.1min\n",
      "[CV] END gamma=1.5783879853890563, learning_rate=0.007517239253342656, max_delta_step=0.1277853151889843, max_depth=12, min_child_weight=4.124851234284971, n_estimators=745, reg_alpha=0.04974074547470406, reg_lambda=0.3991502512609639, subsample=0.6765419227639857; total time= 1.0min\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  12.0s\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  12.0s\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  12.3s\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  12.1s\n",
      "[CV] END gamma=0.8632012725909878, learning_rate=0.0756379021867824, max_delta_step=0.004512619487621619, max_depth=5, min_child_weight=1.5922561163725886, n_estimators=435, reg_alpha=0.06856430159759418, reg_lambda=0.1377401781906964, subsample=0.8926419685712479; total time=  12.0s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  50.0s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  49.4s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  49.5s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  49.8s\n",
      "[CV] END gamma=0.2939797620271688, learning_rate=0.035540927532494104, max_delta_step=0.027295542332669995, max_depth=14, min_child_weight=0.23468141668216005, n_estimators=635, reg_alpha=0.393649803341925, reg_lambda=0.048789946714619455, subsample=0.866941242634403; total time=  49.3s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  33.1s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  32.9s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  32.9s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  33.2s\n",
      "[CV] END gamma=0.14914622679778672, learning_rate=0.06918603669668356, max_delta_step=0.09679809588492402, max_depth=14, min_child_weight=0.019780621330832346, n_estimators=146, reg_alpha=0.19191601211845516, reg_lambda=0.0012682484500023282, subsample=0.6928647954923324; total time=  32.8s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  15.2s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  14.7s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  14.9s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  14.9s\n",
      "[CV] END gamma=6.6360850776123375, learning_rate=0.02519085390684862, max_delta_step=3.0662510776734475, max_depth=8, min_child_weight=0.03343944487838535, n_estimators=290, reg_alpha=0.001000562456331363, reg_lambda=0.030390787275205566, subsample=0.7971894567956928; total time=  15.4s\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.8s\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.7s\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.9s\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.5s\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.5s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  21.7s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  21.0s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  20.4s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  21.2s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  20.8s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.0010340016434251913, learning_rate=0.04321753967138224, max_delta_step=0.9228497044562662, max_depth=6, min_child_weight=0.20637512290600768, n_estimators=347, reg_alpha=0.017838454498583053, reg_lambda=0.0040773533275832545, subsample=0.9469190305262598; total time=  12.4s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  21.6s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  20.7s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  20.2s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  21.0s\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=  20.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:33:50] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:33:52] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.6min\n",
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:41:39] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.6min\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.6s\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.5s\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.1s\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.4s\n",
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:52:44] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.6min\n",
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.6min\n",
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.07611226347834164, max_delta_step=6.992852587738992, max_depth=16, min_child_weight=0.013476245220705231, n_estimators=100, reg_alpha=0.001, reg_lambda=0.01667430948497155, subsample=0.9097411980575998; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.6min\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.6min\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.05841776573401546, max_delta_step=1.7247730889043573, max_depth=16, min_child_weight=0.5513433501697573, n_estimators=100, reg_alpha=10.0, reg_lambda=0.05367649223788274, subsample=0.6246352714878577; total time= 1.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.6s\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.3s\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.2s\n",
      "[CV] END gamma=10.0, learning_rate=0.02772131240470908, max_delta_step=0.9245484203714865, max_depth=11, min_child_weight=0.001, n_estimators=100, reg_alpha=10.0, reg_lambda=0.012082921009542105, subsample=1.0; total time=  16.6s\n",
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:59:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:59:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  58.3s\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  57.1s\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  57.4s\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  57.8s\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  57.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.04796355283222573, max_delta_step=3.2341084031097327, max_depth=16, min_child_weight=5.904053196617127, n_estimators=214, reg_alpha=0.047307939444504, reg_lambda=10.0, subsample=1.0; total time= 2.4min\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  59.0s\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  57.7s\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  56.9s\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  56.9s\n",
      "[CV] END gamma=0.002828842352942036, learning_rate=0.01170190170614538, max_delta_step=10.0, max_depth=10, min_child_weight=4.517989380255843, n_estimators=620, reg_alpha=6.516740707911033, reg_lambda=5.164814830184374, subsample=0.8143945636218808; total time=  57.9s\n",
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:11:35] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:11:40] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:18:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:21:39] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.012028403900773971, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time= 3.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:28:01] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:28:02] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:34:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:34:21] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.013067084164594452, max_delta_step=10.0, max_depth=12, min_child_weight=0.001, n_estimators=962, reg_alpha=10.0, reg_lambda=10.0, subsample=0.95832726161362; total time= 3.1min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:39:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:40:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.5min\n",
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:45:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:45:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.5min\n",
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.5min\n",
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:50:00] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:50:12] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  20.5s\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  20.0s\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  20.4s\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  19.6s\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  19.6s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  19.1s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  19.4s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  18.7s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  18.7s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  17.6s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  22.4s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  22.9s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  23.2s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  22.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  22.7s\n",
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.027219950331790716, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=100, reg_alpha=10.0, reg_lambda=0.2875017401719533, subsample=0.5192431312341648; total time= 2.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=1.7632544414607474, max_depth=16, min_child_weight=0.001, n_estimators=100, reg_alpha=1.434633972096292, reg_lambda=0.006921985922696136, subsample=0.6574218371945808; total time= 1.3min\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  20.5s\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  19.9s\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  20.3s\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  19.5s\n",
      "[CV] END gamma=7.10768527381727, learning_rate=0.01652552389742053, max_delta_step=5.369648661303252, max_depth=3, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=  19.5s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  18.7s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  19.0s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  18.4s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  18.5s\n",
      "[CV] END gamma=0.5632265798021708, learning_rate=0.001, max_delta_step=0.001, max_depth=15, min_child_weight=0.018177750161563158, n_estimators=669, reg_alpha=10.0, reg_lambda=0.9149533741751668, subsample=0.7481717568221748; total time=  17.0s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  22.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  22.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  23.0s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  22.9s\n",
      "[CV] END gamma=10.0, learning_rate=0.03738653904929445, max_delta_step=10.0, max_depth=5, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.1571889644470835, subsample=1.0; total time=  23.2s\n",
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:08:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:08:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 3.0min\n",
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 2.9min\n",
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 3.0min\n",
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:14:10] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:14:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 2.9min\n",
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 3.0min\n",
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 2.9min\n",
      "[CV] END gamma=0.00227977935435408, learning_rate=0.09999999999999999, max_delta_step=1.2020998885017047, max_depth=14, min_child_weight=10.0, n_estimators=289, reg_alpha=0.001, reg_lambda=0.001, subsample=0.540284723778036; total time= 2.9min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:17:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:17:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  14.0s\n",
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  13.6s\n",
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  13.1s\n",
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  13.0s\n",
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  14.0s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  21.2s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  20.5s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  20.9s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  20.7s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  20.4s\n",
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  14.2s\n",
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  13.7s\n",
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  13.0s\n",
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  12.9s\n",
      "[CV] END gamma=0.004612458776591067, learning_rate=0.037520799363181645, max_delta_step=1.261788867438796, max_depth=3, min_child_weight=10.0, n_estimators=580, reg_alpha=10.0, reg_lambda=10.0, subsample=0.6324175040138821; total time=  13.8s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  20.9s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  20.6s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  21.2s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  21.3s\n",
      "[CV] END gamma=1.695676578804205, learning_rate=0.001, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=977, reg_alpha=10.0, reg_lambda=3.0954100665991993, subsample=1.0; total time=  20.4s\n",
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:30:07] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:30:07] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.7min\n",
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.8min\n",
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:39:35] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:39:57] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.7min\n",
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.8min\n",
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.006237111219805693, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=217, reg_alpha=10.0, reg_lambda=0.007822475205056462, subsample=0.7289643939912662; total time= 4.7min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:58:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:58:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.4min\n",
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:25:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:25:30] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.3min\n",
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.4min\n",
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.7min\n",
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:52:12] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:52:30] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.4min\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   8.1s\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   8.4s\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   7.8s\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   8.4s\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   7.9s\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n",
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=36.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.02497463072764877, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=600, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5496664140976447; total time=13.7min\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   8.2s\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   8.3s\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   8.0s\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   8.4s\n",
      "[CV] END gamma=0.001, learning_rate=0.041042942876528696, max_delta_step=10.0, max_depth=3, min_child_weight=0.001, n_estimators=288, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time=   7.7s\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.03876020251401782, max_delta_step=3.7306708396184787, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.030095977377566127, reg_lambda=0.001, subsample=1.0; total time= 3.3min\n",
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=36.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:21:22] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:22:30] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=35.7min\n",
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=35.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=36.9min\n",
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=36.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [17:33:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [17:35:49] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=36.1min\n",
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=36.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=36.5min\n",
      "[CV] END gamma=0.001, learning_rate=0.04572299092674563, max_delta_step=2.3709526901583176, max_depth=16, min_child_weight=0.001, n_estimators=949, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5; total time=35.5min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [18:12:56] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [18:12:57] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.4min\n",
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.4min\n",
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.4min\n",
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.4min\n",
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.3min\n",
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=41.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.4min\n",
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.4min\n",
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.3min\n",
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.3min\n",
      "[CV] END gamma=0.5347724140970809, learning_rate=0.019890899105983437, max_delta_step=10.0, max_depth=10, min_child_weight=0.001, n_estimators=907, reg_alpha=0.4606162362150807, reg_lambda=0.001, subsample=1.0; total time= 1.3min\n",
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=42.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [19:42:25] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [19:42:57] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=42.1min\n",
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=42.3min\n",
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=42.1min\n",
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=42.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [21:06:35] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [21:07:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=41.7min\n",
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=41.0min\n",
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=41.9min\n",
      "[CV] END gamma=0.001, learning_rate=0.012598685829166626, max_delta_step=10.0, max_depth=16, min_child_weight=0.08979549630100576, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=0.5; total time=41.6min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [21:50:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [21:50:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.0min\n",
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=16.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=0.2674397253274466, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.0028100758868447374, subsample=0.9956763999033221; total time= 1.1min\n",
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=16.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [22:28:30] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [22:28:43] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=16.7min\n",
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=16.8min\n",
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=16.9min\n",
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=17.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [23:02:21] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [23:02:49] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=16.9min\n",
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=17.1min\n",
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=17.0min\n",
      "[CV] END gamma=0.001, learning_rate=0.045273300701147906, max_delta_step=0.38292669771554716, max_depth=16, min_child_weight=0.2666795642464577, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6502481227779341; total time=16.7min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [23:20:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [23:20:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  21.4s\n",
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  21.2s\n",
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  20.1s\n",
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  20.5s\n",
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  19.7s\n",
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=20.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  21.3s\n",
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  21.0s\n",
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  20.8s\n",
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  20.8s\n",
      "[CV] END gamma=10.0, learning_rate=0.057789854848598186, max_delta_step=0.31485804799575284, max_depth=3, min_child_weight=0.034159041671621974, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=  19.5s\n",
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=21.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [00:03:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [00:03:46] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=20.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=20.3min\n",
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=21.1min\n",
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=20.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [00:44:13] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [00:45:02] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=20.7min\n",
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=20.9min\n",
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=20.5min\n",
      "[CV] END gamma=0.001, learning_rate=0.014584277354578675, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.001, subsample=0.6264697298424771; total time=20.6min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [01:14:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [01:14:49] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.1min\n",
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.1min\n",
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [01:33:06] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [01:33:12] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.1min\n",
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.2min\n",
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.1min\n",
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [01:51:34] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [01:51:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.2min\n",
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=12.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=1.1555906805788534, learning_rate=0.030585674668859378, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0; total time= 9.3min\n",
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=13.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [02:17:25] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [02:18:10] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=12.7min\n",
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=13.0min\n",
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=13.2min\n",
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=12.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [02:43:38] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [02:43:52] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=13.1min\n",
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=12.9min\n",
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=12.6min\n",
      "[CV] END gamma=0.003339180182802951, learning_rate=0.023351980774009528, max_delta_step=3.806235328016709, max_depth=16, min_child_weight=0.001, n_estimators=479, reg_alpha=10.0, reg_lambda=0.008272389007223439, subsample=1.0; total time=12.8min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [03:07:51] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [03:08:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=11.0min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=11.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=11.2min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [03:29:48] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [03:30:27] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=10.8min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=10.8min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=11.2min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=11.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [03:51:40] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [03:52:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=10.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 2.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 2.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 1.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 1.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 2.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 5.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 4.8min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 4.6min\n",
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [04:48:11] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.4min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=0.7118263856334951, max_depth=16, min_child_weight=0.020874913422095322, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.00579858115115241, subsample=1.0; total time=11.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 2.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 1.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 2.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 2.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5; total time= 1.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 4.8min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 4.7min\n",
      "[CV] END gamma=10.0, learning_rate=0.02706184152539001, max_delta_step=1.0356756695117604, max_depth=16, min_child_weight=10.0, n_estimators=659, reg_alpha=0.001, reg_lambda=0.001, subsample=0.898681270538461; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.6min\n",
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.02115580568487585, max_delta_step=4.927469000716437, max_depth=16, min_child_weight=0.0018996425602431234, n_estimators=688, reg_alpha=0.001, reg_lambda=10.0, subsample=1.0; total time= 5.2min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=18.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [05:13:04] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [05:30:24] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=19.1min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=18.4min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=18.3min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=18.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [05:50:07] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [06:07:48] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=18.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=18.1min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=18.8min\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=17.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [06:26:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.001, learning_rate=0.09999999999999999, max_delta_step=10.0, max_depth=16, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.001, subsample=1.0; total time=18.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [06:29:55] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [06:33:26] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [06:43:56] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.5min\n",
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=31.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.5min\n",
      "[CV] END gamma=10.0, learning_rate=0.03826996331305449, max_delta_step=1.380088907134544, max_depth=16, min_child_weight=0.001, n_estimators=630, reg_alpha=10.0, reg_lambda=0.0461141097839343, subsample=0.5; total time= 3.4min\n",
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=32.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [07:48:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [07:48:46] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=32.4min\n",
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=31.5min\n",
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=32.3min\n",
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=32.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [08:52:12] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [08:53:50] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=31.8min\n",
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=32.0min\n",
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=32.9min\n",
      "[CV] END gamma=0.042891173479585355, learning_rate=0.04751824200178501, max_delta_step=0.36968877274666395, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=0.001, reg_lambda=0.08504807967855205, subsample=0.5443655512295833; total time=31.4min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [09:27:43] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [09:27:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [09:34:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.2min\n",
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 9.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.3min\n",
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.2min\n",
      "[CV] END gamma=10.0, learning_rate=0.04937062520615426, max_delta_step=0.5323537543183766, max_depth=16, min_child_weight=0.001, n_estimators=678, reg_alpha=10.0, reg_lambda=0.0035624944073803654, subsample=1.0; total time= 2.2min\n",
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=10.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [09:56:21] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [09:56:54] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 9.8min\n",
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 9.9min\n",
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time=10.0min\n",
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 9.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [10:16:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [10:16:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 9.9min\n",
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 9.8min\n",
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 9.8min\n",
      "[CV] END gamma=0.001, learning_rate=0.020795772393417657, max_delta_step=3.0923998962264942, max_depth=16, min_child_weight=10.0, n_estimators=482, reg_alpha=10.0, reg_lambda=0.001, subsample=0.5; total time= 9.7min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [10:36:56] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [10:36:56] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time=10.4min\n",
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time=10.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time=10.4min\n",
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time=10.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [10:57:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [10:57:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time=10.0min\n",
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time=10.0min\n",
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time=10.1min\n",
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time=10.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:17:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:18:00] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time=10.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:32:39] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [11:42:17] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.7652928878618932, learning_rate=0.03363820956138038, max_delta_step=0.6296256959375663, max_depth=16, min_child_weight=0.001, n_estimators=1000, reg_alpha=10.0, reg_lambda=9.99999999999999, subsample=1.0; total time= 9.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.8min\n",
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.8min\n",
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.8min\n",
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=11.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.027465627252534496, max_delta_step=10.0, max_depth=16, min_child_weight=0.4742808303133779, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.044317525391420504, subsample=0.5; total time= 4.8min\n",
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=11.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:04:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:05:05] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=10.8min\n",
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=11.2min\n",
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=11.4min\n",
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:26:30] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [12:27:38] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=10.9min\n",
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=11.2min\n",
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=11.4min\n",
      "[CV] END gamma=0.005421226860924486, learning_rate=0.0339913877655914, max_delta_step=1.817526030761908, max_depth=16, min_child_weight=0.001, n_estimators=486, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8000665391754787; total time=10.6min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:15:35] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [13:16:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=37.8min\n",
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=37.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=37.3min\n",
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=38.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:30:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [14:32:37] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=36.8min\n",
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=37.5min\n",
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=38.6min\n",
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=37.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [15:45:26] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [15:47:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=36.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 7.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.017151697657707164, learning_rate=0.010928881741783176, max_delta_step=2.3646861193522284, max_depth=16, min_child_weight=3.1160458807154843, n_estimators=1000, reg_alpha=0.3010498300240876, reg_lambda=0.007109134212147961, subsample=0.9824243638640624; total time=37.4min\n",
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 7.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:01:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:01:25] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 6.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 7.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 7.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 7.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:15:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:15:37] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 6.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 6.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 7.1min\n",
      "[CV] END gamma=10.0, learning_rate=0.017140645592500166, max_delta_step=1.5568026895171034, max_depth=16, min_child_weight=1.04484898011307, n_estimators=1000, reg_alpha=10.0, reg_lambda=0.09736356021550442, subsample=0.5; total time= 6.9min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:22:40] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:22:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   5.0s\n",
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   4.6s\n",
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   5.2s\n",
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   5.0s\n",
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   5.2s\n",
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   4.9s\n",
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   4.7s\n",
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   5.1s\n",
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   5.0s\n",
      "[CV] END gamma=0.003435160724255571, learning_rate=0.09999999999999999, max_delta_step=2.670583835009379, max_depth=3, min_child_weight=0.05648171380926536, n_estimators=100, reg_alpha=10.0, reg_lambda=0.04123548727270661, subsample=1.0; total time=   4.9s\n",
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:29:06] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:29:13] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 2.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 2.9min\n",
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 2.8min\n",
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 3.0min\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  21.2s\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  20.8s\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  21.1s\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  20.8s\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  22.0s\n",
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 3.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 3.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 3.0min\n",
      "[CV] END gamma=10.0, learning_rate=0.019979788344726957, max_delta_step=1.2846975129295857, max_depth=12, min_child_weight=10.0, n_estimators=1000, reg_alpha=0.001, reg_lambda=10.0, subsample=0.5131188291734922; total time= 2.8min\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  21.7s\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  21.3s\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  20.9s\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  20.7s\n",
      "[CV] END gamma=0.7666393214931585, learning_rate=0.09999999999999999, max_delta_step=0.21945580775917659, max_depth=3, min_child_weight=0.0032795464989304277, n_estimators=1000, reg_alpha=10.0, reg_lambda=10.0, subsample=0.7016878378273077; total time=  21.8s\n",
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [17:15:28] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [17:15:36] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.7min\n",
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [17:50:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [17:51:05] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.5min\n",
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.6min\n",
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.7min\n",
      "[CV] END gamma=0.001, learning_rate=0.020771790337181698, max_delta_step=1.524888421197282, max_depth=16, min_child_weight=10.0, n_estimators=792, reg_alpha=0.11538615474806223, reg_lambda=10.0, subsample=0.5; total time=17.4min\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [18:31:11] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [18:31:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.33209821575769133, learning_rate=0.0068639794182825545, max_delta_step=6.061126501381183, max_depth=15, min_child_weight=0.8955856146286302, n_estimators=976, reg_alpha=0.001079218593043752, reg_lambda=0.42561507255154285, subsample=0.5274166164117504; total time=22.5min\n",
      "[CV] END gamma=0.33209821575769133, learning_rate=0.0068639794182825545, max_delta_step=6.061126501381183, max_depth=15, min_child_weight=0.8955856146286302, n_estimators=976, reg_alpha=0.001079218593043752, reg_lambda=0.42561507255154285, subsample=0.5274166164117504; total time=22.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gamma=0.33209821575769133, learning_rate=0.0068639794182825545, max_delta_step=6.061126501381183, max_depth=15, min_child_weight=0.8955856146286302, n_estimators=976, reg_alpha=0.001079218593043752, reg_lambda=0.42561507255154285, subsample=0.5274166164117504; total time=22.9min\n",
      "[CV] END gamma=0.33209821575769133, learning_rate=0.0068639794182825545, max_delta_step=6.061126501381183, max_depth=15, min_child_weight=0.8955856146286302, n_estimators=976, reg_alpha=0.001079218593043752, reg_lambda=0.42561507255154285, subsample=0.5274166164117504; total time=22.4min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbayes_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/skopt/searchcv.py:542\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSearchCV doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support a callable refit, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt define an implicit score to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 542\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/skopt/searchcv.py:599\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 599\u001b[0m     optim_result, score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/skopt/searchcv.py:453\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[1;32m    451\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[0;32m--> 453\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# to get the score name\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bayes_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e2e82-b02f-48ff-b6a6-a36893fb54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_result = bayes_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c76e75-d327-4fdf-99cb-225f3bb5a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(CV_result).sort_values(by='rank_test_score', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4f64f-f266-464b-bc1b-49cf27685762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
